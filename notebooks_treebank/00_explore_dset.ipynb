{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from os.path import expanduser\n",
    "import sys\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pprint import pprint\n",
    "import imodelsx.util\n",
    "from os.path import dirname\n",
    "import pickle as pkl\n",
    "import json\n",
    "from copy import deepcopy\n",
    "from numpy.linalg import norm\n",
    "from math import ceil\n",
    "from imodelsx.qaemb.qaemb import QAEmb, get_sample_questions_and_examples\n",
    "from neuro.treebank.config import STORIES_POPULAR, STORIES_UNPOPULAR, ECOG_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_fname = 'cars-2'\n",
    "features_df = pd.read_csv(\n",
    "    join(ECOG_DIR, 'data', 'transcripts', story_fname, 'features.csv'))\n",
    "sec_window = 3\n",
    "ngram_list = []\n",
    "for i in tqdm(range(0, len(features_df))):\n",
    "    row = features_df.iloc[i]\n",
    "    time_end = row['end']\n",
    "    time_start = time_end - sec_window\n",
    "    ngram = features_df[(features_df['end'] >= time_start) & (\n",
    "        features_df['end'] <= time_end)]['text'].values.tolist()\n",
    "    ngram_list.append(ngram)\n",
    "features_df['ngram'] = ngram_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate consecutive values\n",
    "df = features_df.loc[features_df['sentence'].shift() !=\n",
    "                     features_df['sentence']]\n",
    "\n",
    "# set speaker to '' for duplicate consecutive values\n",
    "duplicate_speaker = df['speaker'].shift() == df['speaker']\n",
    "df = df[df['sentence'].notna()]\n",
    "df.loc[duplicate_speaker, 'speaker'] = ''\n",
    "\n",
    "# numbered sentences\n",
    "# df.loc[~duplicate_speaker, 'speaker'] = '<' + df['speaker'] + '>:\\n'\n",
    "# df['sentence_idx'] = np.arange(len(df)) + 1\n",
    "# df['script'] = df['speaker'] + \\\n",
    "# df['sentence_idx'].astype(str) + '. ' + df['sentence']\n",
    "# story = '\\n'.join(df['script'].iloc[:50])\n",
    "\n",
    "# unnumbered\n",
    "df.loc[~duplicate_speaker, 'speaker'] = '\\n<' + df['speaker'] + '>: '\n",
    "df['script'] = df['speaker'] + df['sentence']\n",
    "story = ' '.join(df['script'].iloc[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(story)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get popular stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(stories_popular)=9 len(stories_unpopular)=12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array(['Cars 2', 'Coraline', 'Lord Of The Rings 1', 'Lord Of The Rings 2',\n",
       "        'Megamind', 'Shrek The Third', 'Spiderman Far From Home',\n",
       "        'The Incredibles', 'Toy Story'], dtype=object),\n",
       " array(['Antman', 'Aquaman', 'Avengers Infinity War', 'Black Panther',\n",
       "        'Fantastic Mr. Fox', 'Guardians Of The Galaxy 2',\n",
       "        'Guardians Of the Galaxy', 'Sesame Street Episode 3990',\n",
       "        'Spiderman Homecoming', 'The Martian', 'Thor Ragnarok', 'venom'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_metadata_files = os.listdir(join(ECOG_DIR, 'data', 'subject_metadata'))\n",
    "jsons = {f: json.load(open(join(ECOG_DIR, 'data', 'subject_metadata', f)))\n",
    "         ['title'] for f in subject_metadata_files}\n",
    "df = pd.DataFrame(jsons.values(), index=jsons.keys()).reset_index()\n",
    "df.rename(columns={'index': 'filename', 0: 'title'}, inplace=True)\n",
    "df['subject'] = df['filename'].apply(lambda x: x.split('_trial')[\n",
    "                                     0].split('_')[-1]).astype(int)\n",
    "# df = df.sort_values(by='subject')\n",
    "df = df.sort_values(by='title')\n",
    "\n",
    "common_subjs = {3, 4, 6, 7, 10}\n",
    "stories_popular = df[df.subject.isin(common_subjs)].title.unique()\n",
    "stories_unpopular = df[~df.subject.isin(common_subjs)].title.unique()\n",
    "print(f'{len(stories_popular)=} {len(stories_unpopular)=}')\n",
    "stories_popular, stories_unpopular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save ensemble features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting = 'words'\n",
    "\n",
    "# output_dir_ensemble = join(ECOG_DIR, 'features', checkpoint_clean, setting)\n",
    "# output_dir_raw = join(ECOG_DIR, 'features_raw', checkpoint_clean, setting)\n",
    "# os.makedirs(output_dir_ensemble, exist_ok=True)\n",
    "# os.makedirs(output_dir_raw, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save ensemble feats\n",
    "for setting in ['words', 'sec_3']:\n",
    "    out_checkpoint = 'ensemble1'\n",
    "    ensemble1 = [\n",
    "        'mistralai/Mistral-7B-Instruct-v0.2',\n",
    "        'meta-llama/Meta-Llama-3-8B-Instruct',\n",
    "        'google/gemma-7b-it',\n",
    "    ]\n",
    "    output_dir_ensemble = join(ECOG_DIR, 'features', out_checkpoint, setting)\n",
    "    os.makedirs(output_dir_ensemble, exist_ok=True)\n",
    "\n",
    "    # read in ensemble feats\n",
    "    ensemble_checkpoint_story_dict = {}\n",
    "    for checkpoint in tqdm(ensemble1):\n",
    "        checkpoint_clean = checkpoint.replace('/', '___')\n",
    "        output_dir_clean = join(ECOG_DIR, 'features',\n",
    "                                checkpoint_clean, setting)\n",
    "        story_fnames = os.listdir(output_dir_clean)\n",
    "        checkpoint_story_dict = {}\n",
    "        for story_fname in story_fnames:\n",
    "            if story_fname.endswith('.pkl'):\n",
    "                checkpoint_story_dict[story_fname] = joblib.load(\n",
    "                    join(output_dir_clean, story_fname))\n",
    "        ensemble_checkpoint_story_dict[checkpoint] = deepcopy(\n",
    "            checkpoint_story_dict)\n",
    "\n",
    "    # save avg feats\n",
    "    common_stories = set.intersection(\n",
    "        *[set(ensemble_checkpoint_story_dict[checkpoint].keys())\n",
    "            for checkpoint in ensemble1]\n",
    "    )\n",
    "    for story_fname in tqdm(common_stories):\n",
    "        # avg over all checkpoints\n",
    "        story1_df = ensemble_checkpoint_story_dict[ensemble1[0]][story_fname]\n",
    "        story2_df = ensemble_checkpoint_story_dict[ensemble1[1]][story_fname]\n",
    "        story3_df = ensemble_checkpoint_story_dict[ensemble1[2]][story_fname]\n",
    "\n",
    "        # align the dfs to have same cols and index\n",
    "        story1_df = story1_df[story2_df.columns]\n",
    "        assert story1_df.columns.equals(story2_df.columns)\n",
    "        assert story1_df.index.equals(story2_df.index)\n",
    "\n",
    "        story2_df = story2_df[story1_df.columns]\n",
    "        assert story2_df.columns.equals(story1_df.columns)\n",
    "        assert story2_df.index.equals(story1_df.index)\n",
    "\n",
    "        # average values\n",
    "        # avg_df = (story1_df.astype(float) + story2_df.astype(float)) / 2\n",
    "        avg_df = (story1_df.astype(float) + story2_df.astype(float) +\n",
    "                  story3_df.astype(float)) / 3\n",
    "\n",
    "        # save\n",
    "        avg_df.to_pickle(join(output_dir_ensemble, story_fname))\n",
    "        avg_df.to_csv(join(output_dir_ensemble,\n",
    "                           story_fname.replace('.pkl', '.csv')))\n",
    "    print('avg feats', output_dir_ensemble, os.listdir(output_dir_ensemble))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/chansingh/mntv1/ecog/features/ensemble1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rclone copy /home/chansingh/mntv1/ecog/features/ensemble1/ box:DeepTune/QA/cached_qa_tree --progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
