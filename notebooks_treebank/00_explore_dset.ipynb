{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from os.path import expanduser\n",
    "import sys\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pprint import pprint\n",
    "import imodelsx.util\n",
    "from os.path import dirname\n",
    "import pickle as pkl\n",
    "import json\n",
    "from copy import deepcopy\n",
    "from numpy.linalg import norm\n",
    "from math import ceil\n",
    "from imodelsx.qaemb.qaemb import QAEmb, get_sample_questions_and_examples\n",
    "from neuro.treebank.config import STORIES_POPULAR, STORIES_UNPOPULAR, ECOG_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_fname = 'cars-2'\n",
    "features_df = pd.read_csv(\n",
    "    join(ECOG_DIR, 'data', 'transcripts', story_fname, 'features.csv'))\n",
    "sec_window = 3\n",
    "ngram_list = []\n",
    "for i in tqdm(range(0, len(features_df))):\n",
    "    row = features_df.iloc[i]\n",
    "    time_end = row['end']\n",
    "    time_start = time_end - sec_window\n",
    "    ngram = features_df[(features_df['end'] >= time_start) & (\n",
    "        features_df['end'] <= time_end)]['text'].values.tolist()\n",
    "    ngram_list.append(ngram)\n",
    "features_df['ngram'] = ngram_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate consecutive values\n",
    "df = features_df.loc[features_df['sentence'].shift() !=\n",
    "                     features_df['sentence']]\n",
    "\n",
    "# set speaker to '' for duplicate consecutive values\n",
    "duplicate_speaker = df['speaker'].shift() == df['speaker']\n",
    "df = df[df['sentence'].notna()]\n",
    "df.loc[duplicate_speaker, 'speaker'] = ''\n",
    "\n",
    "# numbered sentences\n",
    "# df.loc[~duplicate_speaker, 'speaker'] = '<' + df['speaker'] + '>:\\n'\n",
    "# df['sentence_idx'] = np.arange(len(df)) + 1\n",
    "# df['script'] = df['speaker'] + \\\n",
    "# df['sentence_idx'].astype(str) + '. ' + df['sentence']\n",
    "# story = '\\n'.join(df['script'].iloc[:50])\n",
    "\n",
    "# unnumbered\n",
    "df.loc[~duplicate_speaker, 'speaker'] = '\\n<' + df['speaker'] + '>: '\n",
    "df['script'] = df['speaker'] + df['sentence']\n",
    "story = ' '.join(df['script'].iloc[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(story)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get popular stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(stories_popular)=9 len(stories_unpopular)=12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array(['Cars 2', 'Coraline', 'Lord Of The Rings 1', 'Lord Of The Rings 2',\n",
       "        'Megamind', 'Shrek The Third', 'Spiderman Far From Home',\n",
       "        'The Incredibles', 'Toy Story'], dtype=object),\n",
       " array(['Antman', 'Aquaman', 'Avengers Infinity War', 'Black Panther',\n",
       "        'Fantastic Mr. Fox', 'Guardians Of The Galaxy 2',\n",
       "        'Guardians Of the Galaxy', 'Sesame Street Episode 3990',\n",
       "        'Spiderman Homecoming', 'The Martian', 'Thor Ragnarok', 'venom'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_metadata_files = os.listdir(join(ECOG_DIR, 'data', 'subject_metadata'))\n",
    "jsons = {f: json.load(open(join(ECOG_DIR, 'data', 'subject_metadata', f)))\n",
    "         ['title'] for f in subject_metadata_files}\n",
    "df = pd.DataFrame(jsons.values(), index=jsons.keys()).reset_index()\n",
    "df.rename(columns={'index': 'filename', 0: 'title'}, inplace=True)\n",
    "df['subject'] = df['filename'].apply(lambda x: x.split('_trial')[\n",
    "                                     0].split('_')[-1]).astype(int)\n",
    "# df = df.sort_values(by='subject')\n",
    "df = df.sort_values(by='title')\n",
    "\n",
    "common_subjs = {3, 4, 6, 7, 10}\n",
    "stories_popular = df[df.subject.isin(common_subjs)].title.unique()\n",
    "stories_unpopular = df[~df.subject.isin(common_subjs)].title.unique()\n",
    "print(f'{len(stories_popular)=} {len(stories_unpopular)=}')\n",
    "stories_popular, stories_unpopular"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
