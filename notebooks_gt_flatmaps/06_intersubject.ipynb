{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import joblib\n",
    "from pprint import pprint\n",
    "from math import ceil\n",
    "import cortex\n",
    "from neuro.config import repo_dir, PROCESSED_DIR, setup_freesurfer\n",
    "from collections import defaultdict\n",
    "from scipy.stats import norm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import gemv\n",
    "from neuro.flatmaps_helper import load_flatmaps\n",
    "import sasc.viz\n",
    "from neuro import analyze_helper\n",
    "import nibabel as nib\n",
    "neurosynth_compare = __import__('04_neurosynth_compare')\n",
    "import neurosynth\n",
    "from neuro.features.questions.gpt4 import QS_35_STABLE\n",
    "import viz\n",
    "setup_freesurfer()\n",
    "\n",
    "subject = 'S02'\n",
    "# subjects = [f'S0{i}' for i in range(1, 9) if not i == 6] # there's some problem with S06 surf2surf\n",
    "subjects = ['S01', 'S02', 'S03']\n",
    "\n",
    "# load flatmaps\n",
    "d = defaultdict(list)\n",
    "for subject in subjects:\n",
    "    # if subject in ['S01', 'S02', 'S03']:\n",
    "    # settings = ['individual_gpt4',\n",
    "    # 'individual_gpt4_wordrate', 'shapley_35']\n",
    "    # else:\n",
    "    settings = ['individual_gpt4_ndel=1_pc_new']\n",
    "    flatmaps_qa_list = defaultdict(list)\n",
    "    for setting in settings:\n",
    "        flatmaps_qa_dict = joblib.load(\n",
    "            join(PROCESSED_DIR, subject.replace('UT', ''), setting + '.pkl'))\n",
    "        for q in flatmaps_qa_dict.keys():\n",
    "            flatmaps_qa_list[q].append(flatmaps_qa_dict[q])\n",
    "    flatmaps_qa_dict = {\n",
    "        q: np.mean(flatmaps_qa_list[q], axis=0)\n",
    "        for q in flatmaps_qa_list.keys()\n",
    "    }\n",
    "    # for k in sorted(flatmaps_qa_dict.keys()):\n",
    "    for k in QS_35_STABLE:\n",
    "        # print(k, flatmaps_qa_dict[k])\n",
    "        # d[f'q_{subject}'].append(k)\n",
    "        d[subject].append(flatmaps_qa_dict[k])\n",
    "\n",
    "    # print(subject, len(flatmaps_qa_dict))\n",
    "df = pd.DataFrame(d)\n",
    "# df.set_index('q_S01', inplace=True)\n",
    "df.index = QS_35_STABLE\n",
    "df.index.name = 'question'\n",
    "df = df[df.index.isin(QS_35_STABLE)]\n",
    "assert df.shape[0] == 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mni vols\n",
    "'''\n",
    "mni_arrs_list = []\n",
    "for q in tqdm(df.index):\n",
    "    mni_vols = []\n",
    "    for subject in subjects:\n",
    "        print(subject)\n",
    "        subj_vol = cortex.Volume(df.loc[q][subject], 'UT' + subject,\n",
    "                                 xfmname=f\"UT{subject}_auto\")\n",
    "        mni_vol = neurosynth.subj_vol_to_mni_surf(subj_vol, subject)\n",
    "        mni_vols.append(deepcopy(mni_vol))\n",
    "        mni_arrs = [mni_vol.data for mni_vol in mni_vols]\n",
    "    mni_arrs_list.append(deepcopy(mni_arrs))\n",
    "joblib.dump(mni_arrs_list, 'mni_arrs_list.pkl')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load arrs for first 3 subjects\n",
    "mni_arrs_list = joblib.load('mni_arrs_list.pkl')\n",
    "mni_arrs_list = [a[:3] for a in mni_arrs_list]\n",
    "subjects = subjects[:3]\n",
    "\n",
    "# compute correlations\n",
    "corrs_list = []\n",
    "for j, q in enumerate(df.index):\n",
    "    # compute correlation between each one and mean of the others\n",
    "    mni_arrs = np.array(mni_arrs_list[j])\n",
    "    corrs_loo = []\n",
    "    for i in range(mni_arrs.shape[0]):\n",
    "        mni_arr = mni_arrs[i]\n",
    "        other_mni_arrs = np.delete(mni_arrs, i, axis=0)\n",
    "        mean_other_mni_arr = np.mean(other_mni_arrs, axis=0)\n",
    "        corr = np.corrcoef(mni_arr.flatten(),\n",
    "                           mean_other_mni_arr.flatten())[0, 1]\n",
    "        # print(f'corr between {i} and mean of others', corr)\n",
    "        corrs_loo.append(corr)\n",
    "    corrs_list.append(corrs_loo)\n",
    "corrs_df = pd.DataFrame(np.array(corrs_list), columns=subjects, index=df.index)\n",
    "\n",
    "# flatten with column name as value for a new column\n",
    "corrs_df = corrs_df.melt(\n",
    "    ignore_index=False, var_name='subject', value_name='corrs').reset_index()\n",
    "corrs_df.rename(columns={'question': 'questions'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 6), dpi=300)\n",
    "neurosynth_compare.plot_corrs_df(\n",
    "    corrs_df,\n",
    "    out_dir='intersubject',\n",
    "    plot_val=f'corrs',\n",
    "    xlab=f'Inter-subject correlation (MNI space)',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_distrs = []\n",
    "# for i, subject in enumerate(tqdm(['UTS01', 'UTS02', 'UTS03'])):\n",
    "#     flatmaps_qa_list = [arr[i].flatten() for arr in mni_arrs_list]\n",
    "#     flatmaps_null = np.array(joblib.load(\n",
    "#         join(PROCESSED_DIR,\n",
    "#              #  subject.replace('UT', ''), 'resp_chunks_1trs.pkl')))\n",
    "#              subject.replace('UT', ''), 'resp_chunks_1trs_MNI.pkl')))\n",
    "#     # flatmaps_null = [arr.flatten() for arr in flatmaps_null]\n",
    "#     flatmaps_null = flatmaps_null.reshape(flatmaps_null.shape[0], -1)\n",
    "\n",
    "#     _, baseline_distr = viz.compute_pvals(\n",
    "#         flatmaps_qa_list,\n",
    "#         frac_voxels_to_keep=1,\n",
    "#         corrs_gt_arr=corrs_df[f'corrs'].values,\n",
    "#         flatmaps_null=flatmaps_null,\n",
    "#     )\n",
    "\n",
    "#     baseline_distrs.append(baseline_distr)\n",
    "# joblib.dump(baseline_distrs, 'baseline_distrs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_distrs = joblib.load('baseline_distrs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29966815384793277\n",
      "mean test p 0.0\n",
      "individual pvals (err corrected) [0.         0.         0.03871212 0.00625    0.04375    0.\n",
      " 0.         0.         0.         0.         0.         0.00072917\n",
      " 0.0021     0.         0.         0.         0.02822581 0.\n",
      " 0.00403846 0.02333333 0.         0.00072917 0.         0.\n",
      " 0.         0.00965517 0.         0.         0.         0.049\n",
      " 0.         0.00453704 0.         0.00072917 0.0371875 ] num sig 35\n"
     ]
    }
   ],
   "source": [
    "vals_baseline = np.array(baseline_distrs).mean(axis=0)\n",
    "vals_alt = corrs_df[f'corrs'].values\n",
    "\n",
    "n = len(vals_alt)\n",
    "print(np.mean(vals_alt))\n",
    "\n",
    "# permutation test on mean\n",
    "n_samples = 1000\n",
    "means_baseline = [\n",
    "    np.mean(np.random.choice(vals_baseline.flatten(), size=n, replace=False))\n",
    "    for i in range(n_samples)\n",
    "]\n",
    "print('mean test p', np.mean(np.array(means_baseline) >= np.mean(vals_alt)))\n",
    "\n",
    "# permutation test on individuals\n",
    "pvals = []\n",
    "for i in range(len(vals_baseline)):\n",
    "    pvals.append(np.mean(vals_baseline[i] >= vals_alt[i]))\n",
    "pvals = multipletests(\n",
    "    pvals, method='fdr_bh', alpha=0.05)[1]\n",
    "print('individual pvals (err corrected)',\n",
    "      pvals, 'num sig', np.sum(pvals < 0.05))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
