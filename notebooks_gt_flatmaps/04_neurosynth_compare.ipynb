{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cortex\n",
    "from os.path import join\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "sys.path.append('../notebooks')\n",
    "from neuro.config import repo_dir, PROCESSED_DIR\n",
    "from neuro import viz\n",
    "from neurosynth import term_dict, term_dict_rev, get_neurosynth_flatmaps\n",
    "neurosynth_compare = __import__('04_neurosynth_compare')\n",
    "import viz\n",
    "import neurosynth\n",
    "from cortex import mni\n",
    "import os\n",
    "os.environ[\"FSLDIR\"] = \"/home/chansingh/fsl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, this notebook requires first running `03_export_qa_flatmaps.ipynb` into `df_qa_dict.pkl` files for each subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute correlations with qa flatmaps and plot avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting = 'shapley_neurosynth'\n",
    "# setting = 'full_neurosynth'\n",
    "# setting = 'individual_gpt4''\n",
    "for settings in [\n",
    "    # ['full_neurosynth_pc'],\n",
    "    # ['full_neurosynth_wordrate_pc'],\n",
    "    # ['full_35_pc'],\n",
    "    # ['full_35_wordrate_pc'],\n",
    "    # ['full_neurosynth'],\n",
    "    # ['full_neurosynth_wordrate'],\n",
    "    # ['full_35'],\n",
    "    # ['full_35_wordrate'],\n",
    "    # ['individual_gpt4'],\n",
    "]:\n",
    "    print('settings', settings)\n",
    "    # settings = ['']  # shapley_neurosynth, individual_gpt4\n",
    "    subjects = ['UTS01', 'UTS02', 'UTS03']\n",
    "    # subjects = [f'UTS0{i}' for i in range(1, 9)]\n",
    "\n",
    "    # comparison hyperparams\n",
    "    apply_mask = True\n",
    "    frac_voxels_to_keep = 0.1  # 0.10\n",
    "    frac_voxels_to_keep_list = [frac_voxels_to_keep]\n",
    "    # hyperparams\n",
    "    out_dir = join(repo_dir, 'qa_results',\n",
    "                   'neurosynth_compare', '___'.join(settings))\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # load flatmaps\n",
    "    flatmaps_qa_dicts_by_subject = neurosynth.load_flatmaps_qa_dicts_by_subject(\n",
    "        subjects, settings)\n",
    "\n",
    "    # flatmaps_gt_dict_list_subject_mni = {subject: [convert_to_mni_space(flatmaps_gt_dict_list_subject[subject][qs[i]], subject=subject)\n",
    "    #                                                for i in tqdm(range(len(qs)))]\n",
    "    #                                      for subject in ['UTS01', 'UTS02', 'UTS03']}\n",
    "    flatmaps_gt_dict_mni = neurosynth.get_neurosynth_flatmaps(mni=True)\n",
    "    qs = list(set(flatmaps_qa_dicts_by_subject['UTS02'].keys()) & set(\n",
    "        flatmaps_gt_dict_mni.keys()))\n",
    "    print('num common qs', len(qs))\n",
    "\n",
    "    corrs_df = neurosynth_compare.compute_corrs_df(\n",
    "        qs, frac_voxels_to_keep, subjects, flatmaps_qa_dicts_by_subject, apply_mask)\n",
    "\n",
    "    neurosynth_compare.plot_corrs_df(corrs_df, frac_voxels_to_keep, out_dir)\n",
    "\n",
    "    # compute pvals\n",
    "    # pvals_subject = compute_pvals_for_subject(\n",
    "    # corrs_df, 'UTS01', frac_voxels_to_keep_list)\n",
    "    # pvals_subject.style.background_gradient().format(precision=3)\n",
    "\n",
    "    # compute mni space correlations\n",
    "    # corrs_df_mni = neurosynth_compare.compute_mni_corr_df(\n",
    "    #     flatmaps_qa_dicts_by_subject, flatmaps_gt_dict_mni, qs)\n",
    "    # print('avg', corrs_df_mni.loc['avg'])\n",
    "    # corrs_df_mni.to_pickle(join(out_dir, 'corrs_df_mni.pkl'))\n",
    "    # corrs_df_mni.style.background_gradient(axis=None, cmap=\"coolwarm_r\", vmin=-\n",
    "    #                                        corrs_df_mni.abs().max().max(), vmax=corrs_df_mni.abs().max().max()).format(precision=3).to_html(\n",
    "    #     join(out_dir, 'corrs_df_mni.html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-do analysis in MNI space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_df_mni = neurosynth_compare.compute_mni_corr_df(\n",
    "    flatmaps_qa_dicts_by_subject, flatmaps_gt_dict_mni, qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_df_mni.round(3).style.background_gradient(axis=None, cmap=\"coolwarm_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surf example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cortex.db.get_mri_surf2surf_matrix(\"fsaverage\", \"pial\", target_subj='UTS01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNI example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'Does the input mention anything related to navigation?'\n",
    "flatmaps_q = [flatmaps_qa_dicts_by_subject[s][q] for s in subjects]\n",
    "flatmap_q_s01 = flatmaps_q[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatmap_gt = get_neurosynth_flatmaps('UTS01', mni=False)[q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(flatmap_q_s01.ravel(), flatmap_gt.ravel())[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatmaps_gt_dict_mni[q].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatmaps_q_mni = [\n",
    "    neurosynth_compare.convert_to_mni_space(flatmaps_q[i], subject=subjects[i])\n",
    "    for i in range(len(subjects))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_flatmap_q_mni = np.mean(flatmaps_q_mni, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatmaps_gt_dict_mni[q].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(flatmaps_q_mni[0].ravel(), flatmaps_gt_dict_mni[q].ravel())[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(avg_flatmap_q_mni.ravel(), flatmaps_gt_dict_mni[q].ravel())[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View flatmaps in 1 plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_df = pd.read_pickle(join(repo_dir, 'qa_results',\n",
    "                               'neurosynth', setting + '_corrs_df.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = 'shapley_neurosynth'\n",
    "for subject in ['UTS01', 'UTS02', 'UTS03']:\n",
    "    img_dir1 = join(repo_dir, 'qa_results', 'neurosynth',\n",
    "                    subject, 'neurosynth')\n",
    "    img_dir2 = join(repo_dir, 'qa_results', 'neurosynth',\n",
    "                    subject, setting)\n",
    "\n",
    "    # read images and combine them with their filenames on a single plot\n",
    "    # fnames = os.listdir(img_dir1)\n",
    "    # fnames = [f for f in fnames if f.endswith('.png')]\n",
    "    # only keep the ones that are in both directories\n",
    "    # fnames = [f for f in fnames if f in os.listdir(img_dir2)]\n",
    "\n",
    "    corrs = corrs_df[corrs_df['subject'] == subject]\n",
    "    # corrs = corrs.sort_values(f'corrs_{frac_voxels_to_keep}', ascending=False)\n",
    "    fnames = [v + '.png' for v in corrs['questions'].values]\n",
    "\n",
    "    n = len(fnames)\n",
    "    C = 4\n",
    "    R = int(np.ceil(n / C))\n",
    "\n",
    "    fig, axs = plt.subplots(R, C, figsize=(C * 3.2, R * 1))\n",
    "    axs = axs.flatten()\n",
    "    for i in range(len(axs)):\n",
    "        axs[i].axis('off')\n",
    "    for i, fname in enumerate(fnames):\n",
    "        img1 = plt.imread(join(img_dir1, fname))\n",
    "        img2 = plt.imread(join(img_dir2, fname))\n",
    "        axs[i].imshow(np.concatenate([img1, img2], axis=1))\n",
    "        axs[i].set_title(\n",
    "            f'{term_dict_rev[fname[:-4]]} ({corrs[\"corrs\"].values[i]:0.3f})', fontsize=8)\n",
    "\n",
    "    # add text in bottom right of figure\n",
    "    fig.text(0.99, 0.01, f'{subject}\\nNeurosynth on left, QA on right',\n",
    "             ha='right', va='bottom', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(join(repo_dir, 'qa_results', 'neurosynth',\n",
    "                subject, f'flatmaps_{setting}_{subject}.png'), dpi=300)\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
