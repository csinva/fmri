{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cortex\n",
    "from os.path import join\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "sys.path.append('../notebooks')\n",
    "from neuro.config import repo_dir, PROCESSED_DIR\n",
    "from neuro import viz, analyze_helper\n",
    "from neuro.features.questions.gpt4 import QS_35_STABLE\n",
    "from neurosynth import term_dict, term_dict_rev, get_neurosynth_flatmaps\n",
    "neurosynth_compare = __import__('04_neurosynth_compare')\n",
    "import viz\n",
    "import neurosynth\n",
    "from cortex import mni\n",
    "import os\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from neuro.config import repo_dir, PROCESSED_DIR, setup_freesurfer\n",
    "setup_freesurfer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, this notebook requires first running `03_export_qa_flatmaps.ipynb` into `df_qa_dict.pkl` files for each subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute correlations with qa flatmaps and plot avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting = 'shapley_neurosynth'\n",
    "# setting = 'full_neurosynth'\n",
    "# setting = 'individual_gpt4''\n",
    "for settings in [\n",
    "    # ['full_neurosynth_pc'],\n",
    "    # ['full_neurosynth_wordrate_pc'],\n",
    "    # ['full_35_pc'],\n",
    "    # ['full_35_wordrate_pc'],\n",
    "    # ['full_neurosynth'],\n",
    "    # ['full_neurosynth_wordrate'],\n",
    "    # ['full_35'],\n",
    "    # ['full_35_wordrate'],\n",
    "    # ['individual_gpt4'],\n",
    "    ['individual_gpt4_ndel=1_pc_new'],\n",
    "    # ['individual_gpt4_pc_new'],\n",
    "\n",
    "]:\n",
    "    print('settings', settings)\n",
    "    # settings = ['']  # shapley_neurosynth, individual_gpt4\n",
    "    subjects = ['UTS01', 'UTS02', 'UTS03']\n",
    "    # subjects = [f'UTS0{i}' for i in range(1, 9)]\n",
    "\n",
    "    # comparison hyperparams\n",
    "    apply_mask = True\n",
    "    frac_voxels_to_keep = 0.1  # 0.10\n",
    "    frac_voxels_to_keep_list = [frac_voxels_to_keep]\n",
    "    # hyperparams\n",
    "    out_dir = join(repo_dir, 'qa_results',\n",
    "                   'neurosynth_compare', '___'.join(settings))\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # load flatmaps\n",
    "    flatmaps_qa_dicts_by_subject = neurosynth.load_flatmaps_qa_dicts_by_subject(\n",
    "        subjects, settings)\n",
    "\n",
    "    corrs_df = neurosynth_compare.compute_corrs_df(\n",
    "        frac_voxels_to_keep, subjects, flatmaps_qa_dicts_by_subject, apply_mask)\n",
    "\n",
    "    # compute pvals\n",
    "    # pvals_subject = compute_pvals_for_subject(\n",
    "    # corrs_df, 'UTS01', frac_voxels_to_keep_list)\n",
    "    # pvals_subject.style.background_gradient().format(precision=3)\n",
    "\n",
    "    # compute mni space correlations\n",
    "    # corrs_df_mni = neurosynth_compare.compute_mni_corr_df(\n",
    "    #     flatmaps_qa_dicts_by_subject, flatmaps_gt_dict_mni, qs)\n",
    "    # print('avg', corrs_df_mni.loc['avg'])\n",
    "    # corrs_df_mni.to_pickle(join(out_dir, 'corrs_df_mni.pkl'))\n",
    "    # corrs_df_mni.style.background_gradient(axis=None, cmap=\"coolwarm_r\", vmin=-\n",
    "    #                                        corrs_df_mni.abs().max().max(), vmax=corrs_df_mni.abs().max().max()).format(precision=3).to_html(\n",
    "    #     join(out_dir, 'corrs_df_mni.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 6), dpi=300)\n",
    "neurosynth_compare.plot_corrs_df(\n",
    "    corrs_df, out_dir, plot_val=f'corrs_{frac_voxels_to_keep}',\n",
    "    xlab=f'Correlation between NeuroSynth scores and QA coefficients\\n(Top-{int(100*frac_voxels_to_keep)}% best-predicted voxels)')\n",
    "print('saved to', out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_35 = sorted([x[0] for x in corrs_df.questions.unique()])\n",
    "\n",
    "for frac_voxels_to_keep in tqdm(frac_voxels_to_keep_list):\n",
    "    # eng1000_dir = join(PROCESSED_DIR, subject.replace(\n",
    "    # 'UT', ''), 'eng1000_weights.pkl')\n",
    "    # flatmaps_null = joblib.load(eng1000_dir)\n",
    "    baseline_distrs = []\n",
    "    for subject in ['UTS01', 'UTS02', 'UTS03']:\n",
    "        flatmaps_qa_list = [\n",
    "            flatmaps_qa_dicts_by_subject[subject][k] for k in qs_35]\n",
    "        flatmaps_null = np.array(joblib.load(\n",
    "            join(PROCESSED_DIR, subject.replace('UT', ''), 'resp_chunks_1trs.pkl')))\n",
    "\n",
    "        # print('shape', flatmaps_eng1000.shape)\n",
    "        corrs_test = joblib.load(join(PROCESSED_DIR, subject.replace(\n",
    "            'UT', ''), 'corrs_test_35.pkl')).values[0]\n",
    "        _, baseline_distr = viz.compute_pvals(\n",
    "            flatmaps_qa_list, frac_voxels_to_keep,\n",
    "            corrs_df[f'corrs_{frac_voxels_to_keep}'].values,\n",
    "            flatmaps_null=flatmaps_null, mask_corrs=corrs_test)\n",
    "\n",
    "        baseline_distrs.append(baseline_distr)\n",
    "\n",
    "        # get what fraction of 'corrs_perm_eng1000' column is greater than 'corrs'\n",
    "    #     corrs_df[f'pval_{frac_voxels_to_keep}'] = pvals\n",
    "    #     corrs_df[f'baseline_distr_{frac_voxels_to_keep}'] = basline_distr\n",
    "    # for frac_voxels_to_keep in tqdm(frac_voxels_to_keep_list):\n",
    "    #     corrs_df[f'pval_{frac_voxels_to_keep}_err_corrected'] = multipletests(\n",
    "    #         pvals, method='fdr_bh', alpha=0.5)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_baseline = np.array(baseline_distrs).mean(axis=0)\n",
    "vals_alt = corrs_df.groupby('questions')[\n",
    "    f'corrs_{frac_voxels_to_keep}'].mean().sort_index().values\n",
    "\n",
    "n = len(vals_alt)\n",
    "print(np.mean(vals_alt))\n",
    "\n",
    "# permutation test on mean\n",
    "n_samples = 1000\n",
    "means_baseline = [\n",
    "    np.mean(np.random.choice(vals_baseline.flatten(), size=n, replace=False))\n",
    "    for i in range(n_samples)\n",
    "]\n",
    "print('mean test p', np.mean(np.array(means_baseline) >= np.mean(vals_alt)))\n",
    "\n",
    "# permutation test on individuals\n",
    "pvals = []\n",
    "for i in range(len(vals_baseline)):\n",
    "    pvals.append(np.mean(vals_baseline[i] >= vals_alt[i]))\n",
    "pvals = multipletests(\n",
    "    pvals, method='fdr_bh', alpha=0.05)[1]\n",
    "print('individual pvals (err corrected)', pvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate possible matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_tab = corrs_df.pivot_table(\n",
    "    index='questions', columns='subject', values='corrs_0.1'\n",
    ")\n",
    "# add mean col\n",
    "corrs_tab['mean'] = corrs_tab.mean(axis=1)\n",
    "corrs_tab = corrs_tab.sort_values('mean', ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.float_format', '{:.3f}'.format,\n",
    "                       'display.max_rows', None,\n",
    "                       'display.max_columns', None):\n",
    "    display(corrs_tab.sort_values(\n",
    "        by=['questions', 'mean'], ascending=[True, False]).set_index('questions')[['mean']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_matches = defaultdict(list)\n",
    "for k in term_dict_rev.keys():\n",
    "    tab_matches['q'].append(k)\n",
    "    tab_matches['term'].append(term_dict_rev[k])\n",
    "\n",
    "for k in QS_35_STABLE:\n",
    "    if k not in tab_matches['q']:\n",
    "        tab_matches['q'].append(k)\n",
    "        tab_matches['term'].append('NO MATCH')\n",
    "\n",
    "tab_matches = pd.DataFrame(tab_matches)\n",
    "tab_matches['q'] = [analyze_helper.abbrev_question(\n",
    "    q) for q in tab_matches['q']]\n",
    "tab_matches.to_csv('tab_matches.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View flatmaps in 1 plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_df = pd.read_pickle(join(repo_dir, 'qa_results',\n",
    "                               'neurosynth', setting + '_corrs_df.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = 'shapley_neurosynth'\n",
    "for subject in ['UTS01', 'UTS02', 'UTS03']:\n",
    "    img_dir1 = join(repo_dir, 'qa_results', 'neurosynth',\n",
    "                    subject, 'neurosynth')\n",
    "    img_dir2 = join(repo_dir, 'qa_results', 'neurosynth',\n",
    "                    subject, setting)\n",
    "\n",
    "    # read images and combine them with their filenames on a single plot\n",
    "    # fnames = os.listdir(img_dir1)\n",
    "    # fnames = [f for f in fnames if f.endswith('.png')]\n",
    "    # only keep the ones that are in both directories\n",
    "    # fnames = [f for f in fnames if f in os.listdir(img_dir2)]\n",
    "\n",
    "    corrs = corrs_df[corrs_df['subject'] == subject]\n",
    "    # corrs = corrs.sort_values(f'corrs_{frac_voxels_to_keep}', ascending=False)\n",
    "    fnames = [v + '.png' for v in corrs['questions'].values]\n",
    "\n",
    "    n = len(fnames)\n",
    "    C = 4\n",
    "    R = int(np.ceil(n / C))\n",
    "\n",
    "    fig, axs = plt.subplots(R, C, figsize=(C * 3.2, R * 1))\n",
    "    axs = axs.flatten()\n",
    "    for i in range(len(axs)):\n",
    "        axs[i].axis('off')\n",
    "    for i, fname in enumerate(fnames):\n",
    "        img1 = plt.imread(join(img_dir1, fname))\n",
    "        img2 = plt.imread(join(img_dir2, fname))\n",
    "        axs[i].imshow(np.concatenate([img1, img2], axis=1))\n",
    "        axs[i].set_title(\n",
    "            f'{term_dict_rev[fname[:-4]]} ({corrs[\"corrs\"].values[i]:0.3f})', fontsize=8)\n",
    "\n",
    "    # add text in bottom right of figure\n",
    "    fig.text(0.99, 0.01, f'{subject}\\nNeurosynth on left, QA on right',\n",
    "             ha='right', va='bottom', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(join(repo_dir, 'qa_results', 'neurosynth',\n",
    "                subject, f'flatmaps_{setting}_{subject}.png'), dpi=300)\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
