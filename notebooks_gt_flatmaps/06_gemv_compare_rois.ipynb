{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cortex\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import dvu\n",
    "import sys\n",
    "import warnings\n",
    "sys.path.append('../notebooks')\n",
    "from tqdm import tqdm\n",
    "from sasc.config import FMRI_DIR, STORIES_DIR, RESULTS_DIR\n",
    "from neuro.config import repo_dir, PROCESSED_DIR\n",
    "from neuro import analyze_helper, viz\n",
    "from neuro.features.qa_questions import get_questions, get_merged_questions_v3_boostexamples\n",
    "# flatmaps_per_question = __import__('06_flatmaps_per_question')\n",
    "import viz\n",
    "import gemv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, this notebook requires first running `03_export_qa_flatmaps.ipynb` into `df_qa_dict.pkl` files for each subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load gemv average flatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemv_flatmaps_pilot = joblib.load(join(\n",
    "    RESULTS_DIR, \"processed\", \"flatmaps\", 'resps_avg_dict_pilot.pkl'))\n",
    "gemv_flatmaps_pilot5 = joblib.load(join(\n",
    "    RESULTS_DIR, \"processed\", \"flatmaps\", 'resps_avg_dict_pilot5.pkl'))\n",
    "gemv_flatmaps_dict = gemv_flatmaps_pilot | gemv_flatmaps_pilot5\n",
    "qa_questions_list, gemv_questions_list = gemv.get_matched_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check that gpt4 was run for all the questions\n",
    "# subject = 'UTS02'\n",
    "# setting = 'individual_gpt4'\n",
    "# flatmaps_qa = joblib.load(\n",
    "#     join(PROCESSED_DIR, subject.replace('UT', ''), setting + '.pkl'))\n",
    "# for k in qa_list:\n",
    "#     assert k in flatmaps_qa.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings = ['full_35']\n",
    "# settings = ['full_35_wordrate']\n",
    "# settings = ['full_35_pc']\n",
    "# settings = ['full_neurosynth']\n",
    "# settings = ['full_35_gpt4_pc']\n",
    "settings = ['individual_gpt4_pc']\n",
    "# settings = ['shapley_35_gpt4_pc']\n",
    "# settings = ['shapley_35', 'individual_gpt4_pc', 'shapley_35_gpt4_pc']\n",
    "# settings = ['individual_gpt4_ndel=1_pc']\n",
    "# settings = ['full_35_gpt4_ndel=1_pc']\n",
    "# settings = ['full_35_ndel=8_pc']\n",
    "# settings = ['full_35', 'full_35_wordrate']\n",
    "# settings = ['individual_gpt4', 'individual_gpt4_wordrate',]\n",
    "# settings = ['individual_gpt4', 'individual_gpt4_wordrate', 'shapley_35']\n",
    "# settings = ['shapley_35']\n",
    "# settings = ['individual_35']\n",
    "# settings = ['individual_gpt4']\n",
    "# , 'individual_35', full_35', 'shapley_35', 'individual_gpt4',\n",
    "# for setting in ['individual_gpt4', 'shapley_35']:\n",
    "# for setting in ['individual_gpt4', 'individual_gpt4_wordrate']:\n",
    "# , 'shapley_35']:\n",
    "# for setting in ['individual_gpt4']:\n",
    "# for setting in ['individual_gpt4', 'individual_gpt4_wordrate']:\n",
    "# , 'individual_gpt4', 'individual_gpt4_wordrate']:\n",
    "\n",
    "# corrs_mask_per_question = False\n",
    "corrs_mask_per_question = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load qa weights\n",
    "subject = 'UTS02'\n",
    "corrs_df_dict = {}\n",
    "frac_voxels_to_keep_list = [0.001, 0.01, 0.05, 0.1, 0.25, 0.5, 1]\n",
    "\n",
    "# corrs used for masking\n",
    "corrs_test = joblib.load(join(PROCESSED_DIR, subject.replace(\n",
    "    'UT', ''), 'corrs_test_35.pkl')).values[0]\n",
    "corrs_test_individual_dict = joblib.load(join(PROCESSED_DIR, subject.replace(\n",
    "    'UT', ''), 'corrs_test_individual_gpt4_qs_35.pkl'))\n",
    "\n",
    "for j, frac_voxels_to_keep in enumerate(frac_voxels_to_keep_list):\n",
    "    flatmaps_qa_list = defaultdict(list)\n",
    "    for setting in settings:\n",
    "        flatmaps_qa_dict = joblib.load(\n",
    "            join(PROCESSED_DIR, subject.replace('UT', ''), setting + '.pkl'))\n",
    "        for q in flatmaps_qa_dict.keys():\n",
    "            flatmaps_qa_list[q].append(flatmaps_qa_dict[q])\n",
    "    # print('lens', [len(flatmaps_qa_list[q]) for q in flatmaps_qa_list.keys()])\n",
    "    flatmaps_qa_dict = {\n",
    "        q: np.mean(flatmaps_qa_list[q], axis=0)\n",
    "        # q: np.max(flatmaps_qa_list[q], axis=0)\n",
    "        # q: np.median(flatmaps_qa_list[q], axis=0)\n",
    "        for q in flatmaps_qa_list.keys()}\n",
    "\n",
    "    # select what to plot\n",
    "    # df_qa_dict = joblib.load(f'df_qa_dict_{subject.replace(\"UT\", \"\")}.pkl')\n",
    "    questions_names_df = pd.DataFrame({\n",
    "        'qa': qa_questions_list,\n",
    "        'gemv': gemv_questions_list,\n",
    "    })\n",
    "    # filter only questions that exist in the flatmaps\n",
    "    questions_names_df = questions_names_df[questions_names_df['qa'].isin(\n",
    "        flatmaps_qa_dict.keys())]\n",
    "\n",
    "    if isinstance(flatmaps_qa_dict, pd.DataFrame):\n",
    "        questions_names_df = questions_names_df[questions_names_df['qa'].isin(\n",
    "            flatmaps_qa_dict.index)]\n",
    "        flatmaps_qa_list = flatmaps_qa_dict.loc[questions_names_df['qa'].values]['weights'].values\n",
    "    else:\n",
    "        flatmaps_qa_list = [flatmaps_qa_dict[q]\n",
    "                            for q in questions_names_df['qa'].values]\n",
    "    flatmaps_gemv_list = [\n",
    "        gemv_flatmaps_dict[q]\n",
    "        for q in questions_names_df['gemv'].values]\n",
    "    titles_gt = questions_names_df['gemv'].apply(\n",
    "        lambda x: x[0]).astype(str)\n",
    "\n",
    "    # mask flatmaps by corr\n",
    "    # corrs_test = joblib.load(join(PROCESSED_DIR, subject.replace(\n",
    "    #     'UT', ''), 'corrs_test_35.pkl')).values[0]\n",
    "    # corrs_test_mask = (corrs_test >= np.percentile(\n",
    "    #     corrs_test, 100 * (1 - frac_voxels_to_keep))).astype(bool)\n",
    "\n",
    "    # flatmaps_qa = [flatmaps_qa[i][corrs_test_mask]\n",
    "    #                for i in range(len(flatmaps_qa))]\n",
    "    # flatmaps_gemv = [flatmaps_gemv[i][corrs_test_mask]\n",
    "    #                  for i in range(len(flatmaps_gemv))]\n",
    "\n",
    "    # mask flatmaps by extreme vals\n",
    "    for i in range(len(flatmaps_qa_list)):\n",
    "        if frac_voxels_to_keep < 1:\n",
    "            # mask based on extreme values\n",
    "            # mask = np.abs(flatmaps_qa_list[i]) >= np.percentile(\n",
    "            #     np.abs(flatmaps_qa_list[i]), 100 * (1 - frac_voxels_to_keep))\n",
    "\n",
    "            # mask based on corrs\n",
    "            if corrs_mask_per_question:\n",
    "                q = questions_names_df['qa'].values[i]\n",
    "                mask = (corrs_test_individual_dict[q] > np.percentile(\n",
    "                    corrs_test_individual_dict[q], 100 * (1 - frac_voxels_to_keep))).astype(bool)\n",
    "            else:\n",
    "                mask = (corrs_test > np.percentile(\n",
    "                    corrs_test, 100 * (1 - frac_voxels_to_keep))).astype(bool)\n",
    "        else:\n",
    "            mask = np.ones_like(flatmaps_qa_list[i]).astype(bool)\n",
    "\n",
    "        flatmaps_qa_list[i] = flatmaps_qa_list[i][mask]\n",
    "        flatmaps_gemv_list[i] = flatmaps_gemv_list[i][mask]\n",
    "\n",
    "    # # save flatmaps\n",
    "    # if frac_voxels_to_keep in [0.1, 1]:\n",
    "\n",
    "    #     # apply mask as nans\n",
    "    #     for i in range(len(flatmaps_qa)):\n",
    "    #         flatmaps_qa[i][~corrs_test_mask] = np.nan\n",
    "    #         flatmaps_gemv[i][~corrs_test_mask] = np.nan\n",
    "\n",
    "    #     for i in tqdm(range(len(flatmaps_qa))):\n",
    "    #         sasc.viz.quickshow(\n",
    "    #             flatmaps_qa[i],\n",
    "    #             subject=subject,\n",
    "    #             fname_save=join(repo_dir, 'qa_results', 'gemv', subject,\n",
    "    #                             f'frac_voxels={frac_voxels_to_keep}',\n",
    "    #                             setting, f'{titles_gt[i]}.png'),\n",
    "    #             cmap='RdYlBu_r',\n",
    "    #         )\n",
    "\n",
    "    #         sasc.viz.quickshow(\n",
    "    #             flatmaps_gemv[i],\n",
    "    #             subject=subject,\n",
    "    #             fname_save=join(repo_dir, 'qa_results', 'gemv', subject,\n",
    "    #                             f'frac_voxels={frac_voxels_to_keep}',\n",
    "    #                             'gemv', f'{titles_gt[i]}.png'),\n",
    "    #             cmap='RdYlBu_r',\n",
    "    #         )\n",
    "\n",
    "    # shuffle gemv\n",
    "    # random.shuffle(flatmaps_gemv)\n",
    "\n",
    "    # print num nas\n",
    "    # print('nas', [np.isnan(flatmaps_gemv[i]).sum()\n",
    "    #   for i in range(len(flatmaps_gemv))])\n",
    "\n",
    "    corrs_mat = viz._calc_corrs(\n",
    "        flatmaps_qa_list,\n",
    "        flatmaps_gemv_list,\n",
    "        titles_qa=[analyze_helper.abbrev_question(q)\n",
    "                   for q in questions_names_df['qa'].astype(str)],\n",
    "        titles_gt=titles_gt,\n",
    "    )\n",
    "    # corrs_df = pd.DataFrame({'corrs': np.diag(\n",
    "    # corrs.values), 'questions': corrs.columns}).sort_values('corrs', ascending=False)\n",
    "    # corrs_df_dict[frac_voxels_to_keep] = corrs_df.copy()\n",
    "    corrs_df_dict['questions'] = corrs_mat.columns\n",
    "    corrs_df_dict[f'corrs_{frac_voxels_to_keep}'] = np.diag(corrs_mat.values)\n",
    "\n",
    "\n",
    "# actually make plot\n",
    "corrs_df = pd.DataFrame(corrs_df_dict)\n",
    "corrs_df = corrs_df.sort_values('corrs_1', ascending=False)\n",
    "# corrs_df.to_pickle(join(repo_dir, 'qa_results', 'gemv',\n",
    "# setting + '_corrs_df.pkl'))\n",
    "for j, frac_voxels_to_keep in enumerate(frac_voxels_to_keep_list):\n",
    "    colors = sns.color_palette('viridis', len(frac_voxels_to_keep_list))\n",
    "    viz.corr_bars(\n",
    "        corrs_df['corrs_' + str(frac_voxels_to_keep)],\n",
    "        questions=corrs_df['questions'],\n",
    "        out_dir_save=join(repo_dir, 'qa_results', 'gemv',\n",
    "                          'corrs_' + setting),\n",
    "        xlab='GEM-V flatmap <> QA',\n",
    "        color=colors[j],\n",
    "        label=f'{frac_voxels_to_keep * 100:.2f}%',\n",
    "    )\n",
    "    # plt.savefig(join(out_dir_save, 'corrs_barplot.pdf'), bbox_inches='tight')\n",
    "    # plt.savefig(join(out_dir_save, 'corrs_barplot.png'),\n",
    "    #             bbox_inches='tight', dpi=300)\n",
    "    # plt.show()\n",
    "\n",
    "plt.title('___'.join(settings))\n",
    "# center legend text\n",
    "plt.legend(title='Fraction of\\nbest-predicted voxels',\n",
    "           labelcolor='linecolor')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(join(repo_dir, 'qa_results', 'gemv', subject, 'corrs_barplot.pdf'),\n",
    "# bbox_inches='tight')\n",
    "out_fname = 'corrs_' + '___'.join(settings)\n",
    "if corrs_mask_per_question:\n",
    "    out_fname += '_mask_per_question'\n",
    "plt.savefig(join(repo_dir, 'qa_results', 'gemv', subject, out_fname + '.pdf'),\n",
    "            bbox_inches='tight', dpi=300)\n",
    "joblib.dump(corrs_df, join(repo_dir, 'qa_results', 'gemv',\n",
    "                           subject, out_fname + '.pkl'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate results\n",
    "corrs_results_dir = join(repo_dir, 'qa_results', 'gemv', subject)\n",
    "d = defaultdict(list)\n",
    "for fname in os.listdir(corrs_results_dir):\n",
    "    if fname.startswith('corrs_') and fname.endswith('.pkl'):\n",
    "        d['setting'].append(fname.replace('corrs_', '').replace('.pkl', ''))\n",
    "        x = joblib.load(join(corrs_results_dir, fname))\n",
    "        d['corrs_df'].append(joblib.load(join(corrs_results_dir, fname)))\n",
    "        if not len(x) == len(gemv_questions_list):\n",
    "            warnings.warn(\n",
    "                'not all questions were computed for ' + str(d['setting'][-1]))\n",
    "# assert all([x.shape[0] == d['corrs_df'][0].shape[0] for x in d['corrs_df']])\n",
    "avg_df = pd.DataFrame([x.drop(columns='questions').mean(axis=0)\n",
    "                      for x in d['corrs_df']], index=d['setting'])\n",
    "avg_df = avg_df.sort_values(by='corrs_1', ascending=False)\n",
    "avg_df.style.background_gradient(cmap='viridis').format(\"{:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute p-values with eng1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frac_voxels_to_keep in tqdm(frac_voxels_to_keep_list):\n",
    "    eng1000_dir = join(PROCESSED_DIR, subject.replace(\n",
    "        'UT', ''), 'eng1000_weights.pkl')\n",
    "    pvals = viz.compute_pvals(flatmaps_qa_list, frac_voxels_to_keep,\n",
    "                              corrs_df[f'corrs_{frac_voxels_to_keep}'].values, eng1000_dir=eng1000_dir, mask_corrs=corrs_test)\n",
    "\n",
    "    # get what fraction of 'corrs_perm_eng1000' column is greater than 'corrs'\n",
    "    corrs_df[f'pval_{frac_voxels_to_keep}'] = pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add average row\n",
    "corrs_viz = corrs_df.set_index('questions').sort_values(\n",
    "    by='pval_0.001')\n",
    "# by='corrs_1')\n",
    "corrs_viz.loc['AVG'] = corrs_viz.mean()\n",
    "corrs_viz.loc['AVG_FIRST10'] = corrs_viz.head(10).mean()\n",
    "\n",
    "# format scientific notation\n",
    "print('___'.join(settings))\n",
    "corrs_viz.style.background_gradient().format(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ridge_utils.SemanticModel import SemanticModel\n",
    "from neuro.config import em_data_dir\n",
    "eng1000 = SemanticModel.load(join(em_data_dir, \"english1000sm.hf5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index_dict = eng1000.vindex\n",
    "\n",
    "index_to_wordlist_dict = defaultdict(list)\n",
    "for k, v in word_to_index_dict.items():\n",
    "    index_to_wordlist_dict[v].append(k.decode())\n",
    "# check if all lists are length 1\n",
    "assert all([len(v) == 1 for v in index_to_wordlist_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list_985 = list(word_to_index_dict.keys())\n",
    "dog_vec = eng1000['dog'.encode()]\n",
    "words_list_985[np.argmax(dog_vec) + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in corrs_viz.index.values[:-2]:\n",
    "    first_word = k.split()[0]\n",
    "    if first_word.endswith('s'):\n",
    "        first_word = first_word[:-1]\n",
    "    rename = {\n",
    "        'measurement': 'measure',\n",
    "        'dialogue': 'talk',\n",
    "        'sensory': 'sense',\n",
    "        'negation': 'negative',\n",
    "        'cultural': 'culture',\n",
    "    }\n",
    "    first_word = rename.get(first_word, first_word)\n",
    "\n",
    "    print(k, '--', first_word,\n",
    "          eng1000.find_words_like_word(first_word.encode(), n=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at merged flatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_df = pd.read_pickle(join(repo_dir, 'qa_results', 'gemv',\n",
    "                               setting + '_corrs_df.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_parent_dir = join(repo_dir, 'qa_results', 'gemv',\n",
    "                      subject, 'frac_voxels=0.1')\n",
    "img_dir1 = join(img_parent_dir, 'gemv')\n",
    "img_dir2 = join(img_parent_dir, setting)\n",
    "\n",
    "# read images and combine them with their filenames on a single plot\n",
    "# fnames = os.listdir(img_dir1)\n",
    "# fnames = [f for f in fnames if f.endswith('.png')]\n",
    "# only keep the ones that are in both directories\n",
    "# fnames = [f for f in fnames if f in os.listdir(img_dir2)]\n",
    "\n",
    "\n",
    "# corrs = corrs.sort_values('corrs', ascending=False)\n",
    "fnames = [v + '.png' for v in corrs_df['questions'].values]\n",
    "\n",
    "n = len(fnames)\n",
    "C = 4\n",
    "R = int(np.ceil(n / C))\n",
    "\n",
    "fig, axs = plt.subplots(R, C, figsize=(C * 3.2, R * 1))\n",
    "axs = axs.flatten()\n",
    "for i in range(len(axs)):\n",
    "    axs[i].axis('off')\n",
    "for i, fname in enumerate(fnames):\n",
    "    img1 = plt.imread(join(img_dir1, fname))\n",
    "    img2 = plt.imread(join(img_dir2, fname))\n",
    "    axs[i].imshow(np.concatenate([img1, img2], axis=1))\n",
    "    axs[i].set_title(\n",
    "        f'{fname[:-4]} ({corrs_df[\"corrs\"].values[i]:0.3f})', fontsize=8)\n",
    "\n",
    "# add text in bottom right of figure\n",
    "fig.text(0.99, 0.01, f'{subject}\\nGEMV on left, QA on right',\n",
    "         ha='right', va='bottom', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(join(img_parent_dir, f'flatmaps_{setting}_{subject}.png'), dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
