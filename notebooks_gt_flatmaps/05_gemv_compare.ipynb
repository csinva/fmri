{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cortex\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import dvu\n",
    "from neuro.flatmaps_helper import load_flatmaps\n",
    "from neuro.features.questions.gpt4 import QS_35_STABLE\n",
    "import sys\n",
    "import warnings\n",
    "sys.path.append('../notebooks')\n",
    "from tqdm import tqdm\n",
    "from sasc.config import FMRI_DIR, STORIES_DIR, RESULTS_DIR\n",
    "from neuro.config import repo_dir, PROCESSED_DIR\n",
    "from neuro import analyze_helper, viz\n",
    "from neuro.features.qa_questions import get_questions, get_merged_questions_v3_boostexamples\n",
    "# flatmaps_per_question = __import__('06_flatmaps_per_question')\n",
    "import viz\n",
    "import gemv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, this notebook requires first running `03_export_qa_flatmaps.ipynb` into `df_qa_dict.pkl` files for each subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load gemv average flatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gemv_flatmaps_dict_S02' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlist\u001b[39m(\u001b[43mgemv_flatmaps_dict_S02\u001b[49m\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gemv_flatmaps_dict_S02' is not defined"
     ]
    }
   ],
   "source": [
    "list(gemv_flatmaps_dict_S02.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in QS_35_STABLE:\n",
    "    if not q in qa_questions_list:\n",
    "        print(\"'\" + q + \"'\" + ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemv_flatmaps_dict_S02, gemv_flatmaps_dict_S03 = load_flatmaps(\n",
    "    normalize_flatmaps=False, load_timecourse=False)\n",
    "# gemv_flatmaps_pilot | gemv_flatmaps_pilot5\n",
    "gemv_flatmaps_dict = gemv_flatmaps_dict_S02\n",
    "qa_questions_list, gemv_questions_list = gemv.get_matched_lists()\n",
    "assert len(qa_questions_list) == len(gemv_questions_list)\n",
    "assert len(qa_questions_list) == 35\n",
    "\n",
    "# # check that gpt4 was run for all the questions\n",
    "# subject = 'UTS02'\n",
    "# setting = 'individual_gpt4'\n",
    "# flatmaps_qa = joblib.load(\n",
    "#     join(PROCESSED_DIR, subject.replace('UT', ''), setting + '.pkl'))\n",
    "# for k in qa_list:\n",
    "#     assert k in flatmaps_qa.keys()\n",
    "\n",
    "# settings = ['full_35']\n",
    "# settings = ['full_35_wordrate']\n",
    "# settings = ['full_35_pc']\n",
    "# settings = ['full_neurosynth']\n",
    "# settings = ['full_35_gpt4_pc']\n",
    "# settings = ['individual_gpt4_pc']\n",
    "# settings = ['shapley_35_gpt4_pc']\n",
    "# settings = ['shapley_35', 'individual_gpt4_pc', 'shapley_35_gpt4_pc']\n",
    "# settings = ['individual_gpt4_ndel=1_pc']\n",
    "# settings = ['full_35_gpt4_ndel=1_pc']\n",
    "# settings = ['full_35_ndel=8_pc']\n",
    "# settings = ['full_35', 'full_35_wordrate']\n",
    "# settings = ['individual_gpt4', 'individual_gpt4_wordrate',]\n",
    "settings = ['individual_gpt4', 'individual_gpt4_wordrate', 'shapley_35']\n",
    "# settings = ['shapley_35']\n",
    "# settings = ['individual_35']\n",
    "# settings = ['individual_gpt4']\n",
    "# , 'individual_35', full_35', 'shapley_35', 'individual_gpt4',\n",
    "# for setting in ['individual_gpt4', 'shapley_35']:\n",
    "# for setting in ['individual_gpt4', 'individual_gpt4_wordrate']:\n",
    "# , 'shapley_35']:\n",
    "# for setting in ['individual_gpt4']:\n",
    "# for setting in ['individual_gpt4', 'individual_gpt4_wordrate']:\n",
    "# , 'individual_gpt4', 'individual_gpt4_wordrate']:\n",
    "\n",
    "# corrs_mask_per_question = False\n",
    "corrs_mask_per_question = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load qa weights\n",
    "subject = 'UTS02'\n",
    "corrs_df_dict = {}\n",
    "frac_voxels_to_keep_list = [0.01, 0.05, 0.1, 0.25, 0.5, 1]\n",
    "\n",
    "# corrs used for masking\n",
    "corrs_test = joblib.load(join(PROCESSED_DIR, subject.replace(\n",
    "    'UT', ''), 'corrs_test_35.pkl')).values[0]\n",
    "corrs_test_individual_dict = joblib.load(join(PROCESSED_DIR, subject.replace(\n",
    "    'UT', ''), 'corrs_test_individual_gpt4_qs_35.pkl'))\n",
    "\n",
    "for j, frac_voxels_to_keep in enumerate(frac_voxels_to_keep_list):\n",
    "    flatmaps_qa_list = defaultdict(list)\n",
    "    for setting in settings:\n",
    "        flatmaps_qa_dict = joblib.load(\n",
    "            join(PROCESSED_DIR, subject.replace('UT', ''), setting + '.pkl'))\n",
    "        for q in flatmaps_qa_dict.keys():\n",
    "            flatmaps_qa_list[q].append(flatmaps_qa_dict[q])\n",
    "    # print('lens', [len(flatmaps_qa_list[q]) for q in flatmaps_qa_list.keys()])\n",
    "    flatmaps_qa_dict = {\n",
    "        q: np.mean(flatmaps_qa_list[q], axis=0)\n",
    "        # q: np.max(flatmaps_qa_list[q], axis=0)\n",
    "        # q: np.median(flatmaps_qa_list[q], axis=0)\n",
    "        for q in flatmaps_qa_list.keys()}\n",
    "\n",
    "    # select what to plot\n",
    "    # df_qa_dict = joblib.load(f'df_qa_dict_{subject.replace(\"UT\", \"\")}.pkl')\n",
    "    questions_names_df = pd.DataFrame({\n",
    "        'qa': qa_questions_list,\n",
    "        'gemv': gemv_questions_list,\n",
    "    })\n",
    "    # filter only questions that exist in the flatmaps\n",
    "    questions_names_df = questions_names_df[questions_names_df['qa'].isin(\n",
    "        flatmaps_qa_dict.keys())]\n",
    "\n",
    "    if isinstance(flatmaps_qa_dict, pd.DataFrame):\n",
    "        questions_names_df = questions_names_df[questions_names_df['qa'].isin(\n",
    "            flatmaps_qa_dict.index)]\n",
    "        flatmaps_qa_list = flatmaps_qa_dict.loc[questions_names_df['qa'].values]['weights'].values\n",
    "    else:\n",
    "        flatmaps_qa_list = [flatmaps_qa_dict[q]\n",
    "                            for q in questions_names_df['qa'].values]\n",
    "    flatmaps_gemv_list = [\n",
    "        gemv_flatmaps_dict[q]\n",
    "        for q in questions_names_df['gemv'].values]\n",
    "    titles_gt = questions_names_df['gemv'].apply(\n",
    "        lambda x: x[0]).astype(str)\n",
    "\n",
    "    # mask flatmaps by corr\n",
    "    # corrs_test = joblib.load(join(PROCESSED_DIR, subject.replace(\n",
    "    #     'UT', ''), 'corrs_test_35.pkl')).values[0]\n",
    "    # corrs_test_mask = (corrs_test >= np.percentile(\n",
    "    #     corrs_test, 100 * (1 - frac_voxels_to_keep))).astype(bool)\n",
    "\n",
    "    # flatmaps_qa = [flatmaps_qa[i][corrs_test_mask]\n",
    "    #                for i in range(len(flatmaps_qa))]\n",
    "    # flatmaps_gemv = [flatmaps_gemv[i][corrs_test_mask]\n",
    "    #                  for i in range(len(flatmaps_gemv))]\n",
    "\n",
    "    # mask flatmaps by extreme vals\n",
    "    for i in range(len(flatmaps_qa_list)):\n",
    "        if frac_voxels_to_keep < 1:\n",
    "            # mask based on extreme values\n",
    "            # mask = np.abs(flatmaps_qa_list[i]) >= np.percentile(\n",
    "            #     np.abs(flatmaps_qa_list[i]), 100 * (1 - frac_voxels_to_keep))\n",
    "\n",
    "            # mask based on corrs\n",
    "            if corrs_mask_per_question:\n",
    "                q = questions_names_df['qa'].values[i]\n",
    "                mask = (corrs_test_individual_dict[q] > np.percentile(\n",
    "                    corrs_test_individual_dict[q], 100 * (1 - frac_voxels_to_keep))).astype(bool)\n",
    "            else:\n",
    "                mask = (corrs_test > np.percentile(\n",
    "                    corrs_test, 100 * (1 - frac_voxels_to_keep))).astype(bool)\n",
    "        else:\n",
    "            mask = np.ones_like(flatmaps_qa_list[i]).astype(bool)\n",
    "\n",
    "        flatmaps_qa_list[i] = flatmaps_qa_list[i][mask]\n",
    "        flatmaps_gemv_list[i] = flatmaps_gemv_list[i][mask]\n",
    "\n",
    "    # # save flatmaps\n",
    "    # if frac_voxels_to_keep in [0.1, 1]:\n",
    "\n",
    "    #     # apply mask as nans\n",
    "    #     for i in range(len(flatmaps_qa)):\n",
    "    #         flatmaps_qa[i][~corrs_test_mask] = np.nan\n",
    "    #         flatmaps_gemv[i][~corrs_test_mask] = np.nan\n",
    "\n",
    "    #     for i in tqdm(range(len(flatmaps_qa))):\n",
    "    #         sasc.viz.quickshow(\n",
    "    #             flatmaps_qa[i],\n",
    "    #             subject=subject,\n",
    "    #             fname_save=join(repo_dir, 'qa_results', 'gemv', subject,\n",
    "    #                             f'frac_voxels={frac_voxels_to_keep}',\n",
    "    #                             setting, f'{titles_gt[i]}.png'),\n",
    "    #             cmap='RdYlBu_r',\n",
    "    #         )\n",
    "\n",
    "    #         sasc.viz.quickshow(\n",
    "    #             flatmaps_gemv[i],\n",
    "    #             subject=subject,\n",
    "    #             fname_save=join(repo_dir, 'qa_results', 'gemv', subject,\n",
    "    #                             f'frac_voxels={frac_voxels_to_keep}',\n",
    "    #                             'gemv', f'{titles_gt[i]}.png'),\n",
    "    #             cmap='RdYlBu_r',\n",
    "    #         )\n",
    "\n",
    "    # shuffle gemv\n",
    "    # random.shuffle(flatmaps_gemv)\n",
    "\n",
    "    # print num nas\n",
    "    # print('nas', [np.isnan(flatmaps_gemv[i]).sum()\n",
    "    #   for i in range(len(flatmaps_gemv))])\n",
    "\n",
    "    corrs_mat = viz._calc_corrs(\n",
    "        flatmaps_qa_list,\n",
    "        flatmaps_gemv_list,\n",
    "        titles_qa=[analyze_helper.abbrev_question(q)\n",
    "                   for q in questions_names_df['qa'].astype(str)],\n",
    "        titles_gt=titles_gt,\n",
    "    )\n",
    "    # corrs_df = pd.DataFrame({'corrs': np.diag(\n",
    "    # corrs.values), 'questions': corrs.columns}).sort_values('corrs', ascending=False)\n",
    "    # corrs_df_dict[frac_voxels_to_keep] = corrs_df.copy()\n",
    "    # corrs_df_dict['questions'] = corrs_mat.columns\n",
    "    corrs_df_dict['questions'] = [analyze_helper.abbrev_question(\n",
    "        q) for q in questions_names_df['qa'].values]\n",
    "    corrs_df_dict[f'corrs_{frac_voxels_to_keep}'] = np.diag(corrs_mat.values)\n",
    "\n",
    "\n",
    "# actually make plot\n",
    "corrs_df = pd.DataFrame(corrs_df_dict)\n",
    "corrs_df = corrs_df.sort_values('corrs_1', ascending=False)\n",
    "# corrs_df.to_pickle(join(repo_dir, 'qa_results', 'gemv',\n",
    "# setting + '_corrs_df.pkl'))\n",
    "for j, frac_voxels_to_keep in enumerate(frac_voxels_to_keep_list):\n",
    "    colors = sns.color_palette('viridis', len(frac_voxels_to_keep_list))\n",
    "    viz.corr_bars(\n",
    "        corrs_df['corrs_' + str(frac_voxels_to_keep)],\n",
    "        questions=corrs_df['questions'],\n",
    "        out_dir_save=join(repo_dir, 'qa_results', 'gemv',\n",
    "                          'corrs_' + setting),\n",
    "        xlab='Correlation between GEM-V scores and QA coefficients',\n",
    "        color=colors[j],\n",
    "        label=f'{frac_voxels_to_keep * 100:.2f}%',\n",
    "    )\n",
    "    # plt.savefig(join(out_dir_save, 'corrs_barplot.pdf'), bbox_inches='tight')\n",
    "    # plt.savefig(join(out_dir_save, 'corrs_barplot.png'),\n",
    "    #             bbox_inches='tight', dpi=300)\n",
    "    # plt.show()\n",
    "\n",
    "plt.title('___'.join(settings))\n",
    "# center legend text\n",
    "plt.legend(title='Fraction of\\nbest-predicted voxels',\n",
    "           labelcolor='linecolor')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(join(repo_dir, 'qa_results', 'gemv', subject, 'corrs_barplot.pdf'),\n",
    "# bbox_inches='tight')\n",
    "out_fname = 'corrs_' + '___'.join(settings)\n",
    "if corrs_mask_per_question:\n",
    "    out_fname += '_mask_per_question'\n",
    "plt.savefig(join(repo_dir, 'qa_results', 'gemv', subject, out_fname + '.pdf'),\n",
    "            bbox_inches='tight', dpi=300)\n",
    "joblib.dump(corrs_df, join(repo_dir, 'qa_results', 'gemv',\n",
    "                           subject, out_fname + '.pkl'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>corrs_0.01</th>\n",
       "      <th>corrs_0.05</th>\n",
       "      <th>corrs_0.1</th>\n",
       "      <th>corrs_0.25</th>\n",
       "      <th>corrs_0.5</th>\n",
       "      <th>corrs_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Is the input related to a specific industry or...</td>\n",
       "      <td>0.484911</td>\n",
       "      <td>0.545333</td>\n",
       "      <td>0.533160</td>\n",
       "      <td>0.484740</td>\n",
       "      <td>0.426602</td>\n",
       "      <td>0.356287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Does the input contain a measurement?</td>\n",
       "      <td>0.646869</td>\n",
       "      <td>0.581266</td>\n",
       "      <td>0.526034</td>\n",
       "      <td>0.434947</td>\n",
       "      <td>0.354679</td>\n",
       "      <td>0.293160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Does the sentence mention a specific location?</td>\n",
       "      <td>0.727854</td>\n",
       "      <td>0.617503</td>\n",
       "      <td>0.549756</td>\n",
       "      <td>0.445887</td>\n",
       "      <td>0.361092</td>\n",
       "      <td>0.288093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Does the sentence include a direct speech quot...</td>\n",
       "      <td>0.621610</td>\n",
       "      <td>0.605002</td>\n",
       "      <td>0.580742</td>\n",
       "      <td>0.476051</td>\n",
       "      <td>0.361910</td>\n",
       "      <td>0.282815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Does the input contain a number?</td>\n",
       "      <td>0.646063</td>\n",
       "      <td>0.520113</td>\n",
       "      <td>0.469545</td>\n",
       "      <td>0.430197</td>\n",
       "      <td>0.365070</td>\n",
       "      <td>0.279039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Does the sentence include dialogue?</td>\n",
       "      <td>0.606055</td>\n",
       "      <td>0.556876</td>\n",
       "      <td>0.525724</td>\n",
       "      <td>0.428355</td>\n",
       "      <td>0.327143</td>\n",
       "      <td>0.259636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Does the sentence describe a specific sensatio...</td>\n",
       "      <td>0.449804</td>\n",
       "      <td>0.377581</td>\n",
       "      <td>0.341750</td>\n",
       "      <td>0.321860</td>\n",
       "      <td>0.307877</td>\n",
       "      <td>0.259555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Does the text describe a journey?</td>\n",
       "      <td>0.627821</td>\n",
       "      <td>0.555213</td>\n",
       "      <td>0.507804</td>\n",
       "      <td>0.415940</td>\n",
       "      <td>0.326513</td>\n",
       "      <td>0.247556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Does the text describe a mode of communication?</td>\n",
       "      <td>0.607142</td>\n",
       "      <td>0.505605</td>\n",
       "      <td>0.441113</td>\n",
       "      <td>0.340346</td>\n",
       "      <td>0.278727</td>\n",
       "      <td>0.225469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Does the sentence contain a cultural reference?</td>\n",
       "      <td>0.156362</td>\n",
       "      <td>0.304745</td>\n",
       "      <td>0.348302</td>\n",
       "      <td>0.325171</td>\n",
       "      <td>0.271822</td>\n",
       "      <td>0.221440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Does the sentence describe a relationship betw...</td>\n",
       "      <td>0.500309</td>\n",
       "      <td>0.367959</td>\n",
       "      <td>0.320708</td>\n",
       "      <td>0.281189</td>\n",
       "      <td>0.232698</td>\n",
       "      <td>0.189702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Does the sentence involve the mention of a spe...</td>\n",
       "      <td>0.399401</td>\n",
       "      <td>0.321759</td>\n",
       "      <td>0.259131</td>\n",
       "      <td>0.230835</td>\n",
       "      <td>0.229931</td>\n",
       "      <td>0.186723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Does the sentence describe a physical action?</td>\n",
       "      <td>0.694032</td>\n",
       "      <td>0.581767</td>\n",
       "      <td>0.519820</td>\n",
       "      <td>0.390529</td>\n",
       "      <td>0.258831</td>\n",
       "      <td>0.183735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Does the sentence describe a personal or socia...</td>\n",
       "      <td>0.382658</td>\n",
       "      <td>0.292367</td>\n",
       "      <td>0.237553</td>\n",
       "      <td>0.183249</td>\n",
       "      <td>0.181110</td>\n",
       "      <td>0.177918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is time mentioned in the input?</td>\n",
       "      <td>0.258939</td>\n",
       "      <td>0.273387</td>\n",
       "      <td>0.288136</td>\n",
       "      <td>0.239685</td>\n",
       "      <td>0.199983</td>\n",
       "      <td>0.166219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Does the sentence contain a proper noun?</td>\n",
       "      <td>0.246407</td>\n",
       "      <td>0.292184</td>\n",
       "      <td>0.286228</td>\n",
       "      <td>0.250215</td>\n",
       "      <td>0.204533</td>\n",
       "      <td>0.161926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Does the sentence involve an expression of per...</td>\n",
       "      <td>0.393577</td>\n",
       "      <td>0.313597</td>\n",
       "      <td>0.276689</td>\n",
       "      <td>0.239763</td>\n",
       "      <td>0.210145</td>\n",
       "      <td>0.158149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Does the sentence describe a physical sensation?</td>\n",
       "      <td>0.540293</td>\n",
       "      <td>0.472593</td>\n",
       "      <td>0.437672</td>\n",
       "      <td>0.335129</td>\n",
       "      <td>0.223998</td>\n",
       "      <td>0.157611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Does the sentence involve a discussion about p...</td>\n",
       "      <td>0.418238</td>\n",
       "      <td>0.367669</td>\n",
       "      <td>0.333175</td>\n",
       "      <td>0.268383</td>\n",
       "      <td>0.217696</td>\n",
       "      <td>0.154480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Does the sentence include a personal anecdote ...</td>\n",
       "      <td>0.304922</td>\n",
       "      <td>0.278082</td>\n",
       "      <td>0.276042</td>\n",
       "      <td>0.247969</td>\n",
       "      <td>0.196702</td>\n",
       "      <td>0.150462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Does the sentence include technical or special...</td>\n",
       "      <td>0.294934</td>\n",
       "      <td>0.303188</td>\n",
       "      <td>0.289194</td>\n",
       "      <td>0.231703</td>\n",
       "      <td>0.177004</td>\n",
       "      <td>0.129709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Does the sentence describe a visual experience...</td>\n",
       "      <td>0.678506</td>\n",
       "      <td>0.528101</td>\n",
       "      <td>0.460606</td>\n",
       "      <td>0.309042</td>\n",
       "      <td>0.178697</td>\n",
       "      <td>0.127574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Does the input involve planning or organizing?</td>\n",
       "      <td>0.374601</td>\n",
       "      <td>0.319742</td>\n",
       "      <td>0.289270</td>\n",
       "      <td>0.239573</td>\n",
       "      <td>0.179181</td>\n",
       "      <td>0.126110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Does the sentence involve a description of phy...</td>\n",
       "      <td>0.642325</td>\n",
       "      <td>0.497808</td>\n",
       "      <td>0.411339</td>\n",
       "      <td>0.260947</td>\n",
       "      <td>0.156688</td>\n",
       "      <td>0.121806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Does the sentence express the narrator's opini...</td>\n",
       "      <td>0.409500</td>\n",
       "      <td>0.356010</td>\n",
       "      <td>0.303075</td>\n",
       "      <td>0.201376</td>\n",
       "      <td>0.146945</td>\n",
       "      <td>0.115023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Does the sentence involve spatial reasoning?</td>\n",
       "      <td>0.554937</td>\n",
       "      <td>0.366319</td>\n",
       "      <td>0.290194</td>\n",
       "      <td>0.207672</td>\n",
       "      <td>0.157065</td>\n",
       "      <td>0.114208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Does the sentence describe a personal reflecti...</td>\n",
       "      <td>0.421834</td>\n",
       "      <td>0.338459</td>\n",
       "      <td>0.282413</td>\n",
       "      <td>0.210979</td>\n",
       "      <td>0.151929</td>\n",
       "      <td>0.111047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Does the sentence describe a sensory experience?</td>\n",
       "      <td>0.455272</td>\n",
       "      <td>0.371983</td>\n",
       "      <td>0.328381</td>\n",
       "      <td>0.216387</td>\n",
       "      <td>0.133540</td>\n",
       "      <td>0.106076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Is the sentence reflective, involving self-ana...</td>\n",
       "      <td>0.440951</td>\n",
       "      <td>0.343879</td>\n",
       "      <td>0.286116</td>\n",
       "      <td>0.200599</td>\n",
       "      <td>0.136003</td>\n",
       "      <td>0.099210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Does the sentence contain a negation?</td>\n",
       "      <td>0.330453</td>\n",
       "      <td>0.197996</td>\n",
       "      <td>0.158529</td>\n",
       "      <td>0.127444</td>\n",
       "      <td>0.111052</td>\n",
       "      <td>0.083712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Does the input describe a specific texture or ...</td>\n",
       "      <td>0.439712</td>\n",
       "      <td>0.299000</td>\n",
       "      <td>0.222199</td>\n",
       "      <td>0.148712</td>\n",
       "      <td>0.110043</td>\n",
       "      <td>0.082586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Does the text include a planning or decision-m...</td>\n",
       "      <td>0.183607</td>\n",
       "      <td>0.194110</td>\n",
       "      <td>0.195683</td>\n",
       "      <td>0.172478</td>\n",
       "      <td>0.119936</td>\n",
       "      <td>0.082575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Does the sentence express a sense of belonging...</td>\n",
       "      <td>0.099826</td>\n",
       "      <td>0.122875</td>\n",
       "      <td>0.127037</td>\n",
       "      <td>0.077909</td>\n",
       "      <td>0.059128</td>\n",
       "      <td>0.048417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Does the input include a comparison or metaphor?</td>\n",
       "      <td>0.060655</td>\n",
       "      <td>0.060779</td>\n",
       "      <td>0.036342</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.018243</td>\n",
       "      <td>-0.022928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is the sentence abstract rather than concrete?</td>\n",
       "      <td>-0.209527</td>\n",
       "      <td>-0.070174</td>\n",
       "      <td>-0.046900</td>\n",
       "      <td>-0.077404</td>\n",
       "      <td>-0.098313</td>\n",
       "      <td>-0.080965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            questions  corrs_0.01  corrs_0.05  \\\n",
       "7   Is the input related to a specific industry or...    0.484911    0.545333   \n",
       "1               Does the input contain a measurement?    0.646869    0.581266   \n",
       "2      Does the sentence mention a specific location?    0.727854    0.617503   \n",
       "32  Does the sentence include a direct speech quot...    0.621610    0.605002   \n",
       "9                    Does the input contain a number?    0.646063    0.520113   \n",
       "6                 Does the sentence include dialogue?    0.606055    0.556876   \n",
       "26  Does the sentence describe a specific sensatio...    0.449804    0.377581   \n",
       "30                  Does the text describe a journey?    0.627821    0.555213   \n",
       "3     Does the text describe a mode of communication?    0.607142    0.505605   \n",
       "5     Does the sentence contain a cultural reference?    0.156362    0.304745   \n",
       "17  Does the sentence describe a relationship betw...    0.500309    0.367959   \n",
       "19  Does the sentence involve the mention of a spe...    0.399401    0.321759   \n",
       "14      Does the sentence describe a physical action?    0.694032    0.581767   \n",
       "11  Does the sentence describe a personal or socia...    0.382658    0.292367   \n",
       "0                     Is time mentioned in the input?    0.258939    0.273387   \n",
       "16           Does the sentence contain a proper noun?    0.246407    0.292184   \n",
       "13  Does the sentence involve an expression of per...    0.393577    0.313597   \n",
       "31   Does the sentence describe a physical sensation?    0.540293    0.472593   \n",
       "29  Does the sentence involve a discussion about p...    0.418238    0.367669   \n",
       "28  Does the sentence include a personal anecdote ...    0.304922    0.278082   \n",
       "20  Does the sentence include technical or special...    0.294934    0.303188   \n",
       "22  Does the sentence describe a visual experience...    0.678506    0.528101   \n",
       "15     Does the input involve planning or organizing?    0.374601    0.319742   \n",
       "21  Does the sentence involve a description of phy...    0.642325    0.497808   \n",
       "10  Does the sentence express the narrator's opini...    0.409500    0.356010   \n",
       "23       Does the sentence involve spatial reasoning?    0.554937    0.366319   \n",
       "12  Does the sentence describe a personal reflecti...    0.421834    0.338459   \n",
       "18   Does the sentence describe a sensory experience?    0.455272    0.371983   \n",
       "33  Is the sentence reflective, involving self-ana...    0.440951    0.343879   \n",
       "8               Does the sentence contain a negation?    0.330453    0.197996   \n",
       "34  Does the input describe a specific texture or ...    0.439712    0.299000   \n",
       "27  Does the text include a planning or decision-m...    0.183607    0.194110   \n",
       "25  Does the sentence express a sense of belonging...    0.099826    0.122875   \n",
       "24   Does the input include a comparison or metaphor?    0.060655    0.060779   \n",
       "4      Is the sentence abstract rather than concrete?   -0.209527   -0.070174   \n",
       "\n",
       "    corrs_0.1  corrs_0.25  corrs_0.5   corrs_1  \n",
       "7    0.533160    0.484740   0.426602  0.356287  \n",
       "1    0.526034    0.434947   0.354679  0.293160  \n",
       "2    0.549756    0.445887   0.361092  0.288093  \n",
       "32   0.580742    0.476051   0.361910  0.282815  \n",
       "9    0.469545    0.430197   0.365070  0.279039  \n",
       "6    0.525724    0.428355   0.327143  0.259636  \n",
       "26   0.341750    0.321860   0.307877  0.259555  \n",
       "30   0.507804    0.415940   0.326513  0.247556  \n",
       "3    0.441113    0.340346   0.278727  0.225469  \n",
       "5    0.348302    0.325171   0.271822  0.221440  \n",
       "17   0.320708    0.281189   0.232698  0.189702  \n",
       "19   0.259131    0.230835   0.229931  0.186723  \n",
       "14   0.519820    0.390529   0.258831  0.183735  \n",
       "11   0.237553    0.183249   0.181110  0.177918  \n",
       "0    0.288136    0.239685   0.199983  0.166219  \n",
       "16   0.286228    0.250215   0.204533  0.161926  \n",
       "13   0.276689    0.239763   0.210145  0.158149  \n",
       "31   0.437672    0.335129   0.223998  0.157611  \n",
       "29   0.333175    0.268383   0.217696  0.154480  \n",
       "28   0.276042    0.247969   0.196702  0.150462  \n",
       "20   0.289194    0.231703   0.177004  0.129709  \n",
       "22   0.460606    0.309042   0.178697  0.127574  \n",
       "15   0.289270    0.239573   0.179181  0.126110  \n",
       "21   0.411339    0.260947   0.156688  0.121806  \n",
       "10   0.303075    0.201376   0.146945  0.115023  \n",
       "23   0.290194    0.207672   0.157065  0.114208  \n",
       "12   0.282413    0.210979   0.151929  0.111047  \n",
       "18   0.328381    0.216387   0.133540  0.106076  \n",
       "33   0.286116    0.200599   0.136003  0.099210  \n",
       "8    0.158529    0.127444   0.111052  0.083712  \n",
       "34   0.222199    0.148712   0.110043  0.082586  \n",
       "27   0.195683    0.172478   0.119936  0.082575  \n",
       "25   0.127037    0.077909   0.059128  0.048417  \n",
       "24   0.036342    0.000191  -0.018243 -0.022928  \n",
       "4   -0.046900   -0.077404  -0.098313 -0.080965  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3580036/3664055931.py:10: UserWarning: not all questions were computed for full_35_gpt4_ndel=1_pc\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_3580036/3664055931.py:10: UserWarning: not all questions were computed for full_35_wordrate\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_3580036/3664055931.py:10: UserWarning: not all questions were computed for individual_gpt4_pc_mask_per_question\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_3580036/3664055931.py:10: UserWarning: not all questions were computed for full_neurosynth\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_3580036/3664055931.py:10: UserWarning: not all questions were computed for full_35_gpt4_pc\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_3580036/3664055931.py:10: UserWarning: not all questions were computed for full_35_gpt4_pc___individual_gpt4_pc___shapley_35_gpt4_pc\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_3580036/3664055931.py:10: UserWarning: not all questions were computed for individual_gpt4\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_3580036/3664055931.py:10: UserWarning: not all questions were computed for full_35_ndel=8_pc\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_3580036/3664055931.py:10: UserWarning: not all questions were computed for shapley_35_gpt4_pc\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_3580036/3664055931.py:10: UserWarning: not all questions were computed for individual_gpt4_ndel=1_pc\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_3580036/3664055931.py:10: UserWarning: not all questions were computed for individual_gpt4_pc\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_3580036/3664055931.py:10: UserWarning: not all questions were computed for individual_gpt4___individual_gpt4_wordrate\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_3580036/3664055931.py:10: UserWarning: not all questions were computed for individual_35\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_3580036/3664055931.py:10: UserWarning: not all questions were computed for shapley_35\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_3580036/3664055931.py:10: UserWarning: not all questions were computed for full_35_pc\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_3580036/3664055931.py:10: UserWarning: not all questions were computed for full_35\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_3580036/3664055931.py:10: UserWarning: not all questions were computed for shapley_35___individual_gpt4_pc___shapley_35_gpt4_pc\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5ab76_row0_col0, #T_5ab76_row3_col0, #T_5ab76_row17_col0, #T_5ab76_row17_col1, #T_5ab76_row17_col2, #T_5ab76_row17_col3, #T_5ab76_row17_col4, #T_5ab76_row17_col5, #T_5ab76_row17_col6 {\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row0_col1, #T_5ab76_row0_col2, #T_5ab76_row0_col3, #T_5ab76_row0_col4, #T_5ab76_row0_col5, #T_5ab76_row0_col6, #T_5ab76_row2_col0 {\n",
       "  background-color: #fde725;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row1_col0 {\n",
       "  background-color: #f6e620;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row1_col1, #T_5ab76_row7_col0 {\n",
       "  background-color: #98d83e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row1_col2 {\n",
       "  background-color: #7cd250;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row1_col3, #T_5ab76_row2_col4, #T_5ab76_row3_col3 {\n",
       "  background-color: #6ece58;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row1_col4, #T_5ab76_row1_col5, #T_5ab76_row4_col1, #T_5ab76_row7_col1, #T_5ab76_row10_col0 {\n",
       "  background-color: #65cb5e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row1_col6, #T_5ab76_row7_col2 {\n",
       "  background-color: #69cd5b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row2_col1 {\n",
       "  background-color: #95d840;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row2_col2, #T_5ab76_row3_col1 {\n",
       "  background-color: #89d548;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row2_col3 {\n",
       "  background-color: #7fd34e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row2_col5, #T_5ab76_row3_col4 {\n",
       "  background-color: #63cb5f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row2_col6, #T_5ab76_row9_col3 {\n",
       "  background-color: #60ca60;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row3_col2 {\n",
       "  background-color: #7ad151;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row3_col5, #T_5ab76_row3_col6, #T_5ab76_row5_col3 {\n",
       "  background-color: #5ec962;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row4_col0 {\n",
       "  background-color: #d0e11c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row4_col2, #T_5ab76_row5_col5, #T_5ab76_row6_col6, #T_5ab76_row7_col6 {\n",
       "  background-color: #4cc26c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row4_col3 {\n",
       "  background-color: #3fbc73;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row4_col4, #T_5ab76_row8_col4, #T_5ab76_row8_col5 {\n",
       "  background-color: #3dbc74;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row4_col5 {\n",
       "  background-color: #46c06f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row4_col6, #T_5ab76_row5_col4, #T_5ab76_row7_col4 {\n",
       "  background-color: #52c569;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row5_col0 {\n",
       "  background-color: #f4e61e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row5_col1 {\n",
       "  background-color: #86d549;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row5_col2, #T_5ab76_row6_col3, #T_5ab76_row8_col1 {\n",
       "  background-color: #6ccd5a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row5_col6, #T_5ab76_row8_col2 {\n",
       "  background-color: #4ec36b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row6_col0 {\n",
       "  background-color: #ece51b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row6_col1 {\n",
       "  background-color: #8bd646;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row6_col2 {\n",
       "  background-color: #77d153;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row6_col4 {\n",
       "  background-color: #5ac864;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row6_col5 {\n",
       "  background-color: #50c46a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row7_col3, #T_5ab76_row7_col5 {\n",
       "  background-color: #5cc863;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row8_col0 {\n",
       "  background-color: #d8e219;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row8_col3, #T_5ab76_row8_col6 {\n",
       "  background-color: #42be71;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row9_col0 {\n",
       "  background-color: #fbe723;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row9_col1 {\n",
       "  background-color: #93d741;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row9_col2 {\n",
       "  background-color: #70cf57;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row9_col4, #T_5ab76_row12_col0, #T_5ab76_row13_col0 {\n",
       "  background-color: #4ac16d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row9_col5 {\n",
       "  background-color: #3aba76;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row9_col6 {\n",
       "  background-color: #2eb37c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row10_col1, #T_5ab76_row11_col2 {\n",
       "  background-color: #25ac82;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row10_col2, #T_5ab76_row13_col5, #T_5ab76_row13_col6 {\n",
       "  background-color: #1fa188;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row10_col3 {\n",
       "  background-color: #1f9a8a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row10_col4, #T_5ab76_row14_col2 {\n",
       "  background-color: #1e9d89;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row10_col5 {\n",
       "  background-color: #21a585;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row10_col6 {\n",
       "  background-color: #26ad81;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row11_col0 {\n",
       "  background-color: #9dd93b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5ab76_row11_col1 {\n",
       "  background-color: #3bbb75;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row11_col3, #T_5ab76_row11_col6, #T_5ab76_row13_col1 {\n",
       "  background-color: #21a685;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row11_col4, #T_5ab76_row12_col6 {\n",
       "  background-color: #20a386;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row11_col5 {\n",
       "  background-color: #20a486;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row12_col1, #T_5ab76_row13_col2, #T_5ab76_row14_col3 {\n",
       "  background-color: #1f9e89;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row12_col2, #T_5ab76_row12_col4, #T_5ab76_row13_col3 {\n",
       "  background-color: #1f988b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row12_col3 {\n",
       "  background-color: #1f948c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row12_col5 {\n",
       "  background-color: #1fa088;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row13_col4, #T_5ab76_row14_col1 {\n",
       "  background-color: #1e9c89;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row14_col0 {\n",
       "  background-color: #35b779;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row14_col4 {\n",
       "  background-color: #1e9b8a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row14_col5 {\n",
       "  background-color: #1f968b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row14_col6 {\n",
       "  background-color: #228b8d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row15_col0 {\n",
       "  background-color: #481769;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row15_col1 {\n",
       "  background-color: #46075a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row15_col2 {\n",
       "  background-color: #460a5d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row15_col3 {\n",
       "  background-color: #481467;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row15_col4 {\n",
       "  background-color: #481a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row15_col5 {\n",
       "  background-color: #481c6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row15_col6 {\n",
       "  background-color: #482374;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5ab76_row16_col0, #T_5ab76_row16_col1, #T_5ab76_row16_col2, #T_5ab76_row16_col3, #T_5ab76_row16_col4, #T_5ab76_row16_col5, #T_5ab76_row16_col6 {\n",
       "  background-color: #440154;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5ab76\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5ab76_level0_col0\" class=\"col_heading level0 col0\" >corrs_0.001</th>\n",
       "      <th id=\"T_5ab76_level0_col1\" class=\"col_heading level0 col1\" >corrs_0.01</th>\n",
       "      <th id=\"T_5ab76_level0_col2\" class=\"col_heading level0 col2\" >corrs_0.05</th>\n",
       "      <th id=\"T_5ab76_level0_col3\" class=\"col_heading level0 col3\" >corrs_0.1</th>\n",
       "      <th id=\"T_5ab76_level0_col4\" class=\"col_heading level0 col4\" >corrs_0.25</th>\n",
       "      <th id=\"T_5ab76_level0_col5\" class=\"col_heading level0 col5\" >corrs_0.5</th>\n",
       "      <th id=\"T_5ab76_level0_col6\" class=\"col_heading level0 col6\" >corrs_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5ab76_level0_row0\" class=\"row_heading level0 row0\" >individual_gpt4___individual_gpt4_wordrate___shapley_35</th>\n",
       "      <td id=\"T_5ab76_row0_col0\" class=\"data row0 col0\" >nan</td>\n",
       "      <td id=\"T_5ab76_row0_col1\" class=\"data row0 col1\" >0.431</td>\n",
       "      <td id=\"T_5ab76_row0_col2\" class=\"data row0 col2\" >0.379</td>\n",
       "      <td id=\"T_5ab76_row0_col3\" class=\"data row0 col3\" >0.344</td>\n",
       "      <td id=\"T_5ab76_row0_col4\" class=\"data row0 col4\" >0.275</td>\n",
       "      <td id=\"T_5ab76_row0_col5\" class=\"data row0 col5\" >0.213</td>\n",
       "      <td id=\"T_5ab76_row0_col6\" class=\"data row0 col6\" >0.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5ab76_level0_row1\" class=\"row_heading level0 row1\" >shapley_35___individual_gpt4_pc___shapley_35_gpt4_pc</th>\n",
       "      <td id=\"T_5ab76_row1_col0\" class=\"data row1 col0\" >0.394</td>\n",
       "      <td id=\"T_5ab76_row1_col1\" class=\"data row1 col1\" >0.361</td>\n",
       "      <td id=\"T_5ab76_row1_col2\" class=\"data row1 col2\" >0.301</td>\n",
       "      <td id=\"T_5ab76_row1_col3\" class=\"data row1 col3\" >0.265</td>\n",
       "      <td id=\"T_5ab76_row1_col4\" class=\"data row1 col4\" >0.207</td>\n",
       "      <td id=\"T_5ab76_row1_col5\" class=\"data row1 col5\" >0.160</td>\n",
       "      <td id=\"T_5ab76_row1_col6\" class=\"data row1 col6\" >0.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5ab76_level0_row2\" class=\"row_heading level0 row2\" >individual_gpt4</th>\n",
       "      <td id=\"T_5ab76_row2_col0\" class=\"data row2 col0\" >0.400</td>\n",
       "      <td id=\"T_5ab76_row2_col1\" class=\"data row2 col1\" >0.359</td>\n",
       "      <td id=\"T_5ab76_row2_col2\" class=\"data row2 col2\" >0.309</td>\n",
       "      <td id=\"T_5ab76_row2_col3\" class=\"data row2 col3\" >0.274</td>\n",
       "      <td id=\"T_5ab76_row2_col4\" class=\"data row2 col4\" >0.212</td>\n",
       "      <td id=\"T_5ab76_row2_col5\" class=\"data row2 col5\" >0.160</td>\n",
       "      <td id=\"T_5ab76_row2_col6\" class=\"data row2 col6\" >0.123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5ab76_level0_row3\" class=\"row_heading level0 row3\" >individual_gpt4___individual_gpt4_wordrate</th>\n",
       "      <td id=\"T_5ab76_row3_col0\" class=\"data row3 col0\" >nan</td>\n",
       "      <td id=\"T_5ab76_row3_col1\" class=\"data row3 col1\" >0.351</td>\n",
       "      <td id=\"T_5ab76_row3_col2\" class=\"data row3 col2\" >0.300</td>\n",
       "      <td id=\"T_5ab76_row3_col3\" class=\"data row3 col3\" >0.265</td>\n",
       "      <td id=\"T_5ab76_row3_col4\" class=\"data row3 col4\" >0.206</td>\n",
       "      <td id=\"T_5ab76_row3_col5\" class=\"data row3 col5\" >0.157</td>\n",
       "      <td id=\"T_5ab76_row3_col6\" class=\"data row3 col6\" >0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5ab76_level0_row4\" class=\"row_heading level0 row4\" >shapley_35</th>\n",
       "      <td id=\"T_5ab76_row4_col0\" class=\"data row4 col0\" >0.368</td>\n",
       "      <td id=\"T_5ab76_row4_col1\" class=\"data row4 col1\" >0.325</td>\n",
       "      <td id=\"T_5ab76_row4_col2\" class=\"data row4 col2\" >0.268</td>\n",
       "      <td id=\"T_5ab76_row4_col3\" class=\"data row4 col3\" >0.232</td>\n",
       "      <td id=\"T_5ab76_row4_col4\" class=\"data row4 col4\" >0.185</td>\n",
       "      <td id=\"T_5ab76_row4_col5\" class=\"data row4 col5\" >0.147</td>\n",
       "      <td id=\"T_5ab76_row4_col6\" class=\"data row4 col6\" >0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5ab76_level0_row5\" class=\"row_heading level0 row5\" >full_35_gpt4_pc___individual_gpt4_pc___shapley_35_gpt4_pc</th>\n",
       "      <td id=\"T_5ab76_row5_col0\" class=\"data row5 col0\" >0.392</td>\n",
       "      <td id=\"T_5ab76_row5_col1\" class=\"data row5 col1\" >0.350</td>\n",
       "      <td id=\"T_5ab76_row5_col2\" class=\"data row5 col2\" >0.290</td>\n",
       "      <td id=\"T_5ab76_row5_col3\" class=\"data row5 col3\" >0.255</td>\n",
       "      <td id=\"T_5ab76_row5_col4\" class=\"data row5 col4\" >0.197</td>\n",
       "      <td id=\"T_5ab76_row5_col5\" class=\"data row5 col5\" >0.150</td>\n",
       "      <td id=\"T_5ab76_row5_col6\" class=\"data row5 col6\" >0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5ab76_level0_row6\" class=\"row_heading level0 row6\" >individual_gpt4_pc</th>\n",
       "      <td id=\"T_5ab76_row6_col0\" class=\"data row6 col0\" >0.387</td>\n",
       "      <td id=\"T_5ab76_row6_col1\" class=\"data row6 col1\" >0.353</td>\n",
       "      <td id=\"T_5ab76_row6_col2\" class=\"data row6 col2\" >0.298</td>\n",
       "      <td id=\"T_5ab76_row6_col3\" class=\"data row6 col3\" >0.264</td>\n",
       "      <td id=\"T_5ab76_row6_col4\" class=\"data row6 col4\" >0.202</td>\n",
       "      <td id=\"T_5ab76_row6_col5\" class=\"data row6 col5\" >0.151</td>\n",
       "      <td id=\"T_5ab76_row6_col6\" class=\"data row6 col6\" >0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5ab76_level0_row7\" class=\"row_heading level0 row7\" >individual_gpt4_pc_mask_per_question</th>\n",
       "      <td id=\"T_5ab76_row7_col0\" class=\"data row7 col0\" >0.333</td>\n",
       "      <td id=\"T_5ab76_row7_col1\" class=\"data row7 col1\" >0.325</td>\n",
       "      <td id=\"T_5ab76_row7_col2\" class=\"data row7 col2\" >0.289</td>\n",
       "      <td id=\"T_5ab76_row7_col3\" class=\"data row7 col3\" >0.254</td>\n",
       "      <td id=\"T_5ab76_row7_col4\" class=\"data row7 col4\" >0.198</td>\n",
       "      <td id=\"T_5ab76_row7_col5\" class=\"data row7 col5\" >0.157</td>\n",
       "      <td id=\"T_5ab76_row7_col6\" class=\"data row7 col6\" >0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5ab76_level0_row8\" class=\"row_heading level0 row8\" >shapley_35_gpt4_pc</th>\n",
       "      <td id=\"T_5ab76_row8_col0\" class=\"data row8 col0\" >0.375</td>\n",
       "      <td id=\"T_5ab76_row8_col1\" class=\"data row8 col1\" >0.330</td>\n",
       "      <td id=\"T_5ab76_row8_col2\" class=\"data row8 col2\" >0.269</td>\n",
       "      <td id=\"T_5ab76_row8_col3\" class=\"data row8 col3\" >0.236</td>\n",
       "      <td id=\"T_5ab76_row8_col4\" class=\"data row8 col4\" >0.185</td>\n",
       "      <td id=\"T_5ab76_row8_col5\" class=\"data row8 col5\" >0.143</td>\n",
       "      <td id=\"T_5ab76_row8_col6\" class=\"data row8 col6\" >0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5ab76_level0_row9\" class=\"row_heading level0 row9\" >individual_gpt4_ndel=1_pc</th>\n",
       "      <td id=\"T_5ab76_row9_col0\" class=\"data row9 col0\" >0.397</td>\n",
       "      <td id=\"T_5ab76_row9_col1\" class=\"data row9 col1\" >0.358</td>\n",
       "      <td id=\"T_5ab76_row9_col2\" class=\"data row9 col2\" >0.293</td>\n",
       "      <td id=\"T_5ab76_row9_col3\" class=\"data row9 col3\" >0.256</td>\n",
       "      <td id=\"T_5ab76_row9_col4\" class=\"data row9 col4\" >0.193</td>\n",
       "      <td id=\"T_5ab76_row9_col5\" class=\"data row9 col5\" >0.141</td>\n",
       "      <td id=\"T_5ab76_row9_col6\" class=\"data row9 col6\" >0.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5ab76_level0_row10\" class=\"row_heading level0 row10\" >full_35_pc</th>\n",
       "      <td id=\"T_5ab76_row10_col0\" class=\"data row10 col0\" >0.297</td>\n",
       "      <td id=\"T_5ab76_row10_col1\" class=\"data row10 col1\" >0.257</td>\n",
       "      <td id=\"T_5ab76_row10_col2\" class=\"data row10 col2\" >0.209</td>\n",
       "      <td id=\"T_5ab76_row10_col3\" class=\"data row10 col3\" >0.180</td>\n",
       "      <td id=\"T_5ab76_row10_col4\" class=\"data row10 col4\" >0.147</td>\n",
       "      <td id=\"T_5ab76_row10_col5\" class=\"data row10 col5\" >0.121</td>\n",
       "      <td id=\"T_5ab76_row10_col6\" class=\"data row10 col6\" >0.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5ab76_level0_row11\" class=\"row_heading level0 row11\" >full_35_gpt4_pc</th>\n",
       "      <td id=\"T_5ab76_row11_col0\" class=\"data row11 col0\" >0.337</td>\n",
       "      <td id=\"T_5ab76_row11_col1\" class=\"data row11 col1\" >0.287</td>\n",
       "      <td id=\"T_5ab76_row11_col2\" class=\"data row11 col2\" >0.227</td>\n",
       "      <td id=\"T_5ab76_row11_col3\" class=\"data row11 col3\" >0.197</td>\n",
       "      <td id=\"T_5ab76_row11_col4\" class=\"data row11 col4\" >0.154</td>\n",
       "      <td id=\"T_5ab76_row11_col5\" class=\"data row11 col5\" >0.120</td>\n",
       "      <td id=\"T_5ab76_row11_col6\" class=\"data row11 col6\" >0.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5ab76_level0_row12\" class=\"row_heading level0 row12\" >full_35_ndel=8_pc</th>\n",
       "      <td id=\"T_5ab76_row12_col0\" class=\"data row12 col0\" >0.275</td>\n",
       "      <td id=\"T_5ab76_row12_col1\" class=\"data row12 col1\" >0.231</td>\n",
       "      <td id=\"T_5ab76_row12_col2\" class=\"data row12 col2\" >0.195</td>\n",
       "      <td id=\"T_5ab76_row12_col3\" class=\"data row12 col3\" >0.171</td>\n",
       "      <td id=\"T_5ab76_row12_col4\" class=\"data row12 col4\" >0.141</td>\n",
       "      <td id=\"T_5ab76_row12_col5\" class=\"data row12 col5\" >0.116</td>\n",
       "      <td id=\"T_5ab76_row12_col6\" class=\"data row12 col6\" >0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5ab76_level0_row13\" class=\"row_heading level0 row13\" >full_35</th>\n",
       "      <td id=\"T_5ab76_row13_col0\" class=\"data row13 col0\" >0.274</td>\n",
       "      <td id=\"T_5ab76_row13_col1\" class=\"data row13 col1\" >0.248</td>\n",
       "      <td id=\"T_5ab76_row13_col2\" class=\"data row13 col2\" >0.204</td>\n",
       "      <td id=\"T_5ab76_row13_col3\" class=\"data row13 col3\" >0.177</td>\n",
       "      <td id=\"T_5ab76_row13_col4\" class=\"data row13 col4\" >0.145</td>\n",
       "      <td id=\"T_5ab76_row13_col5\" class=\"data row13 col5\" >0.117</td>\n",
       "      <td id=\"T_5ab76_row13_col6\" class=\"data row13 col6\" >0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5ab76_level0_row14\" class=\"row_heading level0 row14\" >full_35_wordrate</th>\n",
       "      <td id=\"T_5ab76_row14_col0\" class=\"data row14 col0\" >0.255</td>\n",
       "      <td id=\"T_5ab76_row14_col1\" class=\"data row14 col1\" >0.229</td>\n",
       "      <td id=\"T_5ab76_row14_col2\" class=\"data row14 col2\" >0.202</td>\n",
       "      <td id=\"T_5ab76_row14_col3\" class=\"data row14 col3\" >0.184</td>\n",
       "      <td id=\"T_5ab76_row14_col4\" class=\"data row14 col4\" >0.144</td>\n",
       "      <td id=\"T_5ab76_row14_col5\" class=\"data row14 col5\" >0.107</td>\n",
       "      <td id=\"T_5ab76_row14_col6\" class=\"data row14 col6\" >0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5ab76_level0_row15\" class=\"row_heading level0 row15\" >individual_35</th>\n",
       "      <td id=\"T_5ab76_row15_col0\" class=\"data row15 col0\" >-0.011</td>\n",
       "      <td id=\"T_5ab76_row15_col1\" class=\"data row15 col1\" >-0.011</td>\n",
       "      <td id=\"T_5ab76_row15_col2\" class=\"data row15 col2\" >-0.005</td>\n",
       "      <td id=\"T_5ab76_row15_col3\" class=\"data row15 col3\" >0.004</td>\n",
       "      <td id=\"T_5ab76_row15_col4\" class=\"data row15 col4\" >0.007</td>\n",
       "      <td id=\"T_5ab76_row15_col5\" class=\"data row15 col5\" >0.006</td>\n",
       "      <td id=\"T_5ab76_row15_col6\" class=\"data row15 col6\" >0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5ab76_level0_row16\" class=\"row_heading level0 row16\" >full_35_gpt4_ndel=1_pc</th>\n",
       "      <td id=\"T_5ab76_row16_col0\" class=\"data row16 col0\" >-0.037</td>\n",
       "      <td id=\"T_5ab76_row16_col1\" class=\"data row16 col1\" >-0.019</td>\n",
       "      <td id=\"T_5ab76_row16_col2\" class=\"data row16 col2\" >-0.014</td>\n",
       "      <td id=\"T_5ab76_row16_col3\" class=\"data row16 col3\" >-0.015</td>\n",
       "      <td id=\"T_5ab76_row16_col4\" class=\"data row16 col4\" >-0.012</td>\n",
       "      <td id=\"T_5ab76_row16_col5\" class=\"data row16 col5\" >-0.011</td>\n",
       "      <td id=\"T_5ab76_row16_col6\" class=\"data row16 col6\" >-0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5ab76_level0_row17\" class=\"row_heading level0 row17\" >full_neurosynth</th>\n",
       "      <td id=\"T_5ab76_row17_col0\" class=\"data row17 col0\" >nan</td>\n",
       "      <td id=\"T_5ab76_row17_col1\" class=\"data row17 col1\" >nan</td>\n",
       "      <td id=\"T_5ab76_row17_col2\" class=\"data row17 col2\" >nan</td>\n",
       "      <td id=\"T_5ab76_row17_col3\" class=\"data row17 col3\" >nan</td>\n",
       "      <td id=\"T_5ab76_row17_col4\" class=\"data row17 col4\" >nan</td>\n",
       "      <td id=\"T_5ab76_row17_col5\" class=\"data row17 col5\" >nan</td>\n",
       "      <td id=\"T_5ab76_row17_col6\" class=\"data row17 col6\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5e5cd7cc10>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregate results\n",
    "corrs_results_dir = join(repo_dir, 'qa_results', 'gemv', subject)\n",
    "d = defaultdict(list)\n",
    "for fname in os.listdir(corrs_results_dir):\n",
    "    if fname.startswith('corrs_') and fname.endswith('.pkl'):\n",
    "        d['setting'].append(fname.replace('corrs_', '').replace('.pkl', ''))\n",
    "        x = joblib.load(join(corrs_results_dir, fname))\n",
    "        d['corrs_df'].append(joblib.load(join(corrs_results_dir, fname)))\n",
    "        if not len(x) == len(gemv_questions_list):\n",
    "            warnings.warn(\n",
    "                'not all questions were computed for ' + str(d['setting'][-1]))\n",
    "# assert all([x.shape[0] == d['corrs_df'][0].shape[0] for x in d['corrs_df']])\n",
    "avg_df = pd.DataFrame([x.drop(columns='questions').mean(axis=0)\n",
    "                      for x in d['corrs_df']], index=d['setting'])\n",
    "avg_df = avg_df.sort_values(by='corrs_1', ascending=False)\n",
    "avg_df.style.background_gradient(cmap='viridis').format(\"{:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute p-values with eng1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frac_voxels_to_keep in tqdm(frac_voxels_to_keep_list):\n",
    "    eng1000_dir = join(PROCESSED_DIR, subject.replace(\n",
    "        'UT', ''), 'eng1000_weights.pkl')\n",
    "    pvals = viz.compute_pvals(flatmaps_qa_list, frac_voxels_to_keep,\n",
    "                              corrs_df[f'corrs_{frac_voxels_to_keep}'].values, eng1000_dir=eng1000_dir, mask_corrs=corrs_test)\n",
    "\n",
    "    # get what fraction of 'corrs_perm_eng1000' column is greater than 'corrs'\n",
    "    corrs_df[f'pval_{frac_voxels_to_keep}'] = pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add average row\n",
    "corrs_viz = corrs_df.set_index('questions').sort_values(\n",
    "    by='pval_0.001')\n",
    "# by='corrs_1')\n",
    "corrs_viz.loc['AVG'] = corrs_viz.mean()\n",
    "corrs_viz.loc['AVG_FIRST10'] = corrs_viz.head(10).mean()\n",
    "\n",
    "# format scientific notation\n",
    "print('___'.join(settings))\n",
    "corrs_viz.style.background_gradient().format(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ridge_utils.SemanticModel import SemanticModel\n",
    "from neuro.config import em_data_dir\n",
    "eng1000 = SemanticModel.load(join(em_data_dir, \"english1000sm.hf5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index_dict = eng1000.vindex\n",
    "\n",
    "index_to_wordlist_dict = defaultdict(list)\n",
    "for k, v in word_to_index_dict.items():\n",
    "    index_to_wordlist_dict[v].append(k.decode())\n",
    "# check if all lists are length 1\n",
    "assert all([len(v) == 1 for v in index_to_wordlist_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list_985 = list(word_to_index_dict.keys())\n",
    "dog_vec = eng1000['dog'.encode()]\n",
    "words_list_985[np.argmax(dog_vec) + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in corrs_viz.index.values[:-2]:\n",
    "    first_word = k.split()[0]\n",
    "    if first_word.endswith('s'):\n",
    "        first_word = first_word[:-1]\n",
    "    rename = {\n",
    "        'measurement': 'measure',\n",
    "        'dialogue': 'talk',\n",
    "        'sensory': 'sense',\n",
    "        'negation': 'negative',\n",
    "        'cultural': 'culture',\n",
    "    }\n",
    "    first_word = rename.get(first_word, first_word)\n",
    "\n",
    "    print(k, '--', first_word,\n",
    "          eng1000.find_words_like_word(first_word.encode(), n=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at merged flatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_df = pd.read_pickle(join(repo_dir, 'qa_results', 'gemv',\n",
    "                               setting + '_corrs_df.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_parent_dir = join(repo_dir, 'qa_results', 'gemv',\n",
    "                      subject, 'frac_voxels=0.1')\n",
    "img_dir1 = join(img_parent_dir, 'gemv')\n",
    "img_dir2 = join(img_parent_dir, setting)\n",
    "\n",
    "# read images and combine them with their filenames on a single plot\n",
    "# fnames = os.listdir(img_dir1)\n",
    "# fnames = [f for f in fnames if f.endswith('.png')]\n",
    "# only keep the ones that are in both directories\n",
    "# fnames = [f for f in fnames if f in os.listdir(img_dir2)]\n",
    "\n",
    "\n",
    "# corrs = corrs.sort_values('corrs', ascending=False)\n",
    "fnames = [v + '.png' for v in corrs_df['questions'].values]\n",
    "\n",
    "n = len(fnames)\n",
    "C = 4\n",
    "R = int(np.ceil(n / C))\n",
    "\n",
    "fig, axs = plt.subplots(R, C, figsize=(C * 3.2, R * 1))\n",
    "axs = axs.flatten()\n",
    "for i in range(len(axs)):\n",
    "    axs[i].axis('off')\n",
    "for i, fname in enumerate(fnames):\n",
    "    img1 = plt.imread(join(img_dir1, fname))\n",
    "    img2 = plt.imread(join(img_dir2, fname))\n",
    "    axs[i].imshow(np.concatenate([img1, img2], axis=1))\n",
    "    axs[i].set_title(\n",
    "        f'{fname[:-4]} ({corrs_df[\"corrs\"].values[i]:0.3f})', fontsize=8)\n",
    "\n",
    "# add text in bottom right of figure\n",
    "fig.text(0.99, 0.01, f'{subject}\\nGEMV on left, QA on right',\n",
    "         ha='right', va='bottom', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(join(img_parent_dir, f'flatmaps_{setting}_{subject}.png'), dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
