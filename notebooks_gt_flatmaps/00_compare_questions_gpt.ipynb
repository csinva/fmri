{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../experiments')\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import imodelsx.process_results\n",
    "from neuro.features import qa_questions, feature_spaces\n",
    "from neuro.data import story_names\n",
    "from neuro.features.stim_utils import load_story_wordseqs, load_story_wordseqs_huge\n",
    "import random\n",
    "import json\n",
    "import neuro.config\n",
    "from neuro import analyze_helper\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "fit_encoding = __import__('02_fit_encoding')\n",
    "from neuro.features.questions.gpt4 import QUESTIONS_GPT4\n",
    "questions = QUESTIONS_GPT4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_names_list = sorted(story_names.get_story_names(\n",
    "    all=True))\n",
    "print('loaded', len(story_names_list), 'stories')\n",
    "wordseqs = load_story_wordseqs_huge(story_names_list)\n",
    "wordseq_idxs = {}\n",
    "ngrams_list_total = []\n",
    "running_idx = 0\n",
    "for story in story_names_list:\n",
    "    ngrams_list = feature_spaces.get_ngrams_list_main(\n",
    "        wordseqs[story], num_ngrams_context=10)\n",
    "    ngrams_list_total.extend(ngrams_list)\n",
    "    assert len(ngrams_list) == len(wordseqs[story].data)\n",
    "    wordseq_idxs[story] = (running_idx, running_idx + len(ngrams_list))\n",
    "    running_idx += len(ngrams_list)\n",
    "print(f'{len(ngrams_list_total)=} ngrams')\n",
    "joblib.dump(({'ngrams_list_total': ngrams_list_total, 'wordseq_idxs': wordseq_idxs}), os.path.join(\n",
    "    neuro.config.root_dir, 'qa/cache_gpt/ngrams_metadata.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_dict = {}\n",
    "for question in tqdm(questions[:35]):\n",
    "    out_file = f'/home/chansingh/mntv1/deep-fMRI/qa/cache_gpt/{question}.pkl'\n",
    "    answers_dict[question] = joblib.load(out_file)\n",
    "out = pd.DataFrame(answers_dict, index=ngrams_list_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = deepcopy(out)\n",
    "o.columns = [analyze_helper.abbrev_question(q) for q in o.columns]\n",
    "\n",
    "# plt.figure(figsize=(10, 10), dpi=300)\n",
    "corrs = o.corr()\n",
    "vabs = np.nanmax(corrs)\n",
    "# set dendrogram color to be white\n",
    "ax = sns.clustermap(corrs, center=0, cmap='RdBu_r', vmin=-vabs,\n",
    "                    vmax=vabs,\n",
    "                    # cbar=False,\n",
    "                    dendrogram_ratio=0.01, tree_kws={'visible': False}\n",
    "                    )\n",
    "\n",
    "cbar = ax.cax\n",
    "# cbar.set_position([0.95, 0.9, 0.03, 0.1])\n",
    "cbar.set_position([1.1, 0.9, 0.03, 0.1])\n",
    "cbar.set_ylabel('$\\\\rho$')\n",
    "\n",
    "\n",
    "# add number to beginning of each yticklabel\n",
    "yticklabels = ax.ax_heatmap.get_yticklabels()\n",
    "yticklabels = [f'{i+1:02}.{l.get_text()}' for i, l in enumerate(yticklabels)]\n",
    "ax.ax_heatmap.set_yticklabels(yticklabels)\n",
    "\n",
    "# set xticklabels to just numbers\n",
    "ax.ax_heatmap.set_xticklabels([f'{i+1:02}' for i in range(len(yticklabels))])\n",
    "\n",
    "# add barplot on top of the clustermap\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.tight_layout\n",
    "\n",
    "plt.xlabel('Mean correlation')\n",
    "# plt.savefig('../qa_results/figs/question_corrs_35.pdf', bbox_inches='tight')\n",
    "plt.savefig('../qa_results/figs/question_corrs_35.png',\n",
    "            bbox_inches='tight', dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barplot sorted by values\n",
    "plt.figure(figsize=(10, 10))\n",
    "o_sort_vals = o.mean().sort_values()\n",
    "plt.grid()\n",
    "sns.barplot(x=o_sort_vals.values, y=o_sort_vals.index)\n",
    "plt.xlabel('Fraction of \"yes\" answers')\n",
    "plt.ylabel('')xw\n",
    "plt.savefig('../qa_results/figs/question_corrs_35_barplot.png', dpi=300,\n",
    "            bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
