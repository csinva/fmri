{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import joblib\n",
    "from pprint import pprint\n",
    "from math import ceil\n",
    "import cortex\n",
    "from neuro.config import repo_dir, PROCESSED_DIR\n",
    "from collections import defaultdict\n",
    "from scipy.stats import norm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import gemv\n",
    "from neuro.flatmaps_helper import load_flatmaps\n",
    "import sasc.viz\n",
    "from neuro import analyze_helper\n",
    "import nibabel as nib\n",
    "neurosynth_compare = __import__('04_neurosynth_compare')\n",
    "import neurosynth\n",
    "from neuro.features.questions.gpt4 import QS_35_STABLE\n",
    "\n",
    "\n",
    "\n",
    "# set os environ SUBJECTS_DIR\n",
    "FREESURFER_VARS = {\n",
    "    'FREESURFER_HOME': os.path.expanduser('~/freesurfer'),\n",
    "    'FSL_DIR': os.path.expanduser('~/fsl'),\n",
    "    'FSFAST_HOME': os.path.expanduser('~/freesurfer/fsfast'),\n",
    "    'MNI_DIR': os.path.expanduser('~/freesurfer/mni'),\n",
    "    # 'SUBJECTS_DIR': join(repo_dir, 'notebooks_gt_flatmaps'),\n",
    "    'SUBJECTS_DIR': os.path.expanduser('~/freesurfer/subjects'),\n",
    "    # add freesurfer bin to path\n",
    "    'PATH': os.path.expanduser('~/freesurfer/bin') + ':' + os.environ['PATH'],\n",
    "}\n",
    "for k in FREESURFER_VARS.keys():\n",
    "    os.environ[k] = FREESURFER_VARS[k]\n",
    "\n",
    "subject = 'S02'\n",
    "subjects = [f'S0{i}' for i in range(1, 9) if not i == 6] # there's some problem with S06 surf2surf\n",
    "# subjects = ['S01', 'S02', 'S03']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load flatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = defaultdict(list)\n",
    "for subject in subjects:\n",
    "    # if subject in ['S01', 'S02', 'S03']:\n",
    "    # settings = ['individual_gpt4',\n",
    "    # 'individual_gpt4_wordrate', 'shapley_35']\n",
    "    # else:\n",
    "    settings = ['individual_gpt4_ndel=1_pc_new']\n",
    "    flatmaps_qa_list = defaultdict(list)\n",
    "    for setting in settings:\n",
    "        flatmaps_qa_dict = joblib.load(\n",
    "            join(PROCESSED_DIR, subject.replace('UT', ''), setting + '.pkl'))\n",
    "        for q in flatmaps_qa_dict.keys():\n",
    "            flatmaps_qa_list[q].append(flatmaps_qa_dict[q])\n",
    "    flatmaps_qa_dict = {\n",
    "        q: np.mean(flatmaps_qa_list[q], axis=0)\n",
    "        for q in flatmaps_qa_list.keys()\n",
    "    }\n",
    "    # for k in sorted(flatmaps_qa_dict.keys()):\n",
    "    for k in QS_35_STABLE:\n",
    "        # print(k, flatmaps_qa_dict[k])\n",
    "        # d[f'q_{subject}'].append(k)\n",
    "        d[subject].append(flatmaps_qa_dict[k])\n",
    "\n",
    "    # print(subject, len(flatmaps_qa_dict))\n",
    "df = pd.DataFrame(d)\n",
    "# df.set_index('q_S01', inplace=True)\n",
    "df.index = QS_35_STABLE\n",
    "df.index.name = 'question'\n",
    "df = df[df.index.isin(QS_35_STABLE)]\n",
    "assert df.shape[0] == 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mni vols\n",
    "mni_arrs_list = []\n",
    "for q in tqdm(df.index):\n",
    "    mni_vols = []\n",
    "    for subject in subjects:\n",
    "        print(subject)\n",
    "        subj_vol = cortex.Volume(df.loc[q][subject], 'UT' + subject,\n",
    "                                 xfmname=f\"UT{subject}_auto\")\n",
    "        mni_vol = neurosynth.subj_vol_to_mni_surf(subj_vol, subject)\n",
    "        mni_vols.append(deepcopy(mni_vol))\n",
    "        mni_arrs = [mni_vol.data for mni_vol in mni_vols]\n",
    "    mni_arrs_list.append(deepcopy(mni_arrs))\n",
    "joblib.dump(mni_arrs_list, 'mni_arrs_list.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load arrs for first 3 subjects\n",
    "mni_arrs_list = joblib.load('mni_arrs_list.pkl')\n",
    "mni_arrs_list = [a[:3] for a in mni_arrs_list]\n",
    "subjects = subjects[:3]\n",
    "\n",
    "# compute correlations\n",
    "corrs_list = []\n",
    "for j, q in enumerate(df.index):\n",
    "    # compute correlation between each one and mean of the others\n",
    "    mni_arrs = np.array(mni_arrs_list[j])\n",
    "    corrs_loo = []\n",
    "    for i in range(mni_arrs.shape[0]):\n",
    "        mni_arr = mni_arrs[i]\n",
    "        other_mni_arrs = np.delete(mni_arrs, i, axis=0)\n",
    "        mean_other_mni_arr = np.mean(other_mni_arrs, axis=0)\n",
    "        corr = np.corrcoef(mni_arr.flatten(),\n",
    "                           mean_other_mni_arr.flatten())[0, 1]\n",
    "        # print(f'corr between {i} and mean of others', corr)\n",
    "        corrs_loo.append(corr)\n",
    "    corrs_list.append(corrs_loo)\n",
    "corrs_df = pd.DataFrame(np.array(corrs_list), columns=subjects, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten with column name as value for a new column\n",
    "corrs_df = corrs_df.melt(\n",
    "    ignore_index=False, var_name='subject', value_name='corrs').reset_index()\n",
    "corrs_df.rename(columns={'question': 'questions'}, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "neurosynth_compare.plot_corrs_df(\n",
    "    corrs_df,\n",
    "    out_dir='intersubject',\n",
    "    plot_val=f'corrs',\n",
    "    xlab=f'Inter-subject correlation (MNI space)',\n",
    "    ylabels=[analyze_helper.abbrev_question(q) for q in df.index.values],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save flatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for term in ['location', 'locations']:\n",
    "    mni_filename = f'/home/chansingh/mntv1/deep-fMRI/qa/neurosynth_data/all_association-test_z/{term}_association-test_z.nii.gz'\n",
    "    mni_vol = cortex.Volume(mni_filename, \"fsaverage\", \"atlas_2mm\")\n",
    "    subj_vol, subj_arr = neurosynth.mni_vol_to_subj_vol_surf(\n",
    "        mni_vol, subject=subject)\n",
    "    print('mni shape', mni_vol.shape, 'subj shape',\n",
    "          subj_vol.shape, 'subj_arr shape', subj_arr.shape)\n",
    "\n",
    "    sasc.viz.quickshow(\n",
    "        subj_vol.data,\n",
    "        subject='UT' + subject,\n",
    "        fname_save=join(f'intersubject/{term}_subj.png'),\n",
    "    )\n",
    "    sasc.viz.quickshow(\n",
    "        mni_vol,\n",
    "        subject='fsaverage',\n",
    "        fname_save=join(f'intersubject/{term}_mni.png'),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'Does the sentence mention a specific location?'\n",
    "for subject in ['S01']:  # ['S02']: #['S01', 'S02', 'S03']:\n",
    "    # if subject in ['S03']:\n",
    "    # settings = ['individual_gpt4', 'individual_gpt4_wordrate', 'shapley_35']\n",
    "    # settings = ['shapley_35']\n",
    "    # else:\n",
    "    settings = ['individual_gpt4_ndel=1_pc_new']\n",
    "    flatmaps_qa_list = defaultdict(list)\n",
    "    for setting in settings:\n",
    "        flatmaps_qa_dict = joblib.load(\n",
    "            join(PROCESSED_DIR, subject.replace('UT', ''), setting + '.pkl'))\n",
    "        flatmaps_qa_list[q].append(flatmaps_qa_dict[q])\n",
    "    flatmaps_qa_dict = {\n",
    "        q: np.mean(flatmaps_qa_list[q], axis=0)\n",
    "        for q in flatmaps_qa_list.keys()}\n",
    "\n",
    "    print('visualizing...')\n",
    "    sasc.viz.quickshow(\n",
    "        flatmaps_qa_dict[q],\n",
    "        subject='UT'+subject,\n",
    "        fname_save=join(repo_dir, 'qa_results', 'figs',\n",
    "                        'flatmaps_export', q, f'QA_{subject}.png'),\n",
    "        # cmap='RdYlBu_r',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemv_flatmaps_dict_S02, gemv_flatmaps_dict_S03 = load_flatmaps(\n",
    "    normalize_flatmaps=False, load_timecourse=False)\n",
    "q_tup = ('locations', 368)\n",
    "sasc.viz.quickshow(\n",
    "    gemv_flatmaps_dict_S02[q_tup],\n",
    "    subject='UTS02',\n",
    "    fname_save=join(repo_dir, 'qa_results', 'figs',\n",
    "                    'flatmaps_export', q, f'gemv_S02.png'),\n",
    "    # cmap='RdYlBu_r',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
