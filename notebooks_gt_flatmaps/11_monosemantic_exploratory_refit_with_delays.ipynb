{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import joblib\n",
    "from pprint import pprint\n",
    "from sklearn.preprocessing import normalize\n",
    "from math import ceil\n",
    "import cortex\n",
    "from neuro.config import repo_dir, PROCESSED_DIR, setup_freesurfer\n",
    "from collections import defaultdict\n",
    "from scipy.stats import norm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import gemv\n",
    "from neuro import flatmaps_helper\n",
    "from neuro.flatmaps_helper import load_flatmaps\n",
    "import sasc.viz\n",
    "from neuro import analyze_helper\n",
    "import nibabel as nib\n",
    "neurosynth_compare = __import__('04_neurosynth_compare')\n",
    "import neurosynth\n",
    "from neuro.features.questions.gpt4 import QS_35_STABLE\n",
    "from neuro.features import qa_questions\n",
    "setup_freesurfer()\n",
    "\n",
    "# subject = 'S02'\n",
    "# subjects = [f'S0{i}' for i in range(1, 9) if not i == 6] # there's some problem with S06 surf2surf\n",
    "subjects = ['S01', 'S02', 'S03']\n",
    "subject = 'S02'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ensemble (non-gpt-4) feats each run one at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_all = pd.read_pickle('oct17_tmp.pkl')\n",
    "r = rr_all[rr_all.ndelays == 4]\n",
    "r = r[r.pc_components == 100]\n",
    "r = r[r.feature_space == 'qa_embedder']\n",
    "r = r[r.qa_questions_version == 'v3_boostexamples_merged']\n",
    "r = r[r.qa_embedding_model == 'ensemble2']\n",
    "r = r[r.single_question_idx >= 0]\n",
    "r = r[r.feature_selection_alpha == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ravg = r.groupby(['single_question_idx'])[\n",
    "    ['corrs_test_mean']].mean().reset_index()\n",
    "qs = qa_questions.get_merged_questions_v3_boostexamples()\n",
    "ravg['question'] = ravg['single_question_idx'].apply(lambda i: qs[i])\n",
    "ravg['q_selected'] = ravg['question'].apply(lambda q: q in QS_35_STABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_selected = ravg[ravg.q_selected]\n",
    "r_unselected = ravg[~ravg.q_selected]\n",
    "sns.histplot(r_unselected.corrs_test_mean, label='Unselected', color=\"C1\")\n",
    "sns.histplot(r_selected.corrs_test_mean, label='Stable 35', color=\"C0\")\n",
    "plt.legend()\n",
    "plt.xlabel('Test correlation using single-question model')\n",
    "plt.ylabel('Question count')\n",
    "print('means', r_selected.corrs_test_mean.mean(),\n",
    "      r_unselected.corrs_test_mean.mean())\n",
    "plt.savefig('monosemantic/single_question_perf_hists.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ravg['question_abbrev'] = ravg['question'].apply(\n",
    "    analyze_helper.abbrev_question)\n",
    "with pd.option_context('display.max_colwidth', None,\n",
    "                       'display.max_rows', None):\n",
    "    display(ravg.sort_values('corrs_test_mean', ascending=False)\n",
    "            [['question_abbrev', 'q_selected']].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gpt-4 feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = pd.read_pickle('oct17_tmp.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = rr\n",
    "r = r[r.subject == subject]\n",
    "r = r[r.use_added_wordrate_feature == False]\n",
    "r = r[r.feature_space == 'qa_embedder']\n",
    "r = r[r.qa_embedding_model == 'gpt4']\n",
    "r = r[r.qa_questions_version.str.endswith('?')]  # individual question\n",
    "r = r[r.ndelays == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = pd.read_pickle('../notebooks/monosemantic_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_dicts = {}\n",
    "for subj in r.subject.unique():\n",
    "    r_subj = r[r.subject == subj]\n",
    "    q_to_corrs = r_subj.set_index(\n",
    "        'qa_questions_version').corrs_test.to_dict()\n",
    "\n",
    "    vox_to_q = df_selected[df_selected.subject == 'UT' + subj]\n",
    "    vox_to_q_dict = vox_to_q.set_index('voxel_idx').question.to_dict()\n",
    "\n",
    "    corrs = np.zeros(len(vox_to_q_dict))\n",
    "    for i, (vox, question) in enumerate(tqdm(vox_to_q_dict.items())):\n",
    "        corrs[i] = q_to_corrs[question][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_to_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vox_to_question_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r_subj.set_index('qa_questions_version')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
