{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import dvu\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import neuro.features.feature_utils\n",
    "import joblib\n",
    "import neuro.data.story_names\n",
    "import neuro.data.response_utils\n",
    "from tqdm import tqdm\n",
    "import neuro.features.feature_spaces\n",
    "from himalaya.ridge import RidgeCV\n",
    "from sklearn.model_selection import check_cv\n",
    "from himalaya.backend import set_backend\n",
    "import neuro.config\n",
    "from tabpfn import TabPFNRegressor\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'UTS03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_names_train = neuro.data.story_names.get_story_names(\n",
    "    subject=subject, train_or_test='train')\n",
    "story_names_test = neuro.data.story_names.get_story_names(\n",
    "    # could set use_huge=True here and below....\n",
    "    subject=subject, train_or_test='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    feature_space = 'eng1000'\n",
    "\n",
    "\n",
    "# load feats, already trimmed and normalized\n",
    "args = A()\n",
    "# feats_train = neuro.features.feature_utils.get_features_full(\n",
    "#     args=args,\n",
    "#     feature_space=args.feature_space,\n",
    "#     qa_embedding_model=None,\n",
    "#     story_names=story_names_train,\n",
    "#     use_added_delays=False,\n",
    "# )\n",
    "feats_test = neuro.features.feature_utils.get_features_full(\n",
    "    args=args,\n",
    "    feature_space=args.feature_space,\n",
    "    qa_embedding_model=None,\n",
    "    story_names=story_names_test,\n",
    "    use_added_delays=False,\n",
    ")\n",
    "\n",
    "print('feat shapes', feats_train.shape, feats_test.shape)\n",
    "print('resp shapes', resps_train.shape, resps_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample output voxels and feature inputs\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "corrs_test = joblib.load(join(neuro.config.PROCESSED_DIR, subject.replace(\n",
    "    'UT', ''), 'corrs_test_35.pkl')).values[0]\n",
    "# find indices of voxels in top-2000 voxels and randomly sample n_voxels\n",
    "inds_top = np.argsort(corrs_test)[-1000:]\n",
    "random_voxels = rng.choice(\n",
    "    inds_top, size=n_voxels, replace=False\n",
    ")\n",
    "resps_train_subsampled_voxels = resps_train[:, random_voxels].astype(\n",
    "    np.float32)\n",
    "resps_test_subsampled_voxels = resps_test[:, random_voxels].astype(np.float32)\n",
    "\n",
    "feats_train_subsampled = feats_train[:, :n_feats].astype(np.float32)\n",
    "feats_test_subsampled = feats_test[:, :n_feats].astype(np.float32)\n",
    "\n",
    "print('feat shapes', feats_train_subsampled.shape, feats_test_subsampled.shape)\n",
    "print('resp shapes', resps_train_subsampled_voxels.shape,\n",
    "      resps_test_subsampled_voxels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up cv splitting\n",
    "n_samples_train = feats_train_subsampled.shape[0]\n",
    "chunk_len = 40\n",
    "chunk_starts = np.arange(0, n_samples_train, chunk_len)\n",
    "cv = generate_leave_one_run_out(n_samples_train, chunk_starts)\n",
    "cv = check_cv(cv)  # copy the cross-validation splitter into a reusable list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RidgeCV(alphas=[1, 10, 100], cv=cv)\n",
    "# add delays for ridge\n",
    "feats_train_subsampled_delayed = neuro.features.feature_utils.make_delayed(\n",
    "    feats_train_subsampled, range(1, n_delays_ridge + 1))\n",
    "model.fit(feats_train_subsampled, resps_train_subsampled_voxels)\n",
    "preds_train = model.predict(feats_train_subsampled)\n",
    "preds_test = model.predict(feats_test_subsampled)\n",
    "\n",
    "\n",
    "def get_corrs(preds, resps):\n",
    "    return [np.corrcoef(preds[:, i], resps[:, i])[0, 1] for i in range(preds.shape[1])]\n",
    "\n",
    "\n",
    "r = defaultdict(list)\n",
    "r['corrs_train_ridge'] = get_corrs(preds_train, resps_train_subsampled_voxels)\n",
    "r['corrs_test_ridge'] = get_corrs(preds_test, resps_test_subsampled_voxels)\n",
    "print('train', np.mean(r['corrs_train_ridge']))\n",
    "print('test', np.mean(r['corrs_test_ridge']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_cols(n):\n",
    "\n",
    "    t = np.arange(n) / n\n",
    "    vals = [t]\n",
    "    for period in np.logspace(0, 3, 5):\n",
    "        vals.append(np.sin(t * period * 2 * np.pi))\n",
    "        vals.append(np.cos(t * period * 2 * np.pi))\n",
    "    return np.stack(vals, axis=1)\n",
    "\n",
    "\n",
    "time_cols = get_time_cols(\n",
    "    feats_train_subsampled.shape[0] + feats_test_subsampled.shape[0])\n",
    "feats_train_subsampled_with_time = np.concatenate(\n",
    "    [feats_train_subsampled, time_cols[:feats_train_subsampled.shape[0]]], axis=1)\n",
    "feats_test_subsampled_with_time = np.concatenate(\n",
    "    [feats_test_subsampled, time_cols[feats_train_subsampled.shape[0]:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(preds_train.shape[1])):\n",
    "    model = TabPFNRegressor(device='cuda:1')\n",
    "    model.fit(feats_train_subsampled, preds_train[:, i])\n",
    "    preds_test = model.predict(feats_test_subsampled)\n",
    "    r['corrs_test_tabpfn'].append(np.corrcoef(\n",
    "        preds_test, resps_test_subsampled_voxels[:, i])[0, 1])\n",
    "\n",
    "    # redo with time feats\n",
    "    model = TabPFNRegressor(device='cuda:1')\n",
    "    model.fit(feats_train_subsampled_with_time, preds_train[:, i])\n",
    "    preds_test = model.predict(feats_test_subsampled_with_time)\n",
    "    r['corrs_test_tabpfn_time'].append(np.corrcoef(\n",
    "        preds_test, resps_test_subsampled_voxels[:, i])[0, 1])\n",
    "\n",
    "    print(\n",
    "        f'voxel {i} test {r[\"corrs_test_ridge\"][i]:.3f} -> {r[\"corrs_test_tabpfn\"][-1]:.3f} -> {r[\"corrs_test_tabpfn_time\"][-1]:.3f}')\n",
    "    print(\n",
    "        '\\tavg cum. improvement',\n",
    "        np.mean(r['corrs_test_tabpfn'] -\n",
    "                np.mean(r['corrs_test_ridge'][:len(r['corrs_test_tabpfn'])])),\n",
    "        np.mean(r['corrs_test_tabpfn_time'] -\n",
    "                np.mean(r['corrs_test_ridge'][:len(r['corrs_test_tabpfn_time'])]))\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
