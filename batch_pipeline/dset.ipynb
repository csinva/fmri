{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import joblib\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "import numpy as np\n",
    "from huth.utils_ds import make_word_ds\n",
    "import data\n",
    "import sys\n",
    "sys.path.append('ridge_utils')\n",
    "\n",
    "class HuthLabDataset(Dataset):\n",
    "    def __init__(self, story_data_dir: str, resp_data_dir: str, subject: str, train_or_test='train', trim_start: int = 5, trim_end: int = 10):\n",
    "        self.subject = subject\n",
    "        self.stories = data.get_train_story_texts(subject=subject, train_or_test=train_or_test)\n",
    "        self.grids = joblib.load(os.path.join(\n",
    "            story_data_dir, \"grids_huge.jbl\"))\n",
    "        self.trfiles = joblib.load(os.path.join(\n",
    "            story_data_dir, \"trfiles_huge.jbl\"))\n",
    "        self.wordseqs = make_word_ds(self.grids, self.trfiles)\n",
    "        self.trim_start = trim_start\n",
    "        self.trim_end = trim_end\n",
    "        # self.lookback = num_trs  # num_trs = num_seconds / 2\n",
    "        self.resp_dict = {}\n",
    "        self.chunk_dict = {}\n",
    "        for story in self.stories:\n",
    "            hf5_path = os.path.join(resp_data_dir, subject, story + \".hf5\")\n",
    "            print(hf5_path)\n",
    "            self.resp_dict[story] = h5py.File(hf5_path, 'r')\n",
    "            self.chunk_dict[story] = self.wordseqs[story].chunks()[\n",
    "                self.trim_start:-self.trim_end]\n",
    "            # Confirm trimming dimensions match\n",
    "            num_trs_stim = len(\n",
    "                self.wordseqs[story].tr_times[self.trim_start:-self.trim_end])\n",
    "            num_trs_resp = self.resp_dict[story]['data'].shape[0]\n",
    "            assert num_trs_stim == num_trs_resp\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stories)\n",
    "\n",
    "    def __getitem__(self, story: str, idx: int, delays: int):\n",
    "        assert delays >= 0\n",
    "        if delays == 0:\n",
    "            return (self.chunk_dict[story][idx], self.resp_dict[story]['data'][idx])\n",
    "        else:\n",
    "            acc_out = []\n",
    "            for i in range(delays+1):\n",
    "                if idx-delays+i < 0:\n",
    "                    acc_out.append(np.array([], dtype='<U13'))\n",
    "                else:\n",
    "                    acc_out.append(self.chunk_dict[story][idx-delays+i])\n",
    "            return (acc_out, self.resp_dict[story]['data'][idx])\n",
    "\n",
    "\n",
    "\n",
    "dset = HuthLabDataset(story_data_dir='.',\n",
    "                      resp_data_dir='/home/chansingh/mntv1/deep-fMRI/ds003020/derivative/preprocessed_data',\n",
    "                      subject=\"UTS01\", train_or_test='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "!datalad clone https://github.com/OpenNeuroDatasets/ds003020.git\n",
    "!cd ds003020\n",
    "!datalad get derivative"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
