{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cortex\n",
    "from os.path import join\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "sys.path.append('../notebooks')\n",
    "from neuro.config import repo_dir, PROCESSED_DIR\n",
    "from neuro import viz\n",
    "from neurosynth import term_dict, term_dict_rev, get_neurosynth_flatmaps\n",
    "import viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, this notebook requires first running `03_export_qa_flatmaps.ipynb` into `df_qa_dict.pkl` files for each subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute correlations with qa flatmaps and plot avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting = 'shapley_neurosynth'\n",
    "# setting = 'full_neurosynth'\n",
    "\n",
    "apply_mask = True\n",
    "frac_voxels_to_keep = 0.1  # 0.10\n",
    "frac_voxels_to_keep_list = [frac_voxels_to_keep]\n",
    "\n",
    "\n",
    "corrs_df_list = defaultdict(list)\n",
    "flatmaps_qa_dicts_by_subject = {}\n",
    "for subject in tqdm(['UTS01', 'UTS02', 'UTS03']):\n",
    "    flatmaps_gt = get_neurosynth_flatmaps(subject)\n",
    "\n",
    "    flatmaps_qa_dict_over_settings = defaultdict(list)\n",
    "    # , 'individual_neurosynth']:\n",
    "    # for setting in ['shapley_neurosynth', 'full_neurosynth', 'individual_gpt4']:\n",
    "    # , 'individual_gpt4', 'shapley_neurosynth']:\n",
    "    for setting in ['shapley_neurosynth']:\n",
    "        flatmaps_qa_dict = joblib.load(\n",
    "            join(PROCESSED_DIR, subject.replace('UT', ''), setting + '.pkl'))\n",
    "        for q in flatmaps_qa_dict.keys():\n",
    "            flatmaps_qa_dict_over_settings[q].append(flatmaps_qa_dict[q])\n",
    "    flatmaps_qa_dict = {\n",
    "        q: np.mean(flatmaps_qa_dict_over_settings[q], axis=0)\n",
    "        for q in flatmaps_qa_dict_over_settings.keys()\n",
    "    }\n",
    "\n",
    "    if apply_mask:\n",
    "        corrs_test = joblib.load(join(PROCESSED_DIR, subject.replace(\n",
    "            'UT', ''), 'corrs_test_35.pkl')).values[0]\n",
    "        # threshold\n",
    "        if frac_voxels_to_keep < 1:\n",
    "            corrs_test_mask = (corrs_test > np.percentile(\n",
    "                corrs_test, 100 * (1 - frac_voxels_to_keep))).astype(bool)\n",
    "        else:\n",
    "            corrs_test_mask = np.ones_like(corrs_test).astype(bool)\n",
    "        flatmaps_qa_dict_masked = {k: flatmaps_qa_dict[k][corrs_test_mask]\n",
    "                                   for k in flatmaps_qa_dict.keys()}\n",
    "        flatmaps_gt_masked = {k: flatmaps_gt[k][corrs_test_mask]\n",
    "                              for k in flatmaps_gt.keys()}\n",
    "\n",
    "    # get common flatmaps and put into d\n",
    "    common_keys = set(flatmaps_gt_masked.keys()) & set(\n",
    "        flatmaps_qa_dict_masked.keys())\n",
    "    d = defaultdict(list)\n",
    "    for k in common_keys:\n",
    "        d['questions'].append(k)\n",
    "        d['corr'].append(np.corrcoef(flatmaps_qa_dict_masked[k],\n",
    "                                     flatmaps_gt_masked[k])[0, 1])\n",
    "        d['flatmap_qa'].append(flatmaps_qa_dict_masked[k])\n",
    "        d['flatmap_neurosynth'].append(flatmaps_gt_masked[k])\n",
    "    d = pd.DataFrame(d).sort_values('corr', ascending=False)\n",
    "\n",
    "    corrs = viz._calc_corrs(\n",
    "        d['flatmap_qa'].values,\n",
    "        d['flatmap_neurosynth'].values,\n",
    "        titles_qa=d['questions'].values,\n",
    "        titles_gt=d['questions'].values,\n",
    "    )\n",
    "\n",
    "    corrs_df_list[f'corrs_{frac_voxels_to_keep}'].extend(\n",
    "        np.diag(corrs).tolist())\n",
    "    corrs_df_list['questions'].extend(d['questions'].values.tolist())\n",
    "    corrs_df_list['subject'].extend([subject] * len(d['questions'].values))\n",
    "\n",
    "    # viz.corr_bars(\n",
    "    #     corrs,\n",
    "    #     out_dir_save=join(repo_dir, 'qa_results', 'neurosynth', setting),\n",
    "    #     xlab='Neurosynth',\n",
    "    # )\n",
    "\n",
    "    # save flatmaps\n",
    "    # for i in tqdm(range(len(d))):\n",
    "    #     sasc.viz.quickshow(\n",
    "    #         d.iloc[i]['flatmap_qa'],\n",
    "    #         subject=subject,\n",
    "    #         fname_save=join(repo_dir, 'qa_results', 'neurosynth', subject,\n",
    "    #                         setting, f'{d.iloc[i][\"questions\"]}.png')\n",
    "    #     )\n",
    "\n",
    "    #     sasc.viz.quickshow(\n",
    "    #         d.iloc[i]['flatmap_neurosynth'],\n",
    "    #         subject=subject,\n",
    "    #         fname_save=join(repo_dir, 'qa_results', 'neurosynth', subject,\n",
    "    #                         'neurosynth', f'{d.iloc[i][\"questions\"]}.png')\n",
    "    #     )\n",
    "    flatmaps_qa_dicts_by_subject[subject] = deepcopy(flatmaps_qa_dict)\n",
    "corrs_df = pd.DataFrame(corrs_df_list)\n",
    "# corrs_df.to_pickle(join(repo_dir, 'qa_results',\n",
    "#    'neurosynth', setting + '_corrs_df.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot correlations in corrs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = corrs_df\n",
    "xlab = f'Flatmap correlation (Top-{int(100*frac_voxels_to_keep)}% best-predicted voxels)'\n",
    "plt.figure(figsize=(7, 5))\n",
    "colors = {\n",
    "    'UTS01': 'C0',\n",
    "    'UTS02': 'C1',\n",
    "    'UTS03': 'C2',\n",
    "    'mean': 'black'\n",
    "}\n",
    "\n",
    "d_mean = pd.DataFrame(c.groupby('questions')[\n",
    "    f'corrs_{frac_voxels_to_keep}'].mean()).reset_index()\n",
    "d_mean['subject'] = 'mean'\n",
    "c = pd.concat([c, d_mean])\n",
    "c = c.set_index('questions')\n",
    "\n",
    "for subject in ['mean', 'UTS01', 'UTS02', 'UTS03']:\n",
    "    corrs_df_subject = c[c['subject'] == subject]\n",
    "    if subject == 'mean':\n",
    "        idx_sort = corrs_df_subject[f'corrs_{frac_voxels_to_keep}'].sort_values(\n",
    "            ascending=False).index\n",
    "    corrs_df_subject = corrs_df_subject.loc[idx_sort]\n",
    "\n",
    "    # plot corrs\n",
    "    if subject == 'mean':\n",
    "        plt.errorbar(\n",
    "            corrs_df_subject[f'corrs_{frac_voxels_to_keep}'],\n",
    "            range(len(corrs_df_subject)),\n",
    "            color='black',\n",
    "            fmt='o',\n",
    "            zorder=1000,\n",
    "            label=subject.capitalize(),\n",
    "        )\n",
    "    else:\n",
    "        plt.errorbar(\n",
    "            corrs_df_subject[f'corrs_{frac_voxels_to_keep}'],\n",
    "            range(len(corrs_df_subject)),\n",
    "            # xerr=np.sqrt(\n",
    "            # r_df[f'corrs_{frac_voxels_to_keep}'] * (1-r_df[f'corrs_{frac_voxels_to_keep}'])\n",
    "            # / r_df['num_test']),\n",
    "            alpha=0.5,\n",
    "            label=subject.upper(),\n",
    "            fmt='o')\n",
    "    plt.axvline(corrs_df_subject[f'corrs_{frac_voxels_to_keep}'].mean(),\n",
    "                linestyle='--', color=colors[subject], zorder=-1000)\n",
    "\n",
    "    print('mean corr', corrs_df_subject[f'corrs_{frac_voxels_to_keep}'].mean())\n",
    "\n",
    "# add horizontal bars\n",
    "plt.yticks(range(len(corrs_df_subject)), [term_dict_rev[k] for k in idx_sort])\n",
    "plt.xlabel(xlab, fontsize='large')\n",
    "plt.grid(axis='y', alpha=0.2)\n",
    "plt.axvline(0, color='gray')\n",
    "\n",
    "abs_lim = max(np.abs(plt.xlim()))\n",
    "plt.xlim(-abs_lim, abs_lim)\n",
    "\n",
    "# annotate with baseline and text label\n",
    "plt.legend(fontsize='large')\n",
    "plt.tight_layout()\n",
    "plt.savefig(join(repo_dir, 'qa_results',\n",
    "            'neurosynth', 'corrs_' + setting + '.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'UTS03'\n",
    "corrs_df_subject = corrs_df[corrs_df['subject']\n",
    "                            == subject].set_index('questions')\n",
    "\n",
    "# corrs_df = pd.DataFrame(corrs_df_dict)\n",
    "flatmaps_qa_list_subject = [flatmaps_qa_dict[q]\n",
    "                            for q in corrs_df_subject.index]\n",
    "for frac_voxels_to_keep in tqdm(frac_voxels_to_keep_list):\n",
    "    eng1000_dir = join(PROCESSED_DIR, subject.replace(\n",
    "        'UT', ''), 'eng1000_weights.pkl')\n",
    "    pvals = viz.compute_pvals(flatmaps_qa_list_subject, frac_voxels_to_keep,\n",
    "                              corrs_df_subject[f'corrs_{frac_voxels_to_keep}'].values, eng1000_dir=eng1000_dir)\n",
    "\n",
    "    # get what fraction of 'corrs_perm_eng1000' column is greater than f'corrs_{frac_voxels_to_keep}'\n",
    "    corrs_df_subject[f'pval_{frac_voxels_to_keep}'] = pvals\n",
    "\n",
    "# format scientific notation\n",
    "corrs_df_subject.sort_values(\n",
    "    by=f'pval_{frac_voxels_to_keep}').style.background_gradient().format(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merged flatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatmaps_qa_dict_list_subjects = {subject: [flatmaps_qa_dicts_by_subject[subject][q] for q in corrs_df_subject.index]\n",
    "                                  for subject in ['UTS01', 'UTS02', 'UTS03']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cortex import mni\n",
    "import os\n",
    "os.environ[\"FSLDIR\"] = \"/home/chansingh/fsl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = flatmaps_qa_dict_list_subjects['UTS01'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = cortex.Volume(data=arr.flatten(), subject='UTS01', xfmname='UTS01_auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_to_mni_cached = cortex.db.get_mnixfm('UTS01', 'UTS01_auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mni_data = mni.transform_to_mni(vol, s1_to_mni_cached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mni_data_vol = mni_data.get_fdata()  # the actual array, shape=(182,218,182)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at merged flatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_df = pd.read_pickle(join(repo_dir, 'qa_results',\n",
    "                               'neurosynth', setting + '_corrs_df.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = 'shapley_neurosynth'\n",
    "for subject in ['UTS01', 'UTS02', 'UTS03']:\n",
    "    img_dir1 = join(repo_dir, 'qa_results', 'neurosynth',\n",
    "                    subject, 'neurosynth')\n",
    "    img_dir2 = join(repo_dir, 'qa_results', 'neurosynth',\n",
    "                    subject, setting)\n",
    "\n",
    "    # read images and combine them with their filenames on a single plot\n",
    "    # fnames = os.listdir(img_dir1)\n",
    "    # fnames = [f for f in fnames if f.endswith('.png')]\n",
    "    # only keep the ones that are in both directories\n",
    "    # fnames = [f for f in fnames if f in os.listdir(img_dir2)]\n",
    "\n",
    "    corrs = corrs_df[corrs_df['subject'] == subject]\n",
    "    # corrs = corrs.sort_values(f'corrs_{frac_voxels_to_keep}', ascending=False)\n",
    "    fnames = [v + '.png' for v in corrs['questions'].values]\n",
    "\n",
    "    n = len(fnames)\n",
    "    C = 4\n",
    "    R = int(np.ceil(n / C))\n",
    "\n",
    "    fig, axs = plt.subplots(R, C, figsize=(C * 3.2, R * 1))\n",
    "    axs = axs.flatten()\n",
    "    for i in range(len(axs)):\n",
    "        axs[i].axis('off')\n",
    "    for i, fname in enumerate(fnames):\n",
    "        img1 = plt.imread(join(img_dir1, fname))\n",
    "        img2 = plt.imread(join(img_dir2, fname))\n",
    "        axs[i].imshow(np.concatenate([img1, img2], axis=1))\n",
    "        axs[i].set_title(\n",
    "            f'{term_dict_rev[fname[:-4]]} ({corrs[\"corrs\"].values[i]:0.3f})', fontsize=8)\n",
    "\n",
    "    # add text in bottom right of figure\n",
    "    fig.text(0.99, 0.01, f'{subject}\\nNeurosynth on left, QA on right',\n",
    "             ha='right', va='bottom', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(join(repo_dir, 'qa_results', 'neurosynth',\n",
    "                subject, f'flatmaps_{setting}_{subject}.png'), dpi=300)\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
