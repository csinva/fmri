{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "# from ridge_utils.DataSequence import DataSequence\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cortex\n",
    "# import seaborn as sns\n",
    "from os.path import join\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "# import sasc.viz\n",
    "import joblib\n",
    "# import dvu\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append('../notebooks')\n",
    "from neuro.config import repo_dir, PROCESSED_DIR\n",
    "from neuro import viz\n",
    "from neurosynth import term_dict, term_dict_rev\n",
    "import viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, this notebook requires first running `03_export_qa_flatmaps.ipynb` into `df_qa_dict.pkl` files for each subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load \"groundtruth\" comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load neurosynth avg. flatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neurosynth_flatmaps(subject, neurosynth_dir='/home/chansingh/mntv1/deep-fMRI/qa/neurosynth_data'):\n",
    "    subject_s = subject.replace('UT', '')\n",
    "    # neurosynth_dir = '/home/chansingh/mntv1/deep-fMRI/qa/neurosynth_data/all_association-test_z'\n",
    "\n",
    "    term_names = [k.replace('.nii.gz', '').replace(\n",
    "        '_association-test_z', '') for k in os.listdir(join(neurosynth_dir, f'all_in_{subject_s}-BOLD'))]\n",
    "\n",
    "    # filter dict for files that were in neurosynth\n",
    "    term_dict_ = {k: v for k, v in term_dict.items() if k in term_names}\n",
    "    # for k in term_dict.keys():\n",
    "    #     if k not in term_names:\n",
    "    #         print(k)\n",
    "\n",
    "    # filter dict for files that had questions run\n",
    "    questions_run = [k.replace('.pkl', '') for k in os.listdir(\n",
    "        '/home/chansingh/mntv1/deep-fMRI/qa/cache_gpt')]\n",
    "    term_dict_ = {k: v for k, v in term_dict_.items() if v in questions_run}\n",
    "\n",
    "    def _load_flatmap(term, neurosynth_dir, subject):\n",
    "        # output_file = join(neurosynth_dir, f'{term}_association-test_z.nii.gz')\n",
    "        output_file = join(\n",
    "            neurosynth_dir, f'all_in_{subject_s}-BOLD/{term}.nii.gz')\n",
    "        vol = cortex.Volume(output_file, subject, subject + '_auto').data\n",
    "        mask = cortex.db.get_mask(subject, subject + '_auto')\n",
    "        return vol[mask]\n",
    "\n",
    "    return {q: _load_flatmap(\n",
    "        term, neurosynth_dir, subject) for (term, q) in term_dict_.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute correlations with qa flatmaps and plot avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corrs_err_subjects(corrs_df, setting, xlab):\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    colors = {\n",
    "        'UTS01': 'C0',\n",
    "        'UTS02': 'C1',\n",
    "        'UTS03': 'C2',\n",
    "        'mean': 'black'\n",
    "    }\n",
    "\n",
    "    d_mean = pd.DataFrame(corrs_df.groupby('questions')[\n",
    "        'corrs'].mean()).reset_index()\n",
    "    d_mean['subject'] = 'mean'\n",
    "    corrs_df = pd.concat([corrs_df, d_mean])\n",
    "    corrs_df = corrs_df.set_index('questions')\n",
    "\n",
    "    for subject in ['mean', 'UTS01', 'UTS02', 'UTS03']:\n",
    "        r_df = corrs_df[corrs_df['subject'] == subject]\n",
    "        if subject == 'mean':\n",
    "            idx_sort = r_df['corrs'].sort_values(ascending=False).index\n",
    "\n",
    "        r_df = r_df.loc[idx_sort]\n",
    "\n",
    "        # plot corrs\n",
    "        if subject == 'mean':\n",
    "            plt.errorbar(\n",
    "                r_df['corrs'],\n",
    "                range(len(r_df)),\n",
    "                color='black',\n",
    "                fmt='o',\n",
    "                zorder=1000,\n",
    "                label=subject.capitalize(),\n",
    "            )\n",
    "        else:\n",
    "            plt.errorbar(\n",
    "                r_df['corrs'],\n",
    "                range(len(r_df)),\n",
    "                # xerr=np.sqrt(\n",
    "                # r_df['corrs'] * (1-r_df['corrs'])\n",
    "                # / r_df['num_test']),\n",
    "                alpha=0.5,\n",
    "                label=subject.upper(),\n",
    "                fmt='o')\n",
    "        plt.axvline(r_df['corrs'].mean(),\n",
    "                    linestyle='--', color=colors[subject], zorder=-1000)\n",
    "\n",
    "        print('mean corr', r_df['corrs'].mean())\n",
    "\n",
    "    # add horizontal bars\n",
    "    plt.yticks(range(len(r_df)), [term_dict_rev[k] for k in idx_sort])\n",
    "    plt.xlabel(xlab, fontsize='large')\n",
    "    plt.grid(axis='y', alpha=0.2)\n",
    "    plt.axvline(0, color='gray')\n",
    "\n",
    "    abs_lim = max(np.abs(plt.xlim()))\n",
    "    plt.xlim(-abs_lim, abs_lim)\n",
    "\n",
    "    # annotate with baseline and text label\n",
    "    plt.legend(fontsize='large')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(join(repo_dir, 'qa_results',\n",
    "                'neurosynth', 'corrs_' + setting + '.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# setting = 'shapley_neurosynth'\n",
    "# setting = 'full_neurosynth'\n",
    "\n",
    "apply_mask = True\n",
    "frac_voxels_to_keep = 0.1\n",
    "\n",
    "\n",
    "corrs_df_list = defaultdict(list)\n",
    "for subject in tqdm(['UTS01', 'UTS02', 'UTS03']):\n",
    "    flatmaps_gt = get_neurosynth_flatmaps(subject)\n",
    "\n",
    "    flatmaps_qa_list = defaultdict(list)\n",
    "    # , 'individual_neurosynth']:\n",
    "    # for setting in ['shapley_neurosynth', 'full_neurosynth', 'individual_gpt4']:\n",
    "    for setting in ['individual_gpt4', 'individual_gpt4', 'shapley_neurosynth']:\n",
    "        flatmaps_qa = joblib.load(\n",
    "            join(PROCESSED_DIR, subject.replace('UT', ''), setting + '.pkl'))\n",
    "        for q in flatmaps_qa.keys():\n",
    "            flatmaps_qa_list[q].append(flatmaps_qa[q])\n",
    "    flatmaps_qa = {\n",
    "        q: np.mean(flatmaps_qa_list[q], axis=0)\n",
    "        for q in flatmaps_qa_list.keys()}\n",
    "\n",
    "    if apply_mask:\n",
    "        corrs_test = joblib.load(join(PROCESSED_DIR, subject.replace(\n",
    "            'UT', ''), 'corrs_test_35.pkl')).values[0]\n",
    "        # threshold top-20%\n",
    "        corrs_test_mask = (corrs_test > np.percentile(\n",
    "            corrs_test, 100 * (1 - frac_voxels_to_keep))).astype(bool)\n",
    "        flatmaps_qa = {k: flatmaps_qa[k][corrs_test_mask]\n",
    "                       for k in flatmaps_qa.keys()}\n",
    "        flatmaps_gt = {k: flatmaps_gt[k][corrs_test_mask]\n",
    "                       for k in flatmaps_gt.keys()}\n",
    "\n",
    "    # get common flatmaps and put into d\n",
    "    common_keys = set(flatmaps_gt.keys()) & set(\n",
    "        flatmaps_qa.keys())\n",
    "    d = defaultdict(list)\n",
    "    for k in common_keys:\n",
    "        d['questions'].append(k)\n",
    "        d['corr'].append(np.corrcoef(flatmaps_qa[k],\n",
    "                                     flatmaps_gt[k])[0, 1])\n",
    "        d['flatmap_qa'].append(flatmaps_qa[k])\n",
    "        d['flatmap_neurosynth'].append(flatmaps_gt[k])\n",
    "    d = pd.DataFrame(d).sort_values('corr', ascending=False)\n",
    "\n",
    "    corrs = viz._calc_corrs(\n",
    "        d['flatmap_qa'].values,\n",
    "        d['flatmap_neurosynth'].values,\n",
    "        titles_qa=d['questions'].values,\n",
    "        titles_gt=d['questions'].values,\n",
    "    )\n",
    "\n",
    "    corrs_df_list['corrs'].extend(np.diag(corrs).tolist())\n",
    "    corrs_df_list['questions'].extend(d['questions'].values.tolist())\n",
    "    corrs_df_list['subject'].extend([subject] * len(d['questions'].values))\n",
    "\n",
    "    # viz.corr_bars(\n",
    "    #     corrs,\n",
    "    #     out_dir_save=join(repo_dir, 'qa_results', 'neurosynth', setting),\n",
    "    #     xlab='Neurosynth',\n",
    "    # )\n",
    "\n",
    "    # save flatmaps\n",
    "    # for i in tqdm(range(len(d))):\n",
    "    #     sasc.viz.quickshow(\n",
    "    #         d.iloc[i]['flatmap_qa'],\n",
    "    #         subject=subject,\n",
    "    #         fname_save=join(repo_dir, 'qa_results', 'neurosynth', subject,\n",
    "    #                         setting, f'{d.iloc[i][\"questions\"]}.png')\n",
    "    #     )\n",
    "\n",
    "    #     sasc.viz.quickshow(\n",
    "    #         d.iloc[i]['flatmap_neurosynth'],\n",
    "    #         subject=subject,\n",
    "    #         fname_save=join(repo_dir, 'qa_results', 'neurosynth', subject,\n",
    "    #                         'neurosynth', f'{d.iloc[i][\"questions\"]}.png')\n",
    "    #     )\n",
    "corrs_df = pd.DataFrame(corrs_df_list)\n",
    "# corrs_df.to_pickle(join(repo_dir, 'qa_results',\n",
    "#    'neurosynth', setting + '_corrs_df.pkl'))\n",
    "\n",
    "plot_corrs_err_subjects(\n",
    "    corrs_df, setting, xlab=f'Flatmap correlation (Top-{int(100*frac_voxels_to_keep)}% best-predicted voxels)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at merged flatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_df = pd.read_pickle(join(repo_dir, 'qa_results',\n",
    "                               'neurosynth', setting + '_corrs_df.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = 'shapley_neurosynth'\n",
    "for subject in ['UTS01', 'UTS02', 'UTS03']:\n",
    "    img_dir1 = join(repo_dir, 'qa_results', 'neurosynth',\n",
    "                    subject, 'neurosynth')\n",
    "    img_dir2 = join(repo_dir, 'qa_results', 'neurosynth',\n",
    "                    subject, setting)\n",
    "\n",
    "    # read images and combine them with their filenames on a single plot\n",
    "    # fnames = os.listdir(img_dir1)\n",
    "    # fnames = [f for f in fnames if f.endswith('.png')]\n",
    "    # only keep the ones that are in both directories\n",
    "    # fnames = [f for f in fnames if f in os.listdir(img_dir2)]\n",
    "\n",
    "    corrs = corrs_df[corrs_df['subject'] == subject]\n",
    "    # corrs = corrs.sort_values('corrs', ascending=False)\n",
    "    fnames = [v + '.png' for v in corrs['questions'].values]\n",
    "\n",
    "    n = len(fnames)\n",
    "    C = 4\n",
    "    R = int(np.ceil(n / C))\n",
    "\n",
    "    fig, axs = plt.subplots(R, C, figsize=(C * 3.2, R * 1))\n",
    "    axs = axs.flatten()\n",
    "    for i in range(len(axs)):\n",
    "        axs[i].axis('off')\n",
    "    for i, fname in enumerate(fnames):\n",
    "        img1 = plt.imread(join(img_dir1, fname))\n",
    "        img2 = plt.imread(join(img_dir2, fname))\n",
    "        axs[i].imshow(np.concatenate([img1, img2], axis=1))\n",
    "        axs[i].set_title(\n",
    "            f'{term_dict_rev[fname[:-4]]} ({corrs[\"corrs\"].values[i]:0.3f})', fontsize=8)\n",
    "\n",
    "    # add text in bottom right of figure\n",
    "    fig.text(0.99, 0.01, f'{subject}\\nNeurosynth on left, QA on right',\n",
    "             ha='right', va='bottom', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(join(repo_dir, 'qa_results', 'neurosynth',\n",
    "                subject, f'flatmaps_{setting}_{subject}.png'), dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
