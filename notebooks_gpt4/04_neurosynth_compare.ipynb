{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from ridge_utils.DataSequence import DataSequence\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cortex\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import sasc.viz\n",
    "import joblib\n",
    "import dvu\n",
    "import sys\n",
    "sys.path.append('../notebooks')\n",
    "from tqdm import tqdm\n",
    "from sasc.config import FMRI_DIR, STORIES_DIR, RESULTS_DIR\n",
    "from neuro.config import repo_dir\n",
    "from neuro import analyze_helper, viz\n",
    "from neuro.features.qa_questions import get_questions, get_merged_questions_v3_boostexamples\n",
    "flatmaps_per_question = __import__('06_flatmaps_per_question')\n",
    "from neurosynth import term_dict, term_dict_rev\n",
    "import viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, this notebook requires first running `03_export_qa_flatmaps.ipynb` into `df_qa_dict.pkl` files for each subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load \"groundtruth\" comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load neurosynth avg. flatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neurosynth_flatmaps(subject, neurosynth_dir='/home/chansingh/mntv1/deep-fMRI/qa/neurosynth_data'):\n",
    "    subject_s = subject.replace('UT', '')\n",
    "    # neurosynth_dir = '/home/chansingh/mntv1/deep-fMRI/qa/neurosynth_data/all_association-test_z'\n",
    "\n",
    "    term_names = [k.replace('.nii.gz', '').replace(\n",
    "        '_association-test_z', '') for k in os.listdir(join(neurosynth_dir, f'all_in_{subject_s}-BOLD'))]\n",
    "\n",
    "    # filter dict for files that were in neurosynth\n",
    "    term_dict_ = {k: v for k, v in term_dict.items() if k in term_names}\n",
    "    # for k in term_dict.keys():\n",
    "    #     if k not in term_names:\n",
    "    #         print(k)\n",
    "\n",
    "    # filter dict for files that had questions run\n",
    "    questions_run = [k.replace('.pkl', '') for k in os.listdir(\n",
    "        '/home/chansingh/mntv1/deep-fMRI/qa/cache_gpt')]\n",
    "    term_dict_ = {k: v for k, v in term_dict_.items() if v in questions_run}\n",
    "\n",
    "    def _load_flatmap(term, neurosynth_dir, subject):\n",
    "        # output_file = join(neurosynth_dir, f'{term}_association-test_z.nii.gz')\n",
    "        output_file = join(\n",
    "            neurosynth_dir, f'all_in_{subject_s}-BOLD/{term}.nii.gz')\n",
    "        vol = cortex.Volume(output_file, subject, subject + '_auto').data\n",
    "        mask = cortex.db.get_mask(subject, subject + '_auto')\n",
    "        return vol[mask]\n",
    "\n",
    "    return {q: _load_flatmap(\n",
    "        term, neurosynth_dir, subject) for (term, q) in term_dict_.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute correlations with qa flatmaps and plot avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = 'shapley_neurosynth'\n",
    "corrs_df_list = defaultdict(list)\n",
    "for subject in ['UTS01', 'UTS02', 'UTS03']:\n",
    "    neurosynth_flatmaps = get_neurosynth_flatmaps(subject)\n",
    "    df_qa_dict = joblib.load(\n",
    "        f'df_qa_dict_{subject.replace(\"UT\", \"\")}.pkl')[setting]\n",
    "    if isinstance(df_qa_dict, pd.DataFrame):\n",
    "        qa_flatmaps = df_qa_dict[setting].to_dict()['weights']\n",
    "    else:\n",
    "        qa_flatmaps = df_qa_dict\n",
    "\n",
    "    # get common flatmaps and put into d\n",
    "    common_keys = set(neurosynth_flatmaps.keys()) & set(\n",
    "        qa_flatmaps.keys())\n",
    "    d = defaultdict(list)\n",
    "    for k in common_keys:\n",
    "        d['questions'].append(k)\n",
    "        d['corr'].append(np.corrcoef(qa_flatmaps[k],\n",
    "                                     neurosynth_flatmaps[k])[0, 1])\n",
    "        d['flatmap_qa'].append(qa_flatmaps[k])\n",
    "        d['flatmap_neurosynth'].append(neurosynth_flatmaps[k])\n",
    "    d = pd.DataFrame(d).sort_values('corr', ascending=False)\n",
    "\n",
    "    corrs = viz._calc_corrs(\n",
    "        d['flatmap_qa'].values,\n",
    "        d['flatmap_neurosynth'].values,\n",
    "        titles_qa=d['questions'].values,\n",
    "        titles_gt=d['questions'].values,\n",
    "    )\n",
    "\n",
    "    corrs_df_list['corrs'].extend(np.diag(corrs).tolist())\n",
    "    corrs_df_list['questions'].extend(d['questions'].values.tolist())\n",
    "    corrs_df_list['subject'].extend([subject] * len(d['questions'].values))\n",
    "\n",
    "    # viz.corr_bars(\n",
    "    #     corrs,\n",
    "    #     out_dir_save=join(repo_dir, 'qa_results', 'neurosynth', setting),\n",
    "    #     xlab='Neurosynth',\n",
    "    # )\n",
    "    # plt.show()\n",
    "\n",
    "    # save flatmaps\n",
    "    # for i in tqdm(range(len(d))):\n",
    "    #     sasc.viz.quickshow(\n",
    "    #         d.iloc[i]['flatmap_qa'],\n",
    "    #         subject=subject,\n",
    "    #         fname_save=join(repo_dir, 'qa_results', 'neurosynth', subject,\n",
    "    #                         setting, f'{d.iloc[i][\"questions\"]}.png')\n",
    "    #     )\n",
    "\n",
    "    #     sasc.viz.quickshow(\n",
    "    #         d.iloc[i]['flatmap_neurosynth'],\n",
    "    #         subject=subject,\n",
    "    #         fname_save=join(repo_dir, 'qa_results', 'neurosynth', subject,\n",
    "    #                         'neurosynth', f'{d.iloc[i][\"questions\"]}.png')\n",
    "    #     )\n",
    "corrs_df = pd.DataFrame(corrs_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_df = pd.DataFrame(corrs_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_df.to_pickle(join(repo_dir, 'qa_results',\n",
    "                   'neurosynth', setting + '_corrs_df.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "colors = {\n",
    "    'UTS01': 'C0',\n",
    "    'UTS02': 'C1',\n",
    "    'UTS03': 'C2',\n",
    "    'mean': 'black'\n",
    "}\n",
    "\n",
    "d_mean = pd.DataFrame(corrs_df.groupby('questions')[\n",
    "                      'corrs'].mean()).reset_index()\n",
    "d_mean['subject'] = 'mean'\n",
    "corrs_df = pd.concat([corrs_df, d_mean])\n",
    "corrs_df = corrs_df.set_index('questions')\n",
    "\n",
    "for subject in ['mean', 'UTS01', 'UTS02', 'UTS03']:\n",
    "    r_df = corrs_df[corrs_df['subject'] == subject]\n",
    "    if subject == 'mean':\n",
    "        idx_sort = r_df['corrs'].sort_values(ascending=False).index\n",
    "\n",
    "    r_df = r_df.loc[idx_sort]\n",
    "\n",
    "    # plot corrs\n",
    "    if subject == 'mean':\n",
    "        plt.errorbar(\n",
    "            r_df['corrs'],\n",
    "            range(len(r_df)),\n",
    "            color='black',\n",
    "            fmt='o',\n",
    "            zorder=1000,\n",
    "            label=subject.capitalize(),\n",
    "        )\n",
    "    else:\n",
    "        plt.errorbar(\n",
    "            r_df['corrs'],\n",
    "            range(len(r_df)),\n",
    "            # xerr=np.sqrt(\n",
    "            # r_df['corrs'] * (1-r_df['corrs'])\n",
    "            # / r_df['num_test']),\n",
    "            alpha=0.5,\n",
    "            label=subject.upper(),\n",
    "            fmt='o')\n",
    "    plt.axvline(r_df['corrs'].mean(),\n",
    "                linestyle='--', color=colors[subject], zorder=-1000)\n",
    "\n",
    "    print('mean corr', r_df['corrs'].mean())\n",
    "\n",
    "# add horizontal bars\n",
    "plt.yticks(range(len(r_df)), [term_dict_rev[k] for k in idx_sort])\n",
    "plt.xlabel(\n",
    "    'Neurosynth flatmap correlation', fontsize='large')\n",
    "plt.grid(axis='y', alpha=0.2)\n",
    "plt.axvline(0, color='gray')\n",
    "\n",
    "abs_lim = max(np.abs(plt.xlim()))\n",
    "plt.xlim(-abs_lim, abs_lim)\n",
    "\n",
    "# annotate with baseline and text label\n",
    "plt.legend(fontsize='large')\n",
    "plt.tight_layout()\n",
    "plt.savefig(join(repo_dir, 'qa_results',\n",
    "            'neurosynth', 'corrs_' + setting + '.png'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at merged flatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_df = pd.read_pickle(join(repo_dir, 'qa_results',\n",
    "                               'neurosynth', setting + '_corrs_df.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = 'shapley_neurosynth'\n",
    "for subject in ['UTS01', 'UTS02', 'UTS03']:\n",
    "    img_dir1 = join(repo_dir, 'qa_results', 'neurosynth',\n",
    "                    subject, 'neurosynth')\n",
    "    img_dir2 = join(repo_dir, 'qa_results', 'neurosynth',\n",
    "                    subject, setting)\n",
    "\n",
    "    # read images and combine them with their filenames on a single plot\n",
    "    # fnames = os.listdir(img_dir1)\n",
    "    # fnames = [f for f in fnames if f.endswith('.png')]\n",
    "    # only keep the ones that are in both directories\n",
    "    # fnames = [f for f in fnames if f in os.listdir(img_dir2)]\n",
    "\n",
    "    corrs = corrs_df[corrs_df['subject'] == subject]\n",
    "    # corrs = corrs.sort_values('corrs', ascending=False)\n",
    "    fnames = [v + '.png' for v in corrs['questions'].values]\n",
    "\n",
    "    n = len(fnames)\n",
    "    C = 4\n",
    "    R = int(np.ceil(n / C))\n",
    "\n",
    "    fig, axs = plt.subplots(R, C, figsize=(C * 3.2, R * 1))\n",
    "    axs = axs.flatten()\n",
    "    for i in range(len(axs)):\n",
    "        axs[i].axis('off')\n",
    "    for i, fname in enumerate(fnames):\n",
    "        img1 = plt.imread(join(img_dir1, fname))\n",
    "        img2 = plt.imread(join(img_dir2, fname))\n",
    "        axs[i].imshow(np.concatenate([img1, img2], axis=1))\n",
    "        axs[i].set_title(\n",
    "            f'{term_dict_rev[fname[:-4]]} ({corrs[\"corrs\"].values[i]:0.3f})', fontsize=8)\n",
    "\n",
    "    # add text in bottom right of figure\n",
    "    fig.text(0.99, 0.01, f'{subject}\\nNeurosynth on left, QA on right',\n",
    "             ha='right', va='bottom', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(join(repo_dir, 'qa_results', 'neurosynth',\n",
    "                subject, f'flatmaps_{setting}_{subject}.png'), dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
