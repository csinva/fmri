{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "# from ridge_utils.DataSequence import DataSequence\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cortex\n",
    "# import seaborn as sns\n",
    "from os.path import join\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "# import sasc.viz\n",
    "import joblib\n",
    "# import dvu\n",
    "import sys\n",
    "sys.path.append('../notebooks')\n",
    "from neuro.config import repo_dir, PROCESSED_DIR\n",
    "from neuro import viz\n",
    "from neurosynth import term_dict, term_dict_rev\n",
    "import viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, this notebook requires first running `03_export_qa_flatmaps.ipynb` into `df_qa_dict.pkl` files for each subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load \"groundtruth\" comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load neurosynth avg. flatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neurosynth_flatmaps(subject, neurosynth_dir='/home/chansingh/mntv1/deep-fMRI/qa/neurosynth_data'):\n",
    "    subject_s = subject.replace('UT', '')\n",
    "    # neurosynth_dir = '/home/chansingh/mntv1/deep-fMRI/qa/neurosynth_data/all_association-test_z'\n",
    "\n",
    "    term_names = [k.replace('.nii.gz', '').replace(\n",
    "        '_association-test_z', '') for k in os.listdir(join(neurosynth_dir, f'all_in_{subject_s}-BOLD'))]\n",
    "\n",
    "    # filter dict for files that were in neurosynth\n",
    "    term_dict_ = {k: v for k, v in term_dict.items() if k in term_names}\n",
    "    # for k in term_dict.keys():\n",
    "    #     if k not in term_names:\n",
    "    #         print(k)\n",
    "\n",
    "    # filter dict for files that had questions run\n",
    "    questions_run = [k.replace('.pkl', '') for k in os.listdir(\n",
    "        '/home/chansingh/mntv1/deep-fMRI/qa/cache_gpt')]\n",
    "    term_dict_ = {k: v for k, v in term_dict_.items() if v in questions_run}\n",
    "\n",
    "    def _load_flatmap(term, neurosynth_dir, subject):\n",
    "        # output_file = join(neurosynth_dir, f'{term}_association-test_z.nii.gz')\n",
    "        output_file = join(\n",
    "            neurosynth_dir, f'all_in_{subject_s}-BOLD/{term}.nii.gz')\n",
    "        vol = cortex.Volume(output_file, subject, subject + '_auto').data\n",
    "        mask = cortex.db.get_mask(subject, subject + '_auto')\n",
    "        return vol[mask]\n",
    "\n",
    "    return {q: _load_flatmap(\n",
    "        term, neurosynth_dir, subject) for (term, q) in term_dict_.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute correlations with qa flatmaps and plot avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting = 'shapley_neurosynth'\n",
    "# setting = 'full_neurosynth'\n",
    "\n",
    "apply_mask = True\n",
    "frac_voxels_to_keep = 0.05\n",
    "\n",
    "\n",
    "corrs_df_list = defaultdict(list)\n",
    "for subject in ['UTS01', 'UTS02', 'UTS03']:\n",
    "    flatmaps_gt = get_neurosynth_flatmaps(subject)\n",
    "\n",
    "    flatmaps_qa_list = defaultdict(list)\n",
    "    # , 'individual_neurosynth']:\n",
    "    # for setting in ['shapley_neurosynth', 'full_neurosynth', 'individual_gpt4']:\n",
    "    for setting in ['individual_gpt4', 'individual_gpt4', 'shapley_neurosynth']:\n",
    "        flatmaps_qa = joblib.load(\n",
    "            join(PROCESSED_DIR, subject.replace('UT', ''), setting + '.pkl'))\n",
    "        for q in flatmaps_qa.keys():\n",
    "            flatmaps_qa_list[q].append(flatmaps_qa[q])\n",
    "    flatmaps_qa = {\n",
    "        q: np.mean(flatmaps_qa_list[q], axis=0)\n",
    "        for q in flatmaps_qa_list.keys()}\n",
    "\n",
    "    if apply_mask:\n",
    "        corrs_test = joblib.load(join(PROCESSED_DIR, subject.replace(\n",
    "            'UT', ''), 'corrs_test_35.pkl')).values[0]\n",
    "        # threshold top-20%\n",
    "        corrs_test_mask = (corrs_test > np.percentile(\n",
    "            corrs_test, 100 * (1 - frac_voxels_to_keep))).astype(bool)\n",
    "        flatmaps_qa = {k: flatmaps_qa[k][corrs_test_mask]\n",
    "                       for k in flatmaps_qa.keys()}\n",
    "        flatmaps_gt = {k: flatmaps_gt[k][corrs_test_mask]\n",
    "                       for k in flatmaps_gt.keys()}\n",
    "    #\n",
    "    # df_qa_dict = joblib.load(\n",
    "    #     f'df_qa_dict_{subject.replace(\"UT\", \"\")}.pkl')[setting]\n",
    "    # if isinstance(df_qa_dict, pd.DataFrame):\n",
    "    #     qa_flatmaps = df_qa_dict[setting].to_dict()['weights']\n",
    "    # else:\n",
    "    #     qa_flatmaps = df_qa_dict\n",
    "\n",
    "    # get common flatmaps and put into d\n",
    "    common_keys = set(flatmaps_gt.keys()) & set(\n",
    "        flatmaps_qa.keys())\n",
    "    d = defaultdict(list)\n",
    "    for k in common_keys:\n",
    "        d['questions'].append(k)\n",
    "        d['corr'].append(np.corrcoef(flatmaps_qa[k],\n",
    "                                     flatmaps_gt[k])[0, 1])\n",
    "        d['flatmap_qa'].append(flatmaps_qa[k])\n",
    "        d['flatmap_neurosynth'].append(flatmaps_gt[k])\n",
    "    d = pd.DataFrame(d).sort_values('corr', ascending=False)\n",
    "\n",
    "    corrs = viz._calc_corrs(\n",
    "        d['flatmap_qa'].values,\n",
    "        d['flatmap_neurosynth'].values,\n",
    "        titles_qa=d['questions'].values,\n",
    "        titles_gt=d['questions'].values,\n",
    "    )\n",
    "\n",
    "    corrs_df_list['corrs'].extend(np.diag(corrs).tolist())\n",
    "    corrs_df_list['questions'].extend(d['questions'].values.tolist())\n",
    "    corrs_df_list['subject'].extend([subject] * len(d['questions'].values))\n",
    "\n",
    "    # viz.corr_bars(\n",
    "    #     corrs,\n",
    "    #     out_dir_save=join(repo_dir, 'qa_results', 'neurosynth', setting),\n",
    "    #     xlab='Neurosynth',\n",
    "    # )\n",
    "\n",
    "    # save flatmaps\n",
    "    # for i in tqdm(range(len(d))):\n",
    "    #     sasc.viz.quickshow(\n",
    "    #         d.iloc[i]['flatmap_qa'],\n",
    "    #         subject=subject,\n",
    "    #         fname_save=join(repo_dir, 'qa_results', 'neurosynth', subject,\n",
    "    #                         setting, f'{d.iloc[i][\"questions\"]}.png')\n",
    "    #     )\n",
    "\n",
    "    #     sasc.viz.quickshow(\n",
    "    #         d.iloc[i]['flatmap_neurosynth'],\n",
    "    #         subject=subject,\n",
    "    #         fname_save=join(repo_dir, 'qa_results', 'neurosynth', subject,\n",
    "    #                         'neurosynth', f'{d.iloc[i][\"questions\"]}.png')\n",
    "    #     )\n",
    "corrs_df = pd.DataFrame(corrs_df_list)\n",
    "corrs_df.to_pickle(join(repo_dir, 'qa_results',\n",
    "                   'neurosynth', setting + '_corrs_df.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m flatmaps_qa \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mflatmaps_qa\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcorrs_test_mask\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mflatmaps_qa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m, in \u001b[0;36m<setcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m flatmaps_qa \u001b[38;5;241m=\u001b[39m {flatmaps_qa[k][corrs_test_mask]\n\u001b[1;32m      2\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m flatmaps_qa\u001b[38;5;241m.\u001b[39mkeys()}\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "flatmaps_qa2 = {flatmaps_qa[k][corrs_test_mask]\n",
    "                for k in flatmaps_qa.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,),\n",
       " (81126,)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81126,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs_test_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81126,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatmaps_qa[k].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00028814,  0.00159367,  0.00117551, ..., -0.00116768,\n",
       "        0.00050614, -0.00021409])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatmaps_qa[k][corrs_test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "colors = {\n",
    "    'UTS01': 'C0',\n",
    "    'UTS02': 'C1',\n",
    "    'UTS03': 'C2',\n",
    "    'mean': 'black'\n",
    "}\n",
    "\n",
    "d_mean = pd.DataFrame(corrs_df.groupby('questions')[\n",
    "                      'corrs'].mean()).reset_index()\n",
    "d_mean['subject'] = 'mean'\n",
    "corrs_df = pd.concat([corrs_df, d_mean])\n",
    "corrs_df = corrs_df.set_index('questions')\n",
    "\n",
    "for subject in ['mean', 'UTS01', 'UTS02', 'UTS03']:\n",
    "    r_df = corrs_df[corrs_df['subject'] == subject]\n",
    "    if subject == 'mean':\n",
    "        idx_sort = r_df['corrs'].sort_values(ascending=False).index\n",
    "\n",
    "    r_df = r_df.loc[idx_sort]\n",
    "\n",
    "    # plot corrs\n",
    "    if subject == 'mean':\n",
    "        plt.errorbar(\n",
    "            r_df['corrs'],\n",
    "            range(len(r_df)),\n",
    "            color='black',\n",
    "            fmt='o',\n",
    "            zorder=1000,\n",
    "            label=subject.capitalize(),\n",
    "        )\n",
    "    else:\n",
    "        plt.errorbar(\n",
    "            r_df['corrs'],\n",
    "            range(len(r_df)),\n",
    "            # xerr=np.sqrt(\n",
    "            # r_df['corrs'] * (1-r_df['corrs'])\n",
    "            # / r_df['num_test']),\n",
    "            alpha=0.5,\n",
    "            label=subject.upper(),\n",
    "            fmt='o')\n",
    "    plt.axvline(r_df['corrs'].mean(),\n",
    "                linestyle='--', color=colors[subject], zorder=-1000)\n",
    "\n",
    "    print('mean corr', r_df['corrs'].mean())\n",
    "\n",
    "# add horizontal bars\n",
    "plt.yticks(range(len(r_df)), [term_dict_rev[k] for k in idx_sort])\n",
    "plt.xlabel(\n",
    "    'Neurosynth flatmap correlation', fontsize='large')\n",
    "plt.grid(axis='y', alpha=0.2)\n",
    "plt.axvline(0, color='gray')\n",
    "\n",
    "abs_lim = max(np.abs(plt.xlim()))\n",
    "plt.xlim(-abs_lim, abs_lim)\n",
    "\n",
    "# annotate with baseline and text label\n",
    "plt.legend(fontsize='large')\n",
    "plt.tight_layout()\n",
    "plt.savefig(join(repo_dir, 'qa_results',\n",
    "            'neurosynth', 'corrs_' + setting + '.png'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at merged flatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_df = pd.read_pickle(join(repo_dir, 'qa_results',\n",
    "                               'neurosynth', setting + '_corrs_df.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = 'shapley_neurosynth'\n",
    "for subject in ['UTS01', 'UTS02', 'UTS03']:\n",
    "    img_dir1 = join(repo_dir, 'qa_results', 'neurosynth',\n",
    "                    subject, 'neurosynth')\n",
    "    img_dir2 = join(repo_dir, 'qa_results', 'neurosynth',\n",
    "                    subject, setting)\n",
    "\n",
    "    # read images and combine them with their filenames on a single plot\n",
    "    # fnames = os.listdir(img_dir1)\n",
    "    # fnames = [f for f in fnames if f.endswith('.png')]\n",
    "    # only keep the ones that are in both directories\n",
    "    # fnames = [f for f in fnames if f in os.listdir(img_dir2)]\n",
    "\n",
    "    corrs = corrs_df[corrs_df['subject'] == subject]\n",
    "    # corrs = corrs.sort_values('corrs', ascending=False)\n",
    "    fnames = [v + '.png' for v in corrs['questions'].values]\n",
    "\n",
    "    n = len(fnames)\n",
    "    C = 4\n",
    "    R = int(np.ceil(n / C))\n",
    "\n",
    "    fig, axs = plt.subplots(R, C, figsize=(C * 3.2, R * 1))\n",
    "    axs = axs.flatten()\n",
    "    for i in range(len(axs)):\n",
    "        axs[i].axis('off')\n",
    "    for i, fname in enumerate(fnames):\n",
    "        img1 = plt.imread(join(img_dir1, fname))\n",
    "        img2 = plt.imread(join(img_dir2, fname))\n",
    "        axs[i].imshow(np.concatenate([img1, img2], axis=1))\n",
    "        axs[i].set_title(\n",
    "            f'{term_dict_rev[fname[:-4]]} ({corrs[\"corrs\"].values[i]:0.3f})', fontsize=8)\n",
    "\n",
    "    # add text in bottom right of figure\n",
    "    fig.text(0.99, 0.01, f'{subject}\\nNeurosynth on left, QA on right',\n",
    "             ha='right', va='bottom', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(join(repo_dir, 'qa_results', 'neurosynth',\n",
    "                subject, f'flatmaps_{setting}_{subject}.png'), dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
