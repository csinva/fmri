{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from ridge_utils.DataSequence import DataSequence\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cortex\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import sasc.viz\n",
    "import joblib\n",
    "import dvu\n",
    "import sys\n",
    "sys.path.append('../notebooks')\n",
    "from tqdm import tqdm\n",
    "from sasc.config import FMRI_DIR, STORIES_DIR, RESULTS_DIR\n",
    "from neuro.config import repo_dir, PROCESSED_DIR\n",
    "from neuro import analyze_helper, viz\n",
    "from neuro.features.qa_questions import get_questions, get_merged_questions_v3_boostexamples\n",
    "flatmaps_per_question = __import__('06_flatmaps_per_question')\n",
    "from neurosynth import term_dict, term_dict_rev\n",
    "import viz\n",
    "from load_coef_flatmaps import _load_coefs_individual, _load_coefs_full, \\\n",
    "_load_coefs_individual_wordrate, _load_coefs_wordrate, _load_coefs_shapley, _load_coefs_individual_gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '/home/chansingh/mntv1/deep-fMRI/encoding/aug14_neurosynth_gemv'\n",
    "rr, cols_varied, mets = analyze_helper.load_clean_results(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '/home/chansingh/mntv1/deep-fMRI/encoding/jun16_gpt4'\n",
    "rr_gpt4, cols_varied, mets = analyze_helper.load_clean_results(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_dir = '/home/chansingh/mntv1/deep-fMRI/encoding/jun16_gpt4'\n",
    "# rr, cols_varied, mets = analyze_helper.load_clean_results(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _load_coefs_full(\n",
    "    rr, subject=subject, qa_questions_version='v3_boostexamples_merged',\n",
    "    use_added_wordrate_feature=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:12<00:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 questions 35 weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "r = rr\n",
    "subject = 'S02'\n",
    "qa_questions_version = 'v3_boostexamples_merged'\n",
    "use_added_wordrate_feature = 1\n",
    "\n",
    "r = r[r.qa_questions_version == qa_questions_version]\n",
    "r = r[r.feature_space == 'qa_embedder']\n",
    "r = r[r.subject == subject]\n",
    "r = r[r.use_random_subset_features == 0]\n",
    "r = r[r.use_added_wordrate_feature == 1]\n",
    "r = r[r.single_question_idx > -1]\n",
    "args0 = r[r.subject == subject].iloc[0]\n",
    "\n",
    "if qa_questions_version == 'v3_boostexamples_merged':\n",
    "    questions = get_merged_questions_v3_boostexamples()\n",
    "    questions = np.array(questions)[args0.weight_enet_mask]\n",
    "else:\n",
    "    questions = get_questions(qa_questions_version)\n",
    "\n",
    "# print(sorted(r.single_question_idx.unique()))\n",
    "assert r.single_question_idx.nunique() == len(\n",
    "    questions), f'{r.single_question_idx.nunique()} != {len(questions)}'\n",
    "assert len(r) == len(questions), f'{len(r)} != {len(questions)}'\n",
    "args0 = r[r.subject == subject].iloc[0]\n",
    "weights = np.array([\n",
    "    flatmaps_per_question.get_weights_top(r.iloc[i])[0]\n",
    "    for i in tqdm(range(len(r)))\n",
    "]).squeeze()\n",
    "print(len(questions), 'questions', len(weights), 'weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatmaps_per_question.get_weights_top(r.iloc[i])[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject = 'S02'\n",
    "for subject in ['S02', 'S01', 'S03']:\n",
    "\n",
    "    # df = _load_coefs_individual_gpt4(rr_gpt4, subject=subject)\n",
    "    # joblib.dump(df, join(PROCESSED_DIR, subject, 'individual_gpt4.pkl'))\n",
    "\n",
    "    # df = _load_coefs_individual(\n",
    "    # rr, subject=subject, qa_questions_version='v1neurosynth')\n",
    "    # joblib.dump(df, join(PROCESSED_DIR, subject, 'individual_neurosynth.pkl'))\n",
    "\n",
    "    # df = _load_coefs_individual(\n",
    "    #     rr, subject=subject, qa_questions_version='v3_boostexamples_merged')\n",
    "    # joblib.dump(df, join(PROCESSED_DIR, subject, 'individual_35.pkl'))\n",
    "\n",
    "    # df = _load_coefs_full(\n",
    "    #     rr, subject=subject, qa_questions_version='v3_boostexamples_merged')\n",
    "    # joblib.dump(df, join(PROCESSED_DIR, subject, 'full_35.pkl'))\n",
    "\n",
    "    # df = _load_coefs_full(\n",
    "    #     rr, subject=subject, qa_questions_version='v1neurosynth')\n",
    "    # joblib.dump(df, join(PROCESSED_DIR, subject, 'full_neurosynth.pkl'))\n",
    "\n",
    "    df = _load_coefs_shapley(\n",
    "        rr, subject, qa_questions_version='v3_boostexamples_merged')\n",
    "    joblib.dump(df, join(\n",
    "        PROCESSED_DIR, subject, 'shapley_35.pkl'))\n",
    "\n",
    "    # df = _load_coefs_shapley(\n",
    "    #     rr, subject, qa_questions_version='v1neurosynth')\n",
    "    # joblib.dump(df, join(PROCESSED_DIR,\n",
    "    #             subject, 'shapley_neurosynth.pkl'))\n",
    "\n",
    "    ########### use old models ###################\n",
    "    # jointly fitted 35-question model\n",
    "    # df_w_selected35 = _load_coefs_35questions(subject=subject)\n",
    "\n",
    "    # individually fitted question models\n",
    "    # df_w_individual = _load_coefs_individual(rr_shapley, subject=subject)\n",
    "    # joblib.dump(df_w_individual, join(PROCESSED_DIR,\n",
    "    # subject, 'individual.pkl'))\n",
    "\n",
    "    # individually fitted question models *with wordrate\n",
    "    # df_w_individual_wordrate = _load_coefs_individual_wordrate(\n",
    "    # subject=subject)\n",
    "\n",
    "    # wordrate\n",
    "    # df_w_wordrate_alone = _load_coefs_wordrate(subject=subject)\n",
    "\n",
    "    # # collate individual dfs #########################\n",
    "    # # average weights for df_w_selected35 and df_w_individual\n",
    "    # if subject == 'S02':\n",
    "    #     df_avg = df_w_selected35.merge(df_w_individual, on='question')\n",
    "    #     df_avg['weights'] = df_avg.apply(\n",
    "    #         lambda x: np.mean([x['weights_x'], x['weights_y']], axis=0), axis=1)\n",
    "\n",
    "    # df_avg_individual = df_w_individual.merge(\n",
    "    #     df_w_individual_wordrate, on='question')\n",
    "    # df_avg_individual['weights'] = df_avg_individual.apply(\n",
    "    #     lambda x: np.mean([x['weights_x'], x['weights_y']], axis=0), axis=1)\n",
    "\n",
    "    # df_qa_dict = {\n",
    "    #     'selected35': df_w_selected35,\n",
    "    #     'individual': df_w_individual,\n",
    "    #     'individual_wordrate': df_w_individual_wordrate,\n",
    "    #     'wordrate_alone': df_w_wordrate_alone,\n",
    "    #     # 'avg': df_avg,\n",
    "    #     'shapley_neurosynth': df_w_shapley_neurosynth,\n",
    "    #     'shapley35': df_w_shapley35,\n",
    "    #     'avg_individual': df_avg_individual\n",
    "    # }\n",
    "    # joblib.dump(df_qa_dict, f'df_qa_dict_{subject}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
