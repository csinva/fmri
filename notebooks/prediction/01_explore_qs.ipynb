{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../experiments')\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "from neuro.features import qa_questions, feature_spaces\n",
    "import dvu\n",
    "import logging\n",
    "import joblib\n",
    "logger = logging.getLogger()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "dvu.set_style()\n",
    "fit_encoding = __import__('02_fit_encoding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save answers to questions across all ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read and export some questions\n",
    "# qs = pd.read_csv('../qa_results/v3_boostexamples_num=29/questions.csv')\n",
    "# qs = (\n",
    "#     qs.rename(columns={'question': 'Question',\n",
    "#               'avg_abs_coef_normalized': 'Importance'})\n",
    "#     .to_latex(escape=False, column_format='lrrrr', float_format='%.3f', index=False)\n",
    "# )\n",
    "# for s in ['Does the sentence', 'Is the sentence', 'Does the input', 'in the input?', '?']:\n",
    "#     qs = qs.replace(s, r'\\textcolor{gray}{' + s + '}')\n",
    "# print(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    use_test_setup = False\n",
    "    subject = 'UTS03'\n",
    "    feature_space = 'qa_embedder'\n",
    "    # qa_embedding_model = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "    # qa_embedding_model = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "    qa_embedding_model = 'meta-llama/Meta-Llama-3-8B-Instruct-fewshot'\n",
    "    # qa_embedding_model = 'meta-llama/Meta-Llama-3-70B-Instruct'\n",
    "    # qa_embedding_model = 'ensemble1'\n",
    "    trim = 5\n",
    "    num_stories = -1\n",
    "    # num_stories = 2\n",
    "    seed_stories = 1\n",
    "    use_huge = 1\n",
    "    input_chunking_type = 'ngram'\n",
    "    input_chunking_size = 10\n",
    "    embedding_layer = -1\n",
    "    use_brain_drive = False\n",
    "\n",
    "\n",
    "train_or_test = 'train'\n",
    "# train_or_test = 'test'\n",
    "args = A()\n",
    "story_names_train, story_names_test = fit_encoding.get_story_names(args)\n",
    "if train_or_test == 'train':\n",
    "    story_names = story_names_train\n",
    "else:\n",
    "    story_names = story_names_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get downsampled features\n",
    "# features_downsampled_list = []\n",
    "# for qa_questions_version in ['v1']:\n",
    "#     # Features\n",
    "#     features_downsampled_dict = feature_spaces.get_features(\n",
    "#         args.feature_space,\n",
    "#         allstories=story_names_train,\n",
    "#         qa_embedding_model=args.qa_embedding_model,\n",
    "#         qa_questions_version=qa_questions_version,\n",
    "#     )\n",
    "#     # n_time_points x n_features\n",
    "#     features_downsampled = encoding_utils.trim_and_normalize_features(\n",
    "#         features_downsampled_dict, args.trim, normalize=True\n",
    "#     )\n",
    "#     features_downsampled_list.append(deepcopy(features_downsampled))\n",
    "# features_downsampled_list = np.hstack(features_downsampled_list)\n",
    "\n",
    "# # transform so feats is (features x n_time_points)\n",
    "# feats = features_downsampled_list.T\n",
    "\n",
    "# get non-downsampled features\n",
    "features_downsampled_list = []\n",
    "ngrams_list = []\n",
    "for qa_questions_version in ['v1', 'v2', 'v3_boostexamples']:\n",
    "    # Features (this doesn't support ensemble1!)\n",
    "    allstories, vectors, wordseqs, ngrams_list_dict = feature_spaces.get_features(\n",
    "        args=args,\n",
    "        feature_space=args.feature_space,\n",
    "        story_names=story_names,\n",
    "        qa_embedding_model=args.qa_embedding_model,\n",
    "        qa_questions_version=qa_questions_version,\n",
    "        downsample=False,\n",
    "        use_huge=args.use_huge,\n",
    "        use_brain_drive=args.use_brain_drive,\n",
    "    )\n",
    "    # n_time_points x n_features\n",
    "    # features_downsampled = encoding_utils.trim_and_normalize_features(\n",
    "    # features_downsampled_dict, args.trim, normalize=True\n",
    "    # )\n",
    "    features = np.vstack([vectors[k] for k in vectors.keys()])\n",
    "    ngrams_list = sum([ngrams_list_dict[k]\n",
    "                      for k in ngrams_list_dict.keys()], [])\n",
    "    features_downsampled_list.append(deepcopy(features))\n",
    "    # ngrams_list.append(ngrams)\n",
    "    # assert len(ngrams) == features.shape[0]\n",
    "features_downsampled_list = np.hstack(features_downsampled_list)\n",
    "\n",
    "# transform so feats is (features x n_time_points)\n",
    "feats = features_downsampled_list.T\n",
    "\n",
    "# # export to csv\n",
    "qa_questions_version = 'v3_boostexamples'\n",
    "qs = qa_questions.get_questions(qa_questions_version, full=True)\n",
    "\n",
    "# # save compressed\n",
    "folder_name = f'../data/{args.qa_embedding_model.replace(\"/\", \"___\")}'\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "np.savez_compressed(\n",
    "    f'{folder_name}/{qa_questions_version}_answers_{train_or_test}_numpy',\n",
    "    feats.astype(bool).T)\n",
    "joblib.dump({'columns': qs, 'index': ngrams_list, 'story_names': story_names},\n",
    "            f'{folder_name}/{qa_questions_version}_{train_or_test}_metadata.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze answers to questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_embedding_model = 'meta-llama/Meta-Llama-3-70B-Instruct'\n",
    "folder = f'../data/{qa_embedding_model.replace(\"/\", \"___\")}'\n",
    "yes_no_answers = np.load(\n",
    "    f'{folder}/v3_boostexamples_answers_train_numpy.npz')['arr_0']\n",
    "metadata = joblib.load(\n",
    "    f'{folder}/v3_boostexamples_train_metadata.pkl')\n",
    "features_df = pd.DataFrame(\n",
    "    yes_no_answers, index=metadata['index'], columns=metadata['columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame(\n",
    "    yes_no_answers, index=metadata['index'], columns=metadata['columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuro.features.questions.gpt4 import QS_35_STABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = features_df[QS_35_STABLE]\n",
    "corrs = feats.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustermap = sns.clustermap(corrs)\n",
    "plt.close()\n",
    "corrs = corrs.iloc[:, clustermap.dendrogram_col.reordered_ind]\n",
    "corrs = corrs.iloc[clustermap.dendrogram_row.reordered_ind, :]\n",
    "\n",
    "# cbar in bottom right\n",
    "# sns.clustermap(\n",
    "sns.heatmap(\n",
    "    corrs,\n",
    "    # cbar_pos=(0.85, 0.03, 0.03, 0.2),\n",
    "    # figsize=(20, 20),\n",
    "    cbar_kws={'label': '$\\\\rho$'},\n",
    "    vmin=-1, vmax=1, cmap='RdBu_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_triu = corrs.where(np.triu(np.ones(corrs.shape), k=1).astype(bool))\n",
    "plt.hist(corrs_triu.values.flatten(), bins=100)\n",
    "plt.xlabel('Pairwise correlation')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indexes/columns of high correlations\n",
    "high_corr = corrs_triu[corrs_triu > 0.6].stack().index\n",
    "high_corr_idx = [(high_corr[i][0], high_corr[i][1])\n",
    "                 for i in range(len(high_corr))]\n",
    "high_corr_vals = [corrs_triu.loc[high_corr[i][0], high_corr[i][1]]\n",
    "                  for i in range(len(high_corr))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(high_corr_idx)):\n",
    "    print(high_corr_vals[i])\n",
    "    print('\\t', high_corr_idx[i][0])\n",
    "    print('\\t', high_corr_idx[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_fracs = pd.DataFrame({\n",
    "    'yes_frac': feats.mean(axis=1),\n",
    "    'question': qs_1,\n",
    "}).sort_values(by='yes_frac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display full width and non-truncated strings\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', None, 'display.max_colwidth', None):\n",
    "    display(yes_fracs.head(30).round(3))\n",
    "    display(yes_fracs.tail(30).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exact sparsity doesnt work that well bc of lanczos sampling\n",
    "# feat_mins = np.zeros(feats.shape[0])\n",
    "# for i in range(feats.shape[0]):\n",
    "# feat_mins[i] = (feats[i] == np.min(feats[i])).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
