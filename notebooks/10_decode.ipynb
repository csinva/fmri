{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ridge_utils.DataSequence import DataSequence\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import dirname\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from neuro.features import qa_questions, feature_spaces\n",
    "from neuro.data import story_names, response_utils\n",
    "from neuro.features.stim_utils import load_story_wordseqs, load_story_wordseqs_huge\n",
    "import neuro.config\n",
    "import seaborn as sns\n",
    "from neuro.features.questions.gpt4 import QS_35_STABLE\n",
    "import numpy as np\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "from os.path import join\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from neuro import analyze_helper\n",
    "import dvu\n",
    "from copy import deepcopy\n",
    "dvu.set_style()\n",
    "data_dir = join(neuro.config.repo_dir, 'data', 'decoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fmri_and_labs(data_dir, story_name='onapproachtopluto', train_or_test='test', subject='uts03'):\n",
    "    '''\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        The fMRI features, with columns corresponding to the principal components\n",
    "        of the fMRI data.\n",
    "    labs : pd.DataFrame\n",
    "        Binary labeled annotations for each of the texts\n",
    "    texts: \n",
    "        The texts corresponding to the rows of df\n",
    "    '''\n",
    "    df = joblib.load(\n",
    "        join(data_dir, subject, train_or_test, story_name + '.pkl'))\n",
    "    dfs = []\n",
    "    for offset in [1, 2, 3, 4]:\n",
    "        df_offset = df.shift(-offset)\n",
    "        df_offset.columns = [col + f'_{offset}' for col in df.columns]\n",
    "        dfs.append(df_offset)\n",
    "    df = pd.concat(dfs, axis=1)  # .dropna()  # would want to dropna here\n",
    "\n",
    "    # load labels\n",
    "    labs = joblib.load(\n",
    "        join(data_dir, 'labels', train_or_test, story_name + '_labels.pkl'))\n",
    "\n",
    "    # drop rows with nans\n",
    "    idxs_na = df.isna().sum(axis=1).values > 0\n",
    "    df = df[~idxs_na]\n",
    "    labs = labs[~idxs_na]\n",
    "    texts = pd.Series(df.index)\n",
    "    return df, labs, texts\n",
    "\n",
    "\n",
    "def concatenate_running_texts(texts, frac=1/2):\n",
    "    '''When decoding, you might want to concatenate \n",
    "    the text of the current and surrounding texts\n",
    "    to deal with the temporal imprecision of the fMRI signal.\n",
    "    '''\n",
    "    texts_before = (\n",
    "        texts.shift(1)\n",
    "        .str.split().apply(  # only keep second half of words\n",
    "            lambda l: ' '.join(l[int(-len(l) * frac):]) if l else '')\n",
    "    )\n",
    "\n",
    "    texts_after = (\n",
    "        texts.shift(-1)\n",
    "        .str.split().apply(  # only keep first half of words\n",
    "            lambda l: ' '.join(l[:int(len(l) * frac)]) if l else '')\n",
    "    )\n",
    "\n",
    "    return texts_before + ' ' + texts + ' ' + texts_after\n",
    "\n",
    "# example get data\n",
    "# df_orig, labs, texts = get_fmri_and_labs(data_dir)\n",
    "# texts = concatenate_running_texts(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run decode for all questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the data for a single subject\n",
    "data_by_subject = {}\n",
    "for subject in ['uts01', 'uts02', 'uts03']:\n",
    "    data = defaultdict(list)\n",
    "    for train_or_test in ['test', 'train']:\n",
    "        story_names_list = os.listdir(join(data_dir, subject, train_or_test))\n",
    "        for story_name in story_names_list:\n",
    "            df, labs, texts = get_fmri_and_labs(\n",
    "                data_dir, story_name.replace('.pkl', ''), train_or_test, subject)\n",
    "            data['df_' + train_or_test].append(df)\n",
    "            data['labs_' + train_or_test].append(labs)\n",
    "            data['texts_' + train_or_test].append(texts)\n",
    "\n",
    "    for k in data:\n",
    "        data[k] = pd.concat(data[k], axis=0)\n",
    "    data_by_subject[subject] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/86 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33484, 800) (33484,) (898, 800) (898,)\n",
      "label 0 Does the input contain a measurement? (5862, 800) (238, 800)\n"
     ]
    }
   ],
   "source": [
    "# set to None to keep all coefs\n",
    "num_coefs_to_keep = None\n",
    "\n",
    "\n",
    "def _keep_only_few_coefs(X, num_coefs_to_keep, num_features=200, num_delays=4):\n",
    "    if num_coefs_to_keep is None:\n",
    "        return X\n",
    "    else:\n",
    "        idxs_to_keep = np.arange(num_coefs_to_keep)\n",
    "        idxs_to_keep = np.concatenate(\n",
    "            [idxs_to_keep + i * num_features for i in range(num_delays)])\n",
    "        return X[:, idxs_to_keep]\n",
    "\n",
    "\n",
    "for subject in ['uts01', 'uts02', 'uts03'][::-1]:\n",
    "    data = data_by_subject[subject]\n",
    "\n",
    "    # example fit linear decoder\n",
    "    r = defaultdict(list)\n",
    "    for label_num in tqdm(range(data['labs_train'].shape[1])):\n",
    "        X_train, y_train = data['df_train'].values, data['labs_train'].values[:, label_num]\n",
    "        X_test, y_test = data['df_test'].values, data['labs_test'].values[:, label_num]\n",
    "        print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "        # balance the binary class imbalance\n",
    "        try:\n",
    "            rus = RandomUnderSampler(random_state=42)\n",
    "            X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "            X_test, y_test = rus.fit_resample(X_test, y_test)\n",
    "\n",
    "            # only keep 5 feats\n",
    "            X_train = _keep_only_few_coefs(X_train, num_coefs_to_keep)\n",
    "            X_test = _keep_only_few_coefs(X_test, num_coefs_to_keep)\n",
    "\n",
    "            if len(y_test) < 30:\n",
    "                print('too few positive labels', label_num)\n",
    "                continue\n",
    "\n",
    "            print('label', label_num,\n",
    "                  data['labs_train'].columns[label_num], X_train.shape, X_test.shape)\n",
    "            m = LogisticRegressionCV(random_state=42)\n",
    "            m.fit(X_train, y_train)\n",
    "            test_acc = m.score(X_test, y_test)\n",
    "            print(\n",
    "                f\"\"\"\\ttest acc {test_acc:.3f}\"\"\")  # \\n\\tnaive acc {1 -y_test.mean():.3f}\"\"\")\n",
    "            r['label'].append(data['labs_train'].columns[label_num])\n",
    "            # y_pred = m.predict(X_test)\n",
    "            # balanced_accuracy_score(y_test, y_pred))\n",
    "            r['test_acc'].append(test_acc)\n",
    "            r['num_test'].append(len(y_test))\n",
    "            r['coef'].append(m.coef_.copy())\n",
    "\n",
    "            # extra test data from another subject ##########\n",
    "            test_acc_ood = []\n",
    "            for subject_ood in ['uts01', 'uts02', 'uts03']:\n",
    "                if subject_ood == subject:\n",
    "                    continue\n",
    "                X_test_ood, y_test_ood = data_by_subject[subject_ood][\n",
    "                    'df_test'].values, data_by_subject[subject_ood]['labs_test'].values[:, label_num]\n",
    "\n",
    "                # balance the binary class imbalance\n",
    "\n",
    "                rus = RandomUnderSampler(random_state=42)\n",
    "                X_test_ood, y_test_ood = rus.fit_resample(\n",
    "                    X_test_ood, y_test_ood)\n",
    "\n",
    "                # except:\n",
    "                #     print('too few positive labels', label_num)\n",
    "                #     continue\n",
    "                # if len(y_test_ood) < 30:\n",
    "                #     continue\n",
    "\n",
    "                # only keep 5 feats\n",
    "                X_test_ood = _keep_only_few_coefs(\n",
    "                    X_test_ood, num_coefs_to_keep)\n",
    "\n",
    "                test_acc_ood_subject = m.score(X_test_ood, y_test_ood)\n",
    "                test_acc_ood.append(test_acc_ood_subject)\n",
    "            r['test_acc_ood'].append(np.mean(test_acc_ood))\n",
    "\n",
    "            print(f\"\"\"\\ttest acc ood {np.mean(test_acc_ood):.3f}\"\"\")\n",
    "            ###############################################\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('error for', label_num)\n",
    "            continue\n",
    "    r_df = pd.DataFrame(r)\n",
    "    # .sort_values(\n",
    "    # metric, ascending=False).reset_index()\n",
    "    r_df.to_pickle(join(data_dir, f'r_df_{subject}.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot learned decoding scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(13, 13))\n",
    "plt.figure(figsize=(8, 8))\n",
    "fig, ax = plt.subplots()\n",
    "colors = {\n",
    "    'uts01': 'C0',\n",
    "    'uts02': 'C1',\n",
    "    'uts03': 'C2',\n",
    "    'mean': 'black'\n",
    "}\n",
    "metric = 'test_acc'\n",
    "# metric = 'test_acc_ood'\n",
    "for subject in ['mean', 'uts01', 'uts02', 'uts03']:\n",
    "    if subject == 'mean':\n",
    "        dfs = [pd.read_pickle(join(data_dir, f'r_df_{subject}.pkl'))\n",
    "               for subject in ['uts01', 'uts02', 'uts03']]\n",
    "        r_df = pd.concat(dfs, axis=0).groupby('label').mean().reset_index()\n",
    "        idx_sort = r_df[metric].sort_values(ascending=False).index\n",
    "    else:\n",
    "        r_df = pd.read_pickle(join(data_dir, f'r_df_{subject}.pkl'))\n",
    "\n",
    "    r_df = r_df.loc[idx_sort]\n",
    "    r_df = r_df[r_df['label'].isin(QS_35_STABLE)]\n",
    "\n",
    "    # plot accuracy with binomial error bars\n",
    "    if subject == 'mean':\n",
    "        plt.errorbar(\n",
    "            r_df[metric],\n",
    "            range(len(r_df)),\n",
    "            color='black',\n",
    "            fmt='o',\n",
    "            ms=4,\n",
    "            zorder=1000,\n",
    "            label=subject.capitalize(),\n",
    "        )\n",
    "        plt.axvline(r_df[metric].mean(), color=colors[subject])\n",
    "    else:\n",
    "        plt.errorbar(\n",
    "            r_df[metric],\n",
    "            range(len(r_df)),\n",
    "            xerr=np.sqrt(\n",
    "                r_df[metric] * (1-r_df[metric])\n",
    "                / r_df['num_test']),\n",
    "            alpha=0.5,\n",
    "            label=subject.upper(),\n",
    "            fmt='o',\n",
    "            ms=4,\n",
    "        )\n",
    "        plt.axvline(r_df[metric].mean(),\n",
    "                    linestyle='--', color=colors[subject])\n",
    "\n",
    "    print('mean acc', r_df[metric].mean())\n",
    "\n",
    "fs = 'x-small'\n",
    "# add horizontal bars\n",
    "labs = [analyze_helper.abbrev_question(q) for q in r_df['label']]\n",
    "plt.yticks(range(len(r_df)), labs, fontsize=fs)\n",
    "plt.xlabel(\n",
    "    'Decoding accuracy', fontsize=fs)\n",
    "plt.xticks(fontsize=fs)\n",
    "# ax.yaxis.set_major_locator(ticker.MultipleLocator(2))\n",
    "# Get the current tick locations\n",
    "xticks = ax.get_xticks()\n",
    "yticks = ax.get_yticks()\n",
    "\n",
    "# Select every other tick\n",
    "# ax.set_xticks(xticks[::2])\n",
    "ax.set_yticks(yticks[::2], minor=True)\n",
    "ax.grid(True, which='major', linewidth=0.7, alpha=0.6)\n",
    "\n",
    "\n",
    "# annotate with baseline and text label\n",
    "plt.axvline(0.5, color='darkgray', linestyle='--')\n",
    "plt.text(0.51, 0, 'Chance', color='darkgray', fontsize=fs, ha='left')\n",
    "plt.legend(fontsize='small')\n",
    "plt.tight_layout()\n",
    "plt.savefig('linear_decoding.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize learned coefs on cortex map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'uts03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_comps = joblib.load(f'{subject}/pca_components.pkl')\n",
    "# vertically stack pca_comps 4 times\n",
    "pca_comps = np.vstack([pca_comps]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quickshow(X: np.ndarray, subject=\"UTS03\", fname_save=None, title=None):\n",
    "    import cortex\n",
    "\n",
    "    \"\"\"\n",
    "    Actual visualizations\n",
    "    Note: for this to work, need to point the cortex config filestore to the `ds003020/derivative/pycortex-db` directory.\n",
    "    This might look something like `/home/chansingh/mntv1/deep-fMRI/data/ds003020/derivative/pycortex-db/UTS03/anatomicals/`\n",
    "    \"\"\"\n",
    "    vol = cortex.Volume(X, subject, xfmname=f\"{subject}_auto\")\n",
    "    # , with_curvature=True, with_sulci=True)\n",
    "    vabs = max(abs(vol.data.min()), abs(vol.data.max()))\n",
    "    vol.vmin = -vabs\n",
    "    vol.vmax = vabs\n",
    "    # fig = plt.figure()\n",
    "    # , vmin=-vabs, vmax=vabs)\n",
    "    cortex.quickshow(vol, with_rois=True, cmap=\"PuBu\")\n",
    "    # fig = plt.gcf()\n",
    "    # add title\n",
    "    # fig.axes[0].set_title(title, fontsize='xx-small')\n",
    "    if fname_save is not None:\n",
    "        plt.savefig(fname_save)\n",
    "        # plt.savefig(fname_save.replace(\".pdf\", \".png\"))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(r_df)):\n",
    "    pc_coef = r_df.iloc[i]['coef']\n",
    "    voxel_coefs = (pc_coef @ pca_comps).squeeze()\n",
    "    quickshow(voxel_coefs, fname_save=join(\n",
    "        'flatmaps_decoding', f'{r_df.iloc[i][\"label\"]}.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
