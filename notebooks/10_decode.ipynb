{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ridge_utils.DataSequence import DataSequence\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import dirname\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from neuro.features import qa_questions, feature_spaces\n",
    "from neuro.data import story_names, response_utils\n",
    "from neuro.features.stim_utils import load_story_wordseqs, load_story_wordseqs_huge\n",
    "import neuro.config\n",
    "import seaborn as sns\n",
    "from neuro.features.questions.gpt4 import QS_35_STABLE\n",
    "import numpy as np\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "from os.path import join\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from neuro import analyze_helper\n",
    "import dvu\n",
    "import sasc.viz\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import numpy as np\n",
    "from neuro.analyze_helper import abbrev_question\n",
    "from neuro.config import repo_dir, PROCESSED_DIR, setup_freesurfer\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"pickle\")\n",
    "import decode\n",
    "dvu.set_style()\n",
    "data_dir = join(neuro.config.repo_dir, 'data', 'decoding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot decoding acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(13, 13))\n",
    "plt.figure(figsize=(8, 8))\n",
    "fig, ax = plt.subplots()\n",
    "colors = {\n",
    "    'uts01': 'C0',\n",
    "    'uts02': 'C1',\n",
    "    'uts03': 'C2',\n",
    "    'mean': 'black'\n",
    "}\n",
    "metric = 'test_acc'\n",
    "# metric = 'test_acc_ood'\n",
    "for subject in ['mean', 'uts01', 'uts02', 'uts03']:\n",
    "    r_df = decode._load_result(subject)\n",
    "    if subject == 'mean':\n",
    "        idx_sort = r_df[metric].sort_values(ascending=False).index\n",
    "\n",
    "    r_df = r_df.loc[idx_sort]\n",
    "    r_df = r_df[r_df['label'].isin(QS_35_STABLE)]\n",
    "\n",
    "    # plot accuracy with binomial error bars\n",
    "    if subject == 'mean':\n",
    "        plt.errorbar(\n",
    "            r_df[metric],\n",
    "            range(len(r_df)),\n",
    "            color='black',\n",
    "            fmt='o',\n",
    "            ms=4,\n",
    "            zorder=1000,\n",
    "            label=subject.capitalize(),\n",
    "        )\n",
    "        plt.axvline(r_df[metric].mean(), color=colors[subject])\n",
    "    else:\n",
    "        plt.errorbar(\n",
    "            r_df[metric],\n",
    "            range(len(r_df)),\n",
    "            xerr=np.sqrt(\n",
    "                r_df[metric] * (1-r_df[metric])\n",
    "                / r_df['num_test']),\n",
    "            alpha=0.5,\n",
    "            label=subject.upper(),\n",
    "            fmt='o',\n",
    "            ms=4,\n",
    "        )\n",
    "        plt.axvline(r_df[metric].mean(),\n",
    "                    linestyle='--', color=colors[subject])\n",
    "\n",
    "    print('mean acc', r_df[metric].mean())\n",
    "\n",
    "fs = 'x-small'\n",
    "# add horizontal bars\n",
    "labs = [analyze_helper.abbrev_question(q) for q in r_df['label']]\n",
    "plt.yticks(range(len(r_df)), labs, fontsize=fs)\n",
    "plt.xlabel(\n",
    "    'Decoding accuracy', fontsize=fs)\n",
    "plt.xticks(fontsize=fs)\n",
    "# ax.yaxis.set_major_locator(ticker.MultipleLocator(2))\n",
    "# Get the current tick locations\n",
    "xticks = ax.get_xticks()\n",
    "yticks = ax.get_yticks()\n",
    "\n",
    "# Select every other tick\n",
    "# ax.set_xticks(xticks[::2])\n",
    "ax.set_yticks(yticks[::2], minor=True)\n",
    "ax.grid(True, which='major', linewidth=0.7, alpha=0.6)\n",
    "\n",
    "\n",
    "# annotate with baseline and text label\n",
    "plt.axvline(0.5, color='darkgray', linestyle='--')\n",
    "plt.text(0.51, 0, 'Chance', color='darkgray', fontsize=fs, ha='left')\n",
    "plt.legend(fontsize='small')\n",
    "plt.tight_layout()\n",
    "plt.savefig('linear_decoding.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize decoding weight flatmaps (and plot with encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in ['uts01', 'uts02', 'uts03']:\n",
    "    # subject = 'uts03'\n",
    "    pca_comps = joblib.load(join(data_dir, f'{subject}/pca_components.pkl'))\n",
    "    # vertically stack pca_comps 4 times\n",
    "    pca_comps = np.vstack([pca_comps]*4)\n",
    "    r_df = decode._load_result(subject)\n",
    "\n",
    "    for i in tqdm(range(len(r_df))):\n",
    "        pc_coef = r_df.iloc[i]['coef']\n",
    "        question = r_df.iloc[i]['label']\n",
    "        if question not in QS_35_STABLE:\n",
    "            continue\n",
    "        voxel_coefs = (pc_coef @ pca_comps).squeeze()\n",
    "        sasc.viz.quickshow(\n",
    "            voxel_coefs,\n",
    "            subject,\n",
    "            fname_save=join(data_dir, 'flatmaps_decoding', subject, f'{question}.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames_arr = []\n",
    "\n",
    "# make grid of plots\n",
    "nrows = 6\n",
    "ncols = 35\n",
    "axes = plt.subplots(nrows=nrows, ncols=ncols,\n",
    "                    figsize=(4.5 * ncols, 3 * nrows))[1]\n",
    "\n",
    "for i, subject in enumerate(['uts01', 'uts02', 'uts03']):\n",
    "    for j, label in enumerate(tqdm(QS_35_STABLE)):\n",
    "        fname = join(data_dir, 'flatmaps_decoding', subject, f'{label}.png')\n",
    "        axes[i, j].imshow(mpimg.imread(fname))\n",
    "        axes[i, j].axis('off')\n",
    "        if i == 0:\n",
    "            axes[i, j].set_title(abbrev_question(label), fontsize='x-small')\n",
    "        if j == 0:\n",
    "            # axes[i, j].set_ylabel(\n",
    "            # subject.upper() + ' Decode', fontsize='x-small')\n",
    "            # show rotated text where ylabel would be\n",
    "            axes[i, j].text(-0.5, 0.5, subject.upper() + ' Decode',\n",
    "                            fontsize='x-small', rotation=90, ha='center', va='center')\n",
    "\n",
    "        fname_enc = join(repo_dir, 'qa_results', 'figs',\n",
    "                         'flatmaps_export', subject.upper().replace('UT', ''), label + '.png')\n",
    "        axes[3 + i, j].imshow(mpimg.imread(fname_enc))\n",
    "        axes[3 + i, j].axis('off')\n",
    "        if j == 0:\n",
    "            # axes[3 + i, j].set_ylabel(subject.upper() +\n",
    "            #   ' Encode', fontsize='x-small')\n",
    "            # show rotated text where ylabel would be\n",
    "            axes[3 + i, j].text(-0.5, 0.5, subject.upper() + ' Encode',\n",
    "                                fontsize='x-small', rotation=90, ha='center', va='center')\n",
    "\n",
    "plt.savefig(join(data_dir, 'flatmaps_decoding', 'all.pdf'))  # , dpi=300)\n",
    "# for subject in ['uts01', 'uts02', 'uts03']:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare enc/dec flatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = defaultdict(list)\n",
    "flatmaps = defaultdict(list)\n",
    "for subject in ['S01', 'S02', 'S03']:\n",
    "    subject_dec = 'ut' + subject.lower()\n",
    "\n",
    "    # subject = 'uts03'\n",
    "    pca_comps = joblib.load(\n",
    "        join(data_dir, f'{subject_dec}/pca_components.pkl'))\n",
    "    # vertically stack pca_comps 4 times\n",
    "    pca_comps = np.vstack([pca_comps]*4)\n",
    "    r_df = _load_result(subject_dec).set_index('label').loc[QS_35_STABLE]\n",
    "\n",
    "    for i, q in tqdm(enumerate(QS_35_STABLE)):\n",
    "\n",
    "        settings = ['individual_gpt4_ndel=1_pc_new']\n",
    "        flatmap_qa = joblib.load(\n",
    "            join(PROCESSED_DIR, subject.replace('UT', ''), 'individual_gpt4_ndel=1_pc_new.pkl'))\n",
    "        flatmaps[subject + '_enc'].append(flatmap_qa[q])\n",
    "\n",
    "        pc_coef = r_df.iloc[i]['coef']\n",
    "        flatmap_decode = (pc_coef @ pca_comps).squeeze()\n",
    "        flatmaps[subject + '_dec'].append(flatmap_decode)\n",
    "\n",
    "        corrs[subject].append(\n",
    "            np.corrcoef(flatmap_decode, flatmap_qa[q])[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3.8, 2))\n",
    "for subj in ['S01', 'S02', 'S03']:\n",
    "    plt.hist(corrs[subj], alpha=0.5, label=subj)\n",
    "plt.legend(frameon=False)\n",
    "plt.xlabel('Correlation between encoding/decoding\\ncoefs for each question')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.savefig(join(repo_dir, 'qa_results', 'figs',\n",
    "            'enc_dec_hist.png'), dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in flatmaps.keys():\n",
    "    arr = np.array(flatmaps[k]).mean(axis=0)\n",
    "# arr_enc = np.array(flatmaps['S02_enc']).mean(axis=0)\n",
    "# arr_dec = np.array(flatmaps['S02_dec']).mean(axis=0)\n",
    "# , fname_save=join(data_dir, 'flatmaps_decoding', 'S02_enc.png'))\n",
    "    sasc.viz.quickshow(arr, 'UT' + k.split('_')[0], fname_save=join(\n",
    "        data_dir, 'flatmaps_decoding', 'avgs', 'avg_' + k + '.png'),\n",
    "        with_colorbar=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the pngs into a grid\n",
    "subjects = ['S01', 'S02', 'S03']\n",
    "nrows = len(subjects)\n",
    "ncols = 2\n",
    "axes = plt.subplots(nrows=nrows, ncols=ncols,\n",
    "                    figsize=(4 * ncols, 2 * nrows))[1]\n",
    "for i, subject in enumerate(subjects):\n",
    "    fname = join(data_dir, 'flatmaps_decoding', 'avg_' + subject + '_enc.png')\n",
    "    axes[i, 0].imshow(mpimg.imread(fname))\n",
    "    axes[i, 0].axis('off')\n",
    "    if i == 0:\n",
    "        axes[i, 0].set_title('Encoding', fontsize='x-small')\n",
    "    # axes[i, 0].set_ylabel(subject.upper(), fontsize='x-small')\n",
    "    # show rotated text where ylabel would be\n",
    "    axes[i, 0].text(-0.5, -20, subject.upper(),\n",
    "                    fontsize='x-small', rotation=90, ha='center', va='center')\n",
    "\n",
    "    fname = join(data_dir, 'flatmaps_decoding', 'avg_' + subject + '_dec.png')\n",
    "    axes[i, 1].imshow(mpimg.imread(fname))\n",
    "    axes[i, 1].axis('off')\n",
    "    if i == 0:\n",
    "        axes[i, 1].set_title('Decoding', fontsize='x-small')\n",
    "plt.tight_layout()\n",
    "plt.savefig(join(data_dir, 'flatmaps_decoding', 'avg_enc_dec.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ablated dec perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [f for f in os.listdir(\n",
    "    join(data_dir, 'test_acc')) if f.startswith('r_df')]\n",
    "r_dfs = []\n",
    "for fname in fnames:\n",
    "    r_df = pd.DataFrame(joblib.load(join(data_dir, 'test_acc', fname))\n",
    "                        [['test_acc']].mean())\n",
    "    r_df['fname'] = fname.replace('.pkl', '').replace('r_df_ut', '')\n",
    "    r_dfs.append(r_df)\n",
    "df = pd.concat(r_dfs)\n",
    "df.rename(columns={0: 'acc'}, inplace=True)\n",
    "\n",
    "df['subject'] = df['fname'].str.split('_').str[0].str.upper()\n",
    "df['shuffle'] = df['fname'].str.contains('shuffle')\n",
    "df['fname'] = df['fname'].str.replace('_shuffle', '')\n",
    "\n",
    "\n",
    "def get_nvoxels(fname):\n",
    "    if 'nvoxels' in fname:\n",
    "        return int(fname.split('=')[-1])\n",
    "    else:\n",
    "        return 100000\n",
    "\n",
    "\n",
    "df['nvoxels'] = df['fname'].apply(get_nvoxels)\n",
    "\n",
    "# add mean subject\n",
    "df_mean = df.groupby(['shuffle', 'nvoxels'])['acc'].mean().reset_index()\n",
    "df_mean['subject'] = 'Mean'\n",
    "df = pd.concat([df, df_mean])\n",
    "\n",
    "# look up nvoxels in df\n",
    "\n",
    "\n",
    "def _rewrite_nvoxels(row):\n",
    "    nvoxels, subj = row['nvoxels'], row['subject']\n",
    "    if nvoxels == 100000:\n",
    "        return neuro.config.VOX_COUNTS[subj]\n",
    "    else:\n",
    "        return nvoxels\n",
    "\n",
    "\n",
    "df['nvoxels'] = df.apply(_rewrite_nvoxels, axis=1)\n",
    "df['shuffle'] = df['shuffle'].replace({False: 'Selected', True: 'Random'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.rename(columns={'subject': 'Subject', 'shuffle': ' '})\n",
    "plt.figure(figsize=(5, 2.5))\n",
    "sns.lineplot(data=df, x='nvoxels',\n",
    "             y='acc', hue='Subject', style=' ', markers=True,\n",
    "             hue_order=['Mean', 'S01', 'S02', 'S03'],\n",
    "             palette=['black', 'C0', 'C1', 'C2'],\n",
    "             style_order=['Selected', 'Random'],\n",
    "             )\n",
    "plt.ylabel('Decoding accuracy')\n",
    "plt.xlabel('Number of voxels')\n",
    "plt.xscale('log')\n",
    "\n",
    "# move legend outside plot\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# set tick labels at 20, 100, 500, 2500, 100000\n",
    "plt.xticks([4, 20, 100, 500, 2500, 12500, 100000],\n",
    "           ['4', '20', '100', '500', '2500', '12500', '100000'])\n",
    "plt.tight_layout()\n",
    "plt.savefig(join(data_dir, 'dec_acc_by_voxels.png'), dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
