{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../experiments')\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import imodelsx.process_results\n",
    "from neuro.features import qa_questions, feature_spaces\n",
    "from neuro.data import story_names\n",
    "from neuro.features.stim_utils import load_story_wordseqs, load_story_wordseqs_huge\n",
    "import random\n",
    "import json\n",
    "import joblib\n",
    "from neuro.features.qa_questions import get_questions, get_merged_questions_v3_boostexamples\n",
    "from tqdm import tqdm\n",
    "from neuro.features.questions.gpt4 import QS_35_STABLE\n",
    "from collections import defaultdict\n",
    "from neuro.features.feature_spaces import get_gpt4_qa_embs_cached\n",
    "fit_encoding = __import__('02_fit_encoding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up data for labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 1 stories\n"
     ]
    }
   ],
   "source": [
    "story_names_list = ['wheretheressmoke']\n",
    "print('loaded', len(story_names_list), 'stories')\n",
    "# wordseqs = feature_spaces.get_story_wordseqs(story_names_train)\n",
    "wordseqs = load_story_wordseqs_huge(story_names_list)\n",
    "\n",
    "ngrams_list_total = []\n",
    "for story in story_names_list:\n",
    "    ngrams_list = feature_spaces.get_ngrams_list_main(\n",
    "        wordseqs[story], num_ngrams_context=10)\n",
    "    # print(ngrams_list[:10])\n",
    "    ngrams_list_total.extend(ngrams_list)\n",
    "\n",
    "# questions = get_merged_questions_v3_boostexamples()\n",
    "questions = QS_35_STABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = np.full((len(ngrams_list_total), len(questions)), fill_value='')\n",
    "df = pd.DataFrame(answers, columns=questions)\n",
    "df['text'] = ngrams_list_total\n",
    "# move question to first position\n",
    "cols = list(df.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "df = df[cols]\n",
    "df.to_csv('ngrams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_gpt4 = get_gpt4_qa_embs_cached(\n",
    "    story_name=story_names_list[0], questions=questions, qa_questions_version=None)\n",
    "embs_gpt4 = pd.DataFrame(embs_gpt4, columns=questions, index=ngrams_list_total)\n",
    "embs_gpt4.to_csv('qa_gpt4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_human1 = pd.read_csv('qa_human1.csv')\n",
    "cols = [c for c in embs_human1.columns if not c in ['text', 'Unnamed: 0']]\n",
    "assert cols == questions\n",
    "assert embs_gpt4.shape[0] == embs_human1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuro.features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_dict = defaultdict(list)\n",
    "for i, q in enumerate(questions):\n",
    "    notna = embs_human1[q].notna()\n",
    "    accs_dict['acc'].append(\n",
    "        np.mean(embs_gpt4[q][notna] == embs_human1[q][notna]))\n",
    "    accs_dict['acc_baseline'].append(np.mean(embs_human1[q][notna]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = pd.DataFrame(accs_dict)\n",
    "accs['acc_baseline_majority'] = accs['acc_baseline'].apply(\n",
    "    lambda x: max(x, 1-x))\n",
    "\n",
    "# seaborn plot distributions\n",
    "# sns.swarmplot(data=accs, color='black')\n",
    "sns.barplot(data=accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs.style.background_gradient(cmap='coolwarm', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
