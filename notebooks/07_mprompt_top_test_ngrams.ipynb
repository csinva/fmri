{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import feature_spaces\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import encoding_utils, feature_spaces\n",
    "import pickle as pkl\n",
    "from collections import defaultdict\n",
    "from feature_spaces import *\n",
    "NUM_VOXELS = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stories, test_stories, allstories = encoding_utils.get_allstories([1, 2, 3, 4, 5])\n",
    "wordseqs = feature_spaces.get_story_wordseqs(test_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 324.31it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_words_for_story(wordseq, max_running_words=5) -> List[str]:\n",
    "    running_words = []\n",
    "    \n",
    "    words = np.array(wordseq.data)\n",
    "    TRIM = 5\n",
    "    tr_times = wordseq.tr_times[5+TRIM: -TRIM]\n",
    "    for i, tr_time in enumerate(tr_times):\n",
    "        valid_times = wordseq.data_times <= tr_time\n",
    "        # print(valid_times)\n",
    "        running_words.append(' '.join(words[valid_times][-max_running_words:]))\n",
    "    #     print(tr_time, running_words)\n",
    "    return running_words\n",
    "\n",
    "texts_list_test = []\n",
    "for story_name in tqdm(test_stories):\n",
    "    wordseq = wordseqs[story_name]\n",
    "    texts_list_test.append(get_words_for_story(wordseq))\n",
    "texts_test = sum(texts_list_test, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76296981 0.74258237 0.72107898 0.71616266 0.71508206]\n"
     ]
    }
   ],
   "source": [
    "subj = 'UTS03'\n",
    "\n",
    "# select top_idxs\n",
    "save_dir = '/home/chansingh/mntv1/deep-fMRI/results/encoding/bert-10__ndel=4/UTS03'\n",
    "corrs_val = np.load(join(save_dir, 'corrs.npz'))['arr_0']\n",
    "top_idxs = np.argsort(corrs_val)[::-1][:NUM_VOXELS]\n",
    "print(corrs_val[top_idxs][:5])\n",
    "\n",
    "# load responses (n_time_points x n_voxels)\n",
    "resp_test = encoding_utils.get_response(test_stories, subj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 18276.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# get the top ngrams for each voxel\n",
    "NUM_NGRAMS = 30\n",
    "top_ngrams = {}\n",
    "for i, voxel in enumerate(tqdm(top_idxs)):\n",
    "    top_resp_idxs = np.argsort(resp_test[:, i])[::-1]\n",
    "    top_ngrams[voxel] = [texts_test[idx][:NUM_NGRAMS] for idx in top_resp_idxs]\n",
    "top_ngrams = pd.DataFrame.from_dict(top_ngrams)\n",
    "top_ngrams.columns = [f'voxel_top_{i}' for i in range(NUM_VOXELS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>voxel_top_0</th>\n",
       "      <th>voxel_top_1</th>\n",
       "      <th>voxel_top_2</th>\n",
       "      <th>voxel_top_3</th>\n",
       "      <th>voxel_top_4</th>\n",
       "      <th>voxel_top_5</th>\n",
       "      <th>voxel_top_6</th>\n",
       "      <th>voxel_top_7</th>\n",
       "      <th>voxel_top_8</th>\n",
       "      <th>voxel_top_9</th>\n",
       "      <th>...</th>\n",
       "      <th>voxel_top_240</th>\n",
       "      <th>voxel_top_241</th>\n",
       "      <th>voxel_top_242</th>\n",
       "      <th>voxel_top_243</th>\n",
       "      <th>voxel_top_244</th>\n",
       "      <th>voxel_top_245</th>\n",
       "      <th>voxel_top_246</th>\n",
       "      <th>voxel_top_247</th>\n",
       "      <th>voxel_top_248</th>\n",
       "      <th>voxel_top_249</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didn't have my cigarettes</td>\n",
       "      <td>a drag of his cigarette</td>\n",
       "      <td>me over and he sees</td>\n",
       "      <td>little crack of light and</td>\n",
       "      <td>and the person comes closer</td>\n",
       "      <td>reminisce about our thirty sec</td>\n",
       "      <td>not ever see her again</td>\n",
       "      <td>washing dogs she had horses</td>\n",
       "      <td>i'll give you a ride</td>\n",
       "      <td>out on this suburban street</td>\n",
       "      <td>...</td>\n",
       "      <td>door and i ran i</td>\n",
       "      <td>was crying i had no</td>\n",
       "      <td>been laundered at least once</td>\n",
       "      <td>i didn't want any part</td>\n",
       "      <td>just then the girl reaches</td>\n",
       "      <td>newish to the neighborhood thi</td>\n",
       "      <td>paper seven cigarettes for me</td>\n",
       "      <td>and we both need this</td>\n",
       "      <td>kind of does the opposite</td>\n",
       "      <td>have my driver's license yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy to see me and</td>\n",
       "      <td>fun and you know let's</td>\n",
       "      <td>fun and you know let's</td>\n",
       "      <td>and she pulls out a</td>\n",
       "      <td>yeah ok and i walk</td>\n",
       "      <td>i'm surprised when i see</td>\n",
       "      <td>her cutoffs in the front</td>\n",
       "      <td>for anything like we would</td>\n",
       "      <td>there is one match inside</td>\n",
       "      <td>of that cigarette and we</td>\n",
       "      <td>...</td>\n",
       "      <td>are getting wider and wider</td>\n",
       "      <td>you and she says never</td>\n",
       "      <td>and she still understands how</td>\n",
       "      <td>live with someone who has</td>\n",
       "      <td>and i say you got</td>\n",
       "      <td>shoes on i was crying</td>\n",
       "      <td>oh man that was close</td>\n",
       "      <td>halfway there i'm a waitress</td>\n",
       "      <td>live with someone who has</td>\n",
       "      <td>but yes carl's efficiency apar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>going home now to my</td>\n",
       "      <td>tell people at home this</td>\n",
       "      <td>i didn't want any part</td>\n",
       "      <td>not gonna be friends i</td>\n",
       "      <td>dollar stores and emergecenter</td>\n",
       "      <td>i cross and i walk</td>\n",
       "      <td>and she pulls out a</td>\n",
       "      <td>or drunk or lonely or</td>\n",
       "      <td>little scary and i follow</td>\n",
       "      <td>i'm surprised when i see</td>\n",
       "      <td>...</td>\n",
       "      <td>fight about and i say</td>\n",
       "      <td>be but i know it's</td>\n",
       "      <td>up and there is one</td>\n",
       "      <td>checking and checking and it's</td>\n",
       "      <td>i didn't want any part</td>\n",
       "      <td>but i was ok because</td>\n",
       "      <td>we finish our cigarettes she</td>\n",
       "      <td>have a one bedroom apartment</td>\n",
       "      <td>smoked all seven cigarettes on</td>\n",
       "      <td>i didn't have my cigarettes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and the person comes closer</td>\n",
       "      <td>checking and checking and it's</td>\n",
       "      <td>oh hey i'm not a</td>\n",
       "      <td>sweet that'll be we are</td>\n",
       "      <td>checking and checking and it's</td>\n",
       "      <td>not gonna be friends i</td>\n",
       "      <td>temper a very very bad</td>\n",
       "      <td>door and i ran i</td>\n",
       "      <td>{cg} and we share some</td>\n",
       "      <td>i'm back and he says</td>\n",
       "      <td>...</td>\n",
       "      <td>we start walking and uh</td>\n",
       "      <td>and she still understands how</td>\n",
       "      <td>door and i ran i</td>\n",
       "      <td>that was great to meet</td>\n",
       "      <td>halfway there i'm a waitress</td>\n",
       "      <td>i didn't want any part</td>\n",
       "      <td>uh she leads me to</td>\n",
       "      <td>that you learn this time</td>\n",
       "      <td>not gonna be friends i</td>\n",
       "      <td>was crying i had no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>there and i'm going home</td>\n",
       "      <td>and that was fun and</td>\n",
       "      <td>of that cigarette and we</td>\n",
       "      <td>he keeps me going she</td>\n",
       "      <td>on that has fifty million</td>\n",
       "      <td>lucky i saw you yeah</td>\n",
       "      <td>i'm surprised when i see</td>\n",
       "      <td>on that has fifty million</td>\n",
       "      <td>yeah ok and i walk</td>\n",
       "      <td>he says who the fuck</td>\n",
       "      <td>...</td>\n",
       "      <td>was crying i had no</td>\n",
       "      <td>i can't ever tell people</td>\n",
       "      <td>shoes on i was crying</td>\n",
       "      <td>stuff about what our lives</td>\n",
       "      <td>place and i think no</td>\n",
       "      <td>to trade stories about our</td>\n",
       "      <td>horrible misery going on there</td>\n",
       "      <td>i'll just be real nice</td>\n",
       "      <td>because i had my cigarettes</td>\n",
       "      <td>think that was gonna happen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   voxel_top_0                     voxel_top_1  \\\n",
       "0  i didn't have my cigarettes         a drag of his cigarette   \n",
       "1          happy to see me and          fun and you know let's   \n",
       "2         going home now to my        tell people at home this   \n",
       "3  and the person comes closer  checking and checking and it's   \n",
       "4     there and i'm going home            and that was fun and   \n",
       "\n",
       "                voxel_top_2                voxel_top_3  \\\n",
       "0       me over and he sees  little crack of light and   \n",
       "1    fun and you know let's        and she pulls out a   \n",
       "2    i didn't want any part     not gonna be friends i   \n",
       "3          oh hey i'm not a    sweet that'll be we are   \n",
       "4  of that cigarette and we      he keeps me going she   \n",
       "\n",
       "                      voxel_top_4                     voxel_top_5  \\\n",
       "0     and the person comes closer  reminisce about our thirty sec   \n",
       "1              yeah ok and i walk        i'm surprised when i see   \n",
       "2  dollar stores and emergecenter              i cross and i walk   \n",
       "3  checking and checking and it's          not gonna be friends i   \n",
       "4       on that has fifty million            lucky i saw you yeah   \n",
       "\n",
       "                voxel_top_6                  voxel_top_7  \\\n",
       "0    not ever see her again  washing dogs she had horses   \n",
       "1  her cutoffs in the front   for anything like we would   \n",
       "2       and she pulls out a        or drunk or lonely or   \n",
       "3    temper a very very bad             door and i ran i   \n",
       "4  i'm surprised when i see    on that has fifty million   \n",
       "\n",
       "                 voxel_top_8                  voxel_top_9  ...  \\\n",
       "0       i'll give you a ride  out on this suburban street  ...   \n",
       "1  there is one match inside     of that cigarette and we  ...   \n",
       "2  little scary and i follow     i'm surprised when i see  ...   \n",
       "3     {cg} and we share some         i'm back and he says  ...   \n",
       "4         yeah ok and i walk         he says who the fuck  ...   \n",
       "\n",
       "                 voxel_top_240                  voxel_top_241  \\\n",
       "0             door and i ran i            was crying i had no   \n",
       "1  are getting wider and wider         you and she says never   \n",
       "2        fight about and i say             be but i know it's   \n",
       "3      we start walking and uh  and she still understands how   \n",
       "4          was crying i had no       i can't ever tell people   \n",
       "\n",
       "                   voxel_top_242                   voxel_top_243  \\\n",
       "0   been laundered at least once          i didn't want any part   \n",
       "1  and she still understands how       live with someone who has   \n",
       "2            up and there is one  checking and checking and it's   \n",
       "3               door and i ran i          that was great to meet   \n",
       "4          shoes on i was crying      stuff about what our lives   \n",
       "\n",
       "                  voxel_top_244                   voxel_top_245  \\\n",
       "0    just then the girl reaches  newish to the neighborhood thi   \n",
       "1             and i say you got           shoes on i was crying   \n",
       "2        i didn't want any part            but i was ok because   \n",
       "3  halfway there i'm a waitress          i didn't want any part   \n",
       "4          place and i think no      to trade stories about our   \n",
       "\n",
       "                    voxel_top_246                 voxel_top_247  \\\n",
       "0   paper seven cigarettes for me         and we both need this   \n",
       "1           oh man that was close  halfway there i'm a waitress   \n",
       "2    we finish our cigarettes she  have a one bedroom apartment   \n",
       "3              uh she leads me to      that you learn this time   \n",
       "4  horrible misery going on there        i'll just be real nice   \n",
       "\n",
       "                    voxel_top_248                   voxel_top_249  \n",
       "0       kind of does the opposite    have my driver's license yet  \n",
       "1       live with someone who has  but yes carl's efficiency apar  \n",
       "2  smoked all seven cigarettes on     i didn't have my cigarettes  \n",
       "3          not gonna be friends i             was crying i had no  \n",
       "4     because i had my cigarettes     think that was gonna happen  \n",
       "\n",
       "[5 rows x 250 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ngrams.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ngrams.to_pickle('top_ngrams.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp top_ngrams.pkl ../../mprompt/mprompt/modules/fmri/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
