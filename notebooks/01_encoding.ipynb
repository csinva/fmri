{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/google/rpc/__init__.py:20: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.rpc')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  pkg_resources.declare_namespace(__name__)\n",
      "/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/pkg_resources/__init__.py:2350: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(parent)\n",
      "/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/lightning/fabric/__init__.py:41: Deprecated call to `pkg_resources.declare_namespace('lightning.fabric')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/pkg_resources/__init__.py:2350: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('lightning')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(parent)\n",
      "/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/torchmetrics/utilities/imports.py:24: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  _PYTHON_LOWER_3_8 = LooseVersion(_PYTHON_VERSION) < LooseVersion(\"3.8\")\n",
      "/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/torchmetrics/utilities/imports.py:24: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  _PYTHON_LOWER_3_8 = LooseVersion(_PYTHON_VERSION) < LooseVersion(\"3.8\")\n",
      "/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/lightning/pytorch/__init__.py:37: Deprecated call to `pkg_resources.declare_namespace('lightning.pytorch')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/pkg_resources/__init__.py:2350: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('lightning')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(parent)\n",
      "100%|██████████| 2/2 [00:00<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment varied these params: ['feature_space']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3b04c_row0_col0, #T_3b04c_row0_col2, #T_3b04c_row0_col3, #T_3b04c_row0_col8, #T_3b04c_row1_col1, #T_3b04c_row1_col4, #T_3b04c_row1_col6, #T_3b04c_row1_col7, #T_3b04c_row1_col10, #T_3b04c_row1_col11 {\n",
       "  background-color: #fcfdbf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3b04c_row0_col1, #T_3b04c_row0_col4, #T_3b04c_row0_col5, #T_3b04c_row0_col6, #T_3b04c_row0_col7, #T_3b04c_row0_col9, #T_3b04c_row0_col10, #T_3b04c_row0_col11, #T_3b04c_row1_col0, #T_3b04c_row1_col2, #T_3b04c_row1_col3, #T_3b04c_row1_col5, #T_3b04c_row1_col8, #T_3b04c_row1_col9 {\n",
       "  background-color: #000004;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3b04c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3b04c_level0_col0\" class=\"col_heading level0 col0\" > test mean</th>\n",
       "      <th id=\"T_3b04c_level0_col1\" class=\"col_heading level0 col1\" > test frac>0</th>\n",
       "      <th id=\"T_3b04c_level0_col2\" class=\"col_heading level0 col2\" > test mean top1 percentile</th>\n",
       "      <th id=\"T_3b04c_level0_col3\" class=\"col_heading level0 col3\" > test mean top5 percentile</th>\n",
       "      <th id=\"T_3b04c_level0_col4\" class=\"col_heading level0 col4\" > tune pc mean</th>\n",
       "      <th id=\"T_3b04c_level0_col5\" class=\"col_heading level0 col5\" > tune pc frac>0</th>\n",
       "      <th id=\"T_3b04c_level0_col6\" class=\"col_heading level0 col6\" > tune pc mean top1 percentile</th>\n",
       "      <th id=\"T_3b04c_level0_col7\" class=\"col_heading level0 col7\" > tune pc mean top5 percentile</th>\n",
       "      <th id=\"T_3b04c_level0_col8\" class=\"col_heading level0 col8\" > test pc mean</th>\n",
       "      <th id=\"T_3b04c_level0_col9\" class=\"col_heading level0 col9\" > test pc frac>0</th>\n",
       "      <th id=\"T_3b04c_level0_col10\" class=\"col_heading level0 col10\" > test pc mean top1 percentile</th>\n",
       "      <th id=\"T_3b04c_level0_col11\" class=\"col_heading level0 col11\" > test pc mean top5 percentile</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >feature_space</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "      <th class=\"blank col10\" >&nbsp;</th>\n",
       "      <th class=\"blank col11\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3b04c_level0_row0\" class=\"row_heading level0 row0\" >eng1000</th>\n",
       "      <td id=\"T_3b04c_row0_col0\" class=\"data row0 col0\" >0.110</td>\n",
       "      <td id=\"T_3b04c_row0_col1\" class=\"data row0 col1\" >0.866</td>\n",
       "      <td id=\"T_3b04c_row0_col2\" class=\"data row0 col2\" >0.513</td>\n",
       "      <td id=\"T_3b04c_row0_col3\" class=\"data row0 col3\" >0.425</td>\n",
       "      <td id=\"T_3b04c_row0_col4\" class=\"data row0 col4\" >0.111</td>\n",
       "      <td id=\"T_3b04c_row0_col5\" class=\"data row0 col5\" >1.000</td>\n",
       "      <td id=\"T_3b04c_row0_col6\" class=\"data row0 col6\" >0.349</td>\n",
       "      <td id=\"T_3b04c_row0_col7\" class=\"data row0 col7\" >0.281</td>\n",
       "      <td id=\"T_3b04c_row0_col8\" class=\"data row0 col8\" >0.223</td>\n",
       "      <td id=\"T_3b04c_row0_col9\" class=\"data row0 col9\" >1.000</td>\n",
       "      <td id=\"T_3b04c_row0_col10\" class=\"data row0 col10\" >0.526</td>\n",
       "      <td id=\"T_3b04c_row0_col11\" class=\"data row0 col11\" >0.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b04c_level0_row1\" class=\"row_heading level0 row1\" >qa_embedder-5</th>\n",
       "      <td id=\"T_3b04c_row1_col0\" class=\"data row1 col0\" >0.110</td>\n",
       "      <td id=\"T_3b04c_row1_col1\" class=\"data row1 col1\" >0.868</td>\n",
       "      <td id=\"T_3b04c_row1_col2\" class=\"data row1 col2\" >0.499</td>\n",
       "      <td id=\"T_3b04c_row1_col3\" class=\"data row1 col3\" >0.420</td>\n",
       "      <td id=\"T_3b04c_row1_col4\" class=\"data row1 col4\" >0.113</td>\n",
       "      <td id=\"T_3b04c_row1_col5\" class=\"data row1 col5\" >1.000</td>\n",
       "      <td id=\"T_3b04c_row1_col6\" class=\"data row1 col6\" >0.403</td>\n",
       "      <td id=\"T_3b04c_row1_col7\" class=\"data row1 col7\" >0.301</td>\n",
       "      <td id=\"T_3b04c_row1_col8\" class=\"data row1 col8\" >0.212</td>\n",
       "      <td id=\"T_3b04c_row1_col9\" class=\"data row1 col9\" >1.000</td>\n",
       "      <td id=\"T_3b04c_row1_col10\" class=\"data row1 col10\" >0.569</td>\n",
       "      <td id=\"T_3b04c_row1_col11\" class=\"data row1 col11\" >0.456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa5226013d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import dvu\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import imodelsx.process_results\n",
    "import qa_questions\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "fit_encoding = __import__('01_fit_encoding')\n",
    "dvu.set_style()\n",
    "\n",
    "# results_dir = '/home/chansingh/mntv1/deep-fMRI/encoding/results_mar27'\n",
    "# results_dir = '/home/chansingh/mntv1/deep-fMRI/encoding/results_mar28'\n",
    "results_dir = '/home/chansingh/mntv1/deep-fMRI/encoding/results_mar30'\n",
    "experiment_filename = '../experiments/01_fit_encoding.py'\n",
    "\n",
    "# load the results in to a pandas dataframe\n",
    "r = imodelsx.process_results.get_results_df(results_dir)\n",
    "r = imodelsx.process_results.fill_missing_args_with_default(\n",
    "    r, experiment_filename)\n",
    "# imodelsx.process_results.delete_runs_in_dataframe(\n",
    "    # r[r.feature_space == 'qa_embedder-10'], actually_delete=True)\n",
    "cols_varied = imodelsx.process_results.get_experiment_keys(\n",
    "    r, experiment_filename)\n",
    "print('experiment varied these params:', cols_varied)\n",
    "\n",
    "mets = [c for c in r.columns if 'corrs' in c and ('mean' in c or 'frac' in c)]\n",
    "    # [c for c in r.columns if 'corrs_tune_' in c]\n",
    "# mets = [met for met in mets if not 'pc' in met]\n",
    "if len(cols_varied) > 0:\n",
    "    d = r.groupby(cols_varied)[mets].mean()\n",
    "else:\n",
    "    d = r[mets]\n",
    "(\n",
    "    d\n",
    "    .sort_values(by='corrs_test_mean', ascending=False)\n",
    "    .rename(columns=lambda x: x.replace('_', ' ').replace('corrs', ''))\n",
    "    .style\n",
    "    .background_gradient(cmap='magma', axis=0)\n",
    "    .format(precision=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare performance of a few different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = r[(r.feature_space == 'qa_embedder-5')\n",
    "       ].sort_values(by='corrs_tune_mean', ascending=False).iloc[0]\n",
    "eng1000 = r[(r.feature_space == 'eng1000')].sort_values(\n",
    "    by='corrs_tune_mean', ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(qa['corrs_test'], eng1000['corrs_test'], '.', ms=1)\n",
    "plt.xlabel(f'QA Embedder (mean: {qa[\"corrs_test\"].mean():0.3f})')\n",
    "plt.ylabel(f'Eng1000 (mean: {eng1000[\"corrs_test\"].mean():0.3f})')\n",
    "plt.title('Test Correlations')\n",
    "m_max = max(qa['corrs_test'].max(), eng1000['corrs_test'].max())\n",
    "m_min = min(qa['corrs_test'].min(), eng1000['corrs_test'].min())\n",
    "plt.plot([m_min, m_max], [m_min, m_max], 'k--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check parameters for rerunning expts (alphas, delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = r[(r.pc_components == -1) * (r.ndelays == 8)].iloc[0]\n",
    "# args = r.sort_values(by='corrs_test_mean').iloc[-1]\n",
    "args = qa\n",
    "model_params_to_save = joblib.load(\n",
    "    join(args.save_dir_unique, 'model_params.pkl'))\n",
    "print(args.feature_space, args.pc_components, args.ndelays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print which alphas are being used\n",
    "pd.Series(model_params_to_save['alphas_best']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = r[(r.pc_components == -1) * (r.feature_space == 'qa_embedder-5')\n",
    "         ].sort_values(by='corrs_tune_mean', ascending=False).iloc[0]\n",
    "args2 = r[(r.pc_components > 0) * (r.feature_space == 'qa_embedder-5')\n",
    "          ].sort_values(by='corrs_tune_mean', ascending=False).iloc[0]\n",
    "# args = r[]\n",
    "\n",
    "# args2 = r[(r.feature_space == 'eng1000')].iloc[0]\n",
    "# args = r[(r.pc_components == -1) * (r.feature_space == 8)].iloc[0]\n",
    "# args = r[(r.pc_components == -1) * (r.ndelays == 8)].iloc[0]\n",
    "# model_params_to_save = joblib.load(\n",
    "# join(args.save_dir_unique, 'model_params.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_thresholds = np.arange(0, 100, 1)\n",
    "corrs_tune_individual = args['corrs_tune']\n",
    "corrs_test_individual = args['corrs_test']\n",
    "corrs_test_pca = args2['corrs_test']\n",
    "res = []\n",
    "for percentile_threshold in percentile_thresholds:\n",
    "    args_top_thresh = np.where(corrs_tune_individual > np.percentile(\n",
    "        corrs_tune_individual, percentile_threshold))[0]\n",
    "    args_non_top_thresh = np.where(corrs_tune_individual <= np.percentile(\n",
    "        corrs_tune_individual, percentile_threshold))[0]\n",
    "    args_total = np.concatenate([args_top_thresh, args_non_top_thresh])\n",
    "    mean_corr_weighted = (corrs_test_individual[args_top_thresh].mean() * args_top_thresh.size +\n",
    "                          corrs_test_pca[args_non_top_thresh].mean() * args_non_top_thresh.size) / args_total.size\n",
    "    # print('mean corr weighted',\n",
    "    #       (corrs_test_individual[args_top_thresh].mean() * args_top_thresh.size +\n",
    "    #        corrs_test_pca[args_non_top_thresh].mean() * args_non_top_thresh.size) / args_total.size\n",
    "    #       )\n",
    "    res.append(mean_corr_weighted)\n",
    "plt.plot(percentile_thresholds, res)\n",
    "plt.axhline(corrs_test_individual.mean(), color='k', linestyle='--')\n",
    "plt.axhline(corrs_test_pca.mean(), color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate model weights usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_names_train, story_names_test = fit_encoding.get_story_names(args)\n",
    "stim_test_delayed, resp_test = fit_encoding.get_data(args, story_names_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calc_corrs(preds, resp):\n",
    "    corrs = []\n",
    "    for i in tqdm(range(preds.shape[1])):\n",
    "        corrs.append(np.corrcoef(\n",
    "            preds[:, i], resp[:, i])[0, 1])\n",
    "    return np.array(corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = model_params_to_save['weights']\n",
    "preds_test = stim_test_delayed @ wt\n",
    "corrs_test = _calc_corrs(preds_test, resp_test)\n",
    "print(np.mean(corrs_test))\n",
    "print(args.corrs_test_mean)\n",
    "assert np.allclose(corrs_test, args['corrs_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate PC models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = r[(r.pc_components == 100) * (r.feature_space == 'qa_embedder-5')\n",
    "         ].sort_values(by='corrs_tune_mean', ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_names_train, story_names_test = fit_encoding.get_story_names(args)\n",
    "stim_test_delayed, resp_test = fit_encoding.get_data(args, story_names_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params_to_save = joblib.load(\n",
    "    join(args.save_dir_unique, 'model_params.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = model_params_to_save['weights']\n",
    "# + model_params_to_save['bias'] (not needed for just calculating corr, but needed for predictions)\n",
    "preds_test = stim_test_delayed @ wt\n",
    "\n",
    "corrs_test = _calc_corrs(preds_test, resp_test)\n",
    "print(np.mean(corrs_test))\n",
    "print(args.corrs_test_mean)\n",
    "assert np.allclose(corrs_test, args['corrs_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original setup, before we had unpacked weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_pc = model_params_to_save['weights_pc']\n",
    "pca = model_params_to_save['pca']\n",
    "scaler_test = model_params_to_save['scaler_test']\n",
    "preds_pc = stim_test_delayed @ wt_pc\n",
    "preds_pc_scaled = scaler_test.inverse_transform(preds_pc)\n",
    "preds_voxels = pca.inverse_transform(preds_pc_scaled)\n",
    "corrs_test = _calc_corrs(preds_voxels, resp_test)\n",
    "assert np.allclose(corrs_test, args['corrs_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vary number of pcs included\n",
    "num_pcs = [5, 25, 50, 100, 200, 500, 1000]\n",
    "corrs = []\n",
    "for num_pc in num_pcs:\n",
    "    wt_pc = model_params_to_save['weights_pc']\n",
    "    pca = model_params_to_save['pca']\n",
    "    scaler_test = model_params_to_save['scaler_test']\n",
    "    preds_pc = stim_test_delayed @ wt_pc\n",
    "    preds_pc_scaled = scaler_test.inverse_transform(preds_pc)\n",
    "\n",
    "    pca_subset = deepcopy(pca)\n",
    "    pca_subset.components_[num_pc:] = 0\n",
    "    preds_voxels = pca_subset.inverse_transform(preds_pc_scaled)\n",
    "\n",
    "    corrs_test = _calc_corrs(preds_voxels, resp_test)\n",
    "    # assert np.allclose(corrs_test, args['corrs_test'])\n",
    "    print(num_pc, np.mean(corrs_test))\n",
    "    corrs.append(np.mean(corrs_test))\n",
    "plt.plot(num_pcs, corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_test = fit_encoding.evaluate_pc_model_on_each_voxel(\n",
    "    args, stim_test_delayed, resp_test,\n",
    "    model_params_to_save, pca, scaler_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = model_params_to_save['weights']\n",
    "\n",
    "# multiply\n",
    "preds_pc = stim_test_delayed @ wt\n",
    "preds_pc_unscaled = preds_pc * scaler_test.scale_ + scaler_test.mean_\n",
    "preds_voxels2 = preds_pc_unscaled @ pca.components_ + pca.mean_\n",
    "\n",
    "# rewrite the above as a multiplication of a single weight matrix\n",
    "preds_voxels2 = (stim_test_delayed @ wt * scaler_test.scale_ +\n",
    "                 scaler_test.mean_) @ pca.components_ + pca.mean_\n",
    "weight_full = wt * scaler_test.scale_ @ pca.components_\n",
    "bias_full = scaler_test.mean_ @ pca.components_ + pca.mean_\n",
    "preds_voxels2 = stim_test_delayed @ weight_full + bias_full\n",
    "\n",
    "assert np.allclose(preds_voxels, preds_voxels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert corrs_test.mean() == args.corrs_test_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
