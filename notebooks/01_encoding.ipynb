{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import dvu\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import imodelsx.process_results\n",
    "import qa_questions\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "fit_encoding = __import__('01_fit_encoding')\n",
    "dvu.set_style()\n",
    "\n",
    "results_dir = '/home/chansingh/mntv1/deep-fMRI/encoding/results_apr1'\n",
    "\n",
    "experiment_filename = '../experiments/01_fit_encoding.py'\n",
    "\n",
    "# load the results in to a pandas dataframe\n",
    "r = imodelsx.process_results.get_results_df(results_dir)\n",
    "r = imodelsx.process_results.fill_missing_args_with_default(\n",
    "    r, experiment_filename)\n",
    "r['qa_embedding_model'] = r.apply(lambda row: {\n",
    "    'mistralai/Mistral-7B-v0.1': 'mistral 7B',\n",
    "    'mistralai/Mixtral-8x7B-v0.1': 'mixtral MOE',\n",
    "}.get(row['qa_embedding_model'], row['qa_embedding_model']) if 'qa_emb' in row['feature_space'] else '', axis=1)\n",
    "cols_varied = imodelsx.process_results.get_experiment_keys(\n",
    "    r, experiment_filename)\n",
    "print('experiment varied these params:', cols_varied)\n",
    "\n",
    "mets = [c for c in r.columns if 'corrs' in c and ('mean' in c or 'frac' in c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = r\n",
    "# d = d[(d.qa_questions_version == 'v1') *\n",
    "#   (d.qa_embedding_model == 'mistral 7B')]\n",
    "if len(cols_varied) > 0:\n",
    "    d = d.groupby(cols_varied)[mets].mean()\n",
    "else:\n",
    "    d = d[mets]\n",
    "\n",
    "(\n",
    "    d\n",
    "    .sort_values(by='corrs_test_mean', ascending=False)\n",
    "    .rename(columns=lambda x: x.replace('_', ' ').replace('corrs', ''))\n",
    "    .style\n",
    "    .background_gradient(cmap='magma', axis=0)\n",
    "    .format(precision=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare performance of a few different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = r[(r.feature_space == 'qa_embedder-5')\n",
    "       ].sort_values(by='corrs_tune_pc_mean', ascending=False).iloc[0]\n",
    "eng1000 = r[(r.feature_space == 'eng1000')].sort_values(\n",
    "    by='corrs_tune_pc_mean', ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(qa['corrs_test'], eng1000['corrs_test'], '.', ms=1)\n",
    "plt.xlabel(f'QA Embedder (mean: {qa[\"corrs_test\"].mean():0.3f})')\n",
    "plt.ylabel(f'Eng1000 (mean: {eng1000[\"corrs_test\"].mean():0.3f})')\n",
    "plt.title('Test Correlations')\n",
    "m_max = max(qa['corrs_test'].max(), eng1000['corrs_test'].max())\n",
    "m_min = min(qa['corrs_test'].min(), eng1000['corrs_test'].min())\n",
    "plt.plot([m_min, m_max], [m_min, m_max], 'k--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check parameters for rerunning expts (alphas, delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = r[(r.pc_components == -1) * (r.ndelays == 8)].iloc[0]\n",
    "# args = r.sort_values(by='corrs_test_mean').iloc[-1]\n",
    "args = qa\n",
    "model_params_to_save = joblib.load(\n",
    "    join(args.save_dir_unique, 'model_params.pkl'))\n",
    "print(args.feature_space, args.pc_components, args.ndelays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print which alphas are being used\n",
    "pd.Series(model_params_to_save['alphas_best']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = r[(r.pc_components == -1) * (r.feature_space == 'qa_embedder-5')\n",
    "         ].sort_values(by='corrs_tune_mean', ascending=False).iloc[0]\n",
    "args2 = r[(r.pc_components > 0) * (r.feature_space == 'qa_embedder-5')\n",
    "          ].sort_values(by='corrs_tune_mean', ascending=False).iloc[0]\n",
    "# args = r[]\n",
    "\n",
    "# args2 = r[(r.feature_space == 'eng1000')].iloc[0]\n",
    "# args = r[(r.pc_components == -1) * (r.feature_space == 8)].iloc[0]\n",
    "# args = r[(r.pc_components == -1) * (r.ndelays == 8)].iloc[0]\n",
    "# model_params_to_save = joblib.load(\n",
    "# join(args.save_dir_unique, 'model_params.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_thresholds = np.arange(0, 100, 1)\n",
    "corrs_tune_individual = args['corrs_tune']\n",
    "corrs_test_individual = args['corrs_test']\n",
    "corrs_test_pca = args2['corrs_test']\n",
    "res = []\n",
    "for percentile_threshold in percentile_thresholds:\n",
    "    args_top_thresh = np.where(corrs_tune_individual > np.percentile(\n",
    "        corrs_tune_individual, percentile_threshold))[0]\n",
    "    args_non_top_thresh = np.where(corrs_tune_individual <= np.percentile(\n",
    "        corrs_tune_individual, percentile_threshold))[0]\n",
    "    args_total = np.concatenate([args_top_thresh, args_non_top_thresh])\n",
    "    mean_corr_weighted = (corrs_test_individual[args_top_thresh].mean() * args_top_thresh.size +\n",
    "                          corrs_test_pca[args_non_top_thresh].mean() * args_non_top_thresh.size) / args_total.size\n",
    "    # print('mean corr weighted',\n",
    "    #       (corrs_test_individual[args_top_thresh].mean() * args_top_thresh.size +\n",
    "    #        corrs_test_pca[args_non_top_thresh].mean() * args_non_top_thresh.size) / args_total.size\n",
    "    #       )\n",
    "    res.append(mean_corr_weighted)\n",
    "plt.plot(percentile_thresholds, res)\n",
    "plt.axhline(corrs_test_individual.mean(), color='k', linestyle='--')\n",
    "plt.axhline(corrs_test_pca.mean(), color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate model weights usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_names_train, story_names_test = fit_encoding.get_story_names(args)\n",
    "stim_test_delayed, resp_test = fit_encoding.get_data(args, story_names_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calc_corrs(preds, resp):\n",
    "    corrs = []\n",
    "    for i in tqdm(range(preds.shape[1])):\n",
    "        corrs.append(np.corrcoef(\n",
    "            preds[:, i], resp[:, i])[0, 1])\n",
    "    return np.array(corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = model_params_to_save['weights']\n",
    "preds_test = stim_test_delayed @ wt\n",
    "corrs_test = _calc_corrs(preds_test, resp_test)\n",
    "print(np.mean(corrs_test))\n",
    "print(args.corrs_test_mean)\n",
    "assert np.allclose(corrs_test, args['corrs_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate PC models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = r[(r.pc_components == 100) * (r.feature_space == 'qa_embedder-5')\n",
    "         ].sort_values(by='corrs_tune_mean', ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_names_train, story_names_test = fit_encoding.get_story_names(args)\n",
    "stim_test_delayed, resp_test = fit_encoding.get_data(args, story_names_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params_to_save = joblib.load(\n",
    "    join(args.save_dir_unique, 'model_params.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = model_params_to_save['weights']\n",
    "# + model_params_to_save['bias'] (not needed for just calculating corr, but needed for predictions)\n",
    "preds_test = stim_test_delayed @ wt\n",
    "\n",
    "corrs_test = _calc_corrs(preds_test, resp_test)\n",
    "print(np.mean(corrs_test))\n",
    "print(args.corrs_test_mean)\n",
    "assert np.allclose(corrs_test, args['corrs_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original setup, before we had unpacked weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_pc = model_params_to_save['weights_pc']\n",
    "pca = model_params_to_save['pca']\n",
    "scaler_test = model_params_to_save['scaler_test']\n",
    "preds_pc = stim_test_delayed @ wt_pc\n",
    "preds_pc_scaled = scaler_test.inverse_transform(preds_pc)\n",
    "preds_voxels = pca.inverse_transform(preds_pc_scaled)\n",
    "corrs_test = _calc_corrs(preds_voxels, resp_test)\n",
    "assert np.allclose(corrs_test, args['corrs_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vary number of pcs included\n",
    "num_pcs = [5, 25, 50, 100, 200, 500, 1000]\n",
    "corrs = []\n",
    "for num_pc in num_pcs:\n",
    "    wt_pc = model_params_to_save['weights_pc']\n",
    "    pca = model_params_to_save['pca']\n",
    "    scaler_test = model_params_to_save['scaler_test']\n",
    "    preds_pc = stim_test_delayed @ wt_pc\n",
    "    preds_pc_scaled = scaler_test.inverse_transform(preds_pc)\n",
    "\n",
    "    pca_subset = deepcopy(pca)\n",
    "    pca_subset.components_[num_pc:] = 0\n",
    "    preds_voxels = pca_subset.inverse_transform(preds_pc_scaled)\n",
    "\n",
    "    corrs_test = _calc_corrs(preds_voxels, resp_test)\n",
    "    # assert np.allclose(corrs_test, args['corrs_test'])\n",
    "    print(num_pc, np.mean(corrs_test))\n",
    "    corrs.append(np.mean(corrs_test))\n",
    "plt.plot(num_pcs, corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_test = fit_encoding.evaluate_pc_model_on_each_voxel(\n",
    "    args, stim_test_delayed, resp_test,\n",
    "    model_params_to_save, pca, scaler_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = model_params_to_save['weights']\n",
    "\n",
    "# multiply\n",
    "preds_pc = stim_test_delayed @ wt\n",
    "preds_pc_unscaled = preds_pc * scaler_test.scale_ + scaler_test.mean_\n",
    "preds_voxels2 = preds_pc_unscaled @ pca.components_ + pca.mean_\n",
    "\n",
    "# rewrite the above as a multiplication of a single weight matrix\n",
    "preds_voxels2 = (stim_test_delayed @ wt * scaler_test.scale_ +\n",
    "                 scaler_test.mean_) @ pca.components_ + pca.mean_\n",
    "weight_full = wt * scaler_test.scale_ @ pca.components_\n",
    "bias_full = scaler_test.mean_ @ pca.components_ + pca.mean_\n",
    "preds_voxels2 = stim_test_delayed @ weight_full + bias_full\n",
    "\n",
    "assert np.allclose(preds_voxels, preds_voxels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert corrs_test.mean() == args.corrs_test_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
