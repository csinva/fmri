{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import dvu\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import imodelsx.process_results\n",
    "import qa_questions\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import analyze_helper\n",
    "fit_encoding = __import__('01_fit_encoding')\n",
    "dvu.set_style()\n",
    "\n",
    "results_dir = '/home/chansingh/mntv1/deep-fMRI/encoding/results_apr7'\n",
    "r, cols_varied, mets = analyze_helper.load_clean_results(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imodelsx.process_results.delete_runs_in_dataframe(\n",
    "#     r[r.seed != 1], actually_delete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = r\n",
    "# d = d[d.subject == 'UTS01']\n",
    "d = d[d.feature_selection_alpha_index < 0]\n",
    "d = d[d.distill_model_path == 'None']\n",
    "d = d[~(d.feature_space == 'qa_embedder-10') | (d.ndelays == 8)]\n",
    "d = d[~(d.feature_space == 'qa_embedder-25')]\n",
    "d = d[d.pc_components == 100]\n",
    "cols_varied = [c for c in cols_varied if not c in [\n",
    "    'distill_model_path', 'feature_selection_alpha_index']]\n",
    "# d = d[(d.qa_questions_version == 'v1') *\n",
    "#   (d.qa_embedding_model == 'mistral 7B')]\n",
    "if len(cols_varied) > 0:\n",
    "    d = d.groupby(cols_varied)[mets].mean()\n",
    "else:\n",
    "    d = d[mets]\n",
    "\n",
    "(\n",
    "    d\n",
    "    # .sort_values(by='corrs_test_mean', ascending=False)\n",
    "    .sort_values(by='corrs_tune_pc_mean', ascending=False)\n",
    "    .rename(columns=lambda x: x.replace('_', ' ').replace('corrs', ''))\n",
    "    .style\n",
    "    .background_gradient(cmap='magma', axis=0)\n",
    "    .format(precision=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # look at distill_model_path\n",
    "# d = r[(r.feature_space == 'qa_embedder-10') * (r.pc_components == 100)]\n",
    "# d = d.groupby(cols_varied)[mets].mean()\n",
    "# d.pivot_table(index=[c for c in cols_varied if not c == 'distill_model_path'],\n",
    "#               columns='distill_model_path', values='corrs_test_mean', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best results breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['feature_space_simplified'] = r['feature_space'].apply(\n",
    "    lambda x: 'llama' if 'llama' in x else x\n",
    ")\n",
    "d = r\n",
    "d = d[d.feature_selection_alpha_index < 0]\n",
    "d = d[d.distill_model_path == 'None']\n",
    "d = d[~(d.feature_space == 'qa_embedder-10') | (d.ndelays == 8)]\n",
    "d = d[~(d.feature_space == 'qa_embedder-25')]\n",
    "d = d[d.pc_components == 100]\n",
    "\n",
    "d = d.sort_values(\n",
    "    by='corrs_tune_pc_mean', ascending=False)\n",
    "d = d.groupby(['subject', 'feature_space_simplified'])[mets]\n",
    "d = d.first().reset_index()\n",
    "tab = d.pivot_table(index='subject', columns='feature_space_simplified',\n",
    "                    values='corrs_test_mean', aggfunc='mean')\n",
    "\n",
    "# # add average row\n",
    "tab.loc['AVG'] = tab.mean()\n",
    "tab.round(3)\n",
    "# for k, v in d:\n",
    "#     print(k)\n",
    "#     display(v.head().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab['Subject'] = tab.index.str.replace('UT', '')\n",
    "# rename stuf\n",
    "tab.columns = tab.columns.map(lambda x: {\n",
    "    'bert-10': 'BERT',\n",
    "    'eng1000': 'Eng1000',\n",
    "    'llama': 'LLaMA',\n",
    "    'qa_embedder-10': 'QA-Embs',\n",
    "}.get(x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = tab.melt(id_vars='Subject',\n",
    "                     var_name='feature_space_simplified', value_name='corrs_test_mean')\n",
    "# fig, ax = plt.subplots(figsize=(4, 3))\n",
    "plt.figure(figsize=(4.5, 3.2))\n",
    "sns.barplot(\n",
    "    plot_data, x='Subject', y='corrs_test_mean',\n",
    "    hue='feature_space_simplified',\n",
    "    hue_order=['Eng1000', 'QA-Embs', 'BERT', 'LLaMA'],\n",
    "    palette=['coral', 'C0', '#777', '#333'])\n",
    "# move legend outside\n",
    "plt.legend(loc='upper left', frameon=False)  # , bbox_to_anchor=(0.75, 1.2))\n",
    "plt.ylabel('Test correlation')\n",
    "plt.ylim((0.05, 0.15))\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figs/corr_best.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### qa version breakdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = r[(r.feature_space == 'qa_embedder-10') * (r.pc_components == 100)]\n",
    "# d = r[(r.pc_components == 100)]\n",
    "d = d[d.ndelays == 8]\n",
    "d = d.groupby(cols_varied)[mets].mean()\n",
    "(\n",
    "    d.pivot_table(index=[c for c in cols_varied if not c == 'qa_embedding_model'],\n",
    "                  columns='qa_embedding_model', values='corrs_test_mean', aggfunc='mean')\n",
    "    .style.background_gradient(cmap='magma')  # , axis=0)\n",
    "    .format(precision=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = r[(~r.feature_space.str.contains('qa_embedder')) * (r.pc_components == 100)]\n",
    "# d = r[(r.pc_components == 100)]\n",
    "# d = d[d.ndelays == 8]\n",
    "d = d.groupby(cols_varied)[mets].mean()\n",
    "(\n",
    "    d.pivot_table(index=[c for c in cols_varied if not c == 'feature_space'],\n",
    "                  columns='feature_space', values='corrs_test_mean', aggfunc='mean')\n",
    "    .style.background_gradient(cmap='magma')  # , axis=0)\n",
    "    .format(precision=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare performance of a few different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa = r[(r.feature_space == 'qa_embedder-5')\n",
    "# ].sort_values(by='corrs_tune_pc_mean', ascending=False).iloc[0]\n",
    "qa = r.iloc[0]\n",
    "eng1000 = r[(r.feature_space == 'eng1000')].sort_values(\n",
    "    by='corrs_tune_pc_mean', ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(qa['corrs_test'], eng1000['corrs_test'], '.', ms=1)\n",
    "plt.xlabel(f'QA Embedder (mean: {qa[\"corrs_test\"].mean():0.3f})')\n",
    "plt.ylabel(f'Eng1000 (mean: {eng1000[\"corrs_test\"].mean():0.3f})')\n",
    "plt.title('Test Correlations')\n",
    "m_max = max(qa['corrs_test'].max(), eng1000['corrs_test'].max())\n",
    "m_min = min(qa['corrs_test'].min(), eng1000['corrs_test'].min())\n",
    "plt.plot([m_min, m_max], [m_min, m_max], 'k--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check parameters for rerunning expts (alphas, delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = r[(r.pc_components == -1) * (r.ndelays == 8)].iloc[0]\n",
    "args = r.sort_values(by='corrs_test_mean').iloc[-1]\n",
    "model_params_to_save = joblib.load(\n",
    "    join(args.save_dir_unique, 'model_params.pkl'))\n",
    "print(args.feature_space, args.pc_components, args.ndelays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print which alphas are being used\n",
    "pd.Series(model_params_to_save['alphas_best']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = r[(r.pc_components == -1) * (r.feature_space == 'qa_embedder-5')\n",
    "         ].sort_values(by='corrs_tune_mean', ascending=False).iloc[0]\n",
    "args2 = r[(r.pc_components > 0) * (r.feature_space == 'qa_embedder-5')\n",
    "          ].sort_values(by='corrs_tune_mean', ascending=False).iloc[0]\n",
    "# args = r[]\n",
    "\n",
    "# args2 = r[(r.feature_space == 'eng1000')].iloc[0]\n",
    "# args = r[(r.pc_components == -1) * (r.feature_space == 8)].iloc[0]\n",
    "# args = r[(r.pc_components == -1) * (r.ndelays == 8)].iloc[0]\n",
    "# model_params_to_save = joblib.load(\n",
    "# join(args.save_dir_unique, 'model_params.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_thresholds = np.arange(0, 100, 1)\n",
    "corrs_tune_individual = args['corrs_tune']\n",
    "corrs_test_individual = args['corrs_test']\n",
    "corrs_test_pca = args2['corrs_test']\n",
    "res = []\n",
    "for percentile_threshold in percentile_thresholds:\n",
    "    args_top_thresh = np.where(corrs_tune_individual > np.percentile(\n",
    "        corrs_tune_individual, percentile_threshold))[0]\n",
    "    args_non_top_thresh = np.where(corrs_tune_individual <= np.percentile(\n",
    "        corrs_tune_individual, percentile_threshold))[0]\n",
    "    args_total = np.concatenate([args_top_thresh, args_non_top_thresh])\n",
    "    mean_corr_weighted = (corrs_test_individual[args_top_thresh].mean() * args_top_thresh.size +\n",
    "                          corrs_test_pca[args_non_top_thresh].mean() * args_non_top_thresh.size) / args_total.size\n",
    "    # print('mean corr weighted',\n",
    "    #       (corrs_test_individual[args_top_thresh].mean() * args_top_thresh.size +\n",
    "    #        corrs_test_pca[args_non_top_thresh].mean() * args_non_top_thresh.size) / args_total.size\n",
    "    #       )\n",
    "    res.append(mean_corr_weighted)\n",
    "plt.plot(percentile_thresholds, res)\n",
    "plt.axhline(corrs_test_individual.mean(), color='k', linestyle='--')\n",
    "plt.axhline(corrs_test_pca.mean(), color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate model weights usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = r.iloc[0]\n",
    "story_names_train, story_names_test = fit_encoding.get_story_names(args)\n",
    "stim_test_delayed, resp_test = fit_encoding.get_data(\n",
    "    args, story_names_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test stim is all 0?\n",
    "np.unique(stim_test_delayed, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calc_corrs(preds, resp):\n",
    "    corrs = []\n",
    "    for i in tqdm(range(preds.shape[1])):\n",
    "        corrs.append(np.corrcoef(\n",
    "            preds[:, i], resp[:, i])[0, 1])\n",
    "    return np.array(corrs)\n",
    "\n",
    "\n",
    "wt = model_params_to_save['weights']\n",
    "preds_test = stim_test_delayed @ wt\n",
    "corrs_test = _calc_corrs(preds_test, resp_test)\n",
    "print(np.mean(corrs_test))\n",
    "print(args.corrs_test_mean)\n",
    "assert np.allclose(corrs_test, args['corrs_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate PC models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = r[(r.pc_components == 100) * (r.feature_space == 'qa_embedder-5')\n",
    "         ].sort_values(by='corrs_tune_mean', ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_names_train, story_names_test = fit_encoding.get_story_names(args)\n",
    "stim_test_delayed, resp_test = fit_encoding.get_data(args, story_names_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params_to_save = joblib.load(\n",
    "    join(args.save_dir_unique, 'model_params.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = model_params_to_save['weights']\n",
    "# + model_params_to_save['bias'] (not needed for just calculating corr, but needed for predictions)\n",
    "preds_test = stim_test_delayed @ wt\n",
    "\n",
    "corrs_test = _calc_corrs(preds_test, resp_test)\n",
    "print(np.mean(corrs_test))\n",
    "print(args.corrs_test_mean)\n",
    "assert np.allclose(corrs_test, args['corrs_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original setup, before we had unpacked weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_pc = model_params_to_save['weights_pc']\n",
    "pca = model_params_to_save['pca']\n",
    "scaler_test = model_params_to_save['scaler_test']\n",
    "preds_pc = stim_test_delayed @ wt_pc\n",
    "preds_pc_scaled = scaler_test.inverse_transform(preds_pc)\n",
    "preds_voxels = pca.inverse_transform(preds_pc_scaled)\n",
    "corrs_test = _calc_corrs(preds_voxels, resp_test)\n",
    "assert np.allclose(corrs_test, args['corrs_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vary number of pcs included\n",
    "num_pcs = [5, 25, 50, 100, 200, 500, 1000]\n",
    "corrs = []\n",
    "for num_pc in num_pcs:\n",
    "    wt_pc = model_params_to_save['weights_pc']\n",
    "    pca = model_params_to_save['pca']\n",
    "    scaler_test = model_params_to_save['scaler_test']\n",
    "    preds_pc = stim_test_delayed @ wt_pc\n",
    "    preds_pc_scaled = scaler_test.inverse_transform(preds_pc)\n",
    "\n",
    "    pca_subset = deepcopy(pca)\n",
    "    pca_subset.components_[num_pc:] = 0\n",
    "    preds_voxels = pca_subset.inverse_transform(preds_pc_scaled)\n",
    "\n",
    "    corrs_test = _calc_corrs(preds_voxels, resp_test)\n",
    "    # assert np.allclose(corrs_test, args['corrs_test'])\n",
    "    print(num_pc, np.mean(corrs_test))\n",
    "    corrs.append(np.mean(corrs_test))\n",
    "plt.plot(num_pcs, corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_test = fit_encoding.evaluate_pc_model_on_each_voxel(\n",
    "    args, stim_test_delayed, resp_test,\n",
    "    model_params_to_save, pca, scaler_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = model_params_to_save['weights']\n",
    "\n",
    "# multiply\n",
    "preds_pc = stim_test_delayed @ wt\n",
    "preds_pc_unscaled = preds_pc * scaler_test.scale_ + scaler_test.mean_\n",
    "preds_voxels2 = preds_pc_unscaled @ pca.components_ + pca.mean_\n",
    "\n",
    "# rewrite the above as a multiplication of a single weight matrix\n",
    "preds_voxels2 = (stim_test_delayed @ wt * scaler_test.scale_ +\n",
    "                 scaler_test.mean_) @ pca.components_ + pca.mean_\n",
    "weight_full = wt * scaler_test.scale_ @ pca.components_\n",
    "bias_full = scaler_test.mean_ @ pca.components_ + pca.mean_\n",
    "preds_voxels2 = stim_test_delayed @ weight_full + bias_full\n",
    "\n",
    "assert np.allclose(preds_voxels, preds_voxels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert corrs_test.mean() == args.corrs_test_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
