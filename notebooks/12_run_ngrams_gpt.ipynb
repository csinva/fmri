{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../experiments')\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import imodelsx.process_results\n",
    "from neuro.features import qa_questions, feature_spaces\n",
    "from neuro.data import story_names\n",
    "from neuro.features.stim_utils import load_story_wordseqs, load_story_wordseqs_huge\n",
    "import random\n",
    "import json\n",
    "import neuro.config\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "fit_encoding = __import__('02_fit_encoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 103 stories\n",
      "len(ngrams_list_total)=195190 ngrams\n"
     ]
    }
   ],
   "source": [
    "story_names_list = sorted(story_names.get_story_names(\n",
    "    all=True))\n",
    "print('loaded', len(story_names_list), 'stories')\n",
    "wordseqs = load_story_wordseqs_huge(story_names_list)\n",
    "wordseq_idxs = {}\n",
    "ngrams_list_total = []\n",
    "running_idx = 0\n",
    "for story in story_names_list:\n",
    "    ngrams_list = feature_spaces.get_ngrams_list_main(\n",
    "        wordseqs[story], num_ngrams_context=10)\n",
    "    ngrams_list_total.extend(ngrams_list)\n",
    "    assert len(ngrams_list) == len(wordseqs[story].data)\n",
    "    wordseq_idxs[story] = (running_idx, running_idx + len(ngrams_list))\n",
    "    running_idx += len(ngrams_list)\n",
    "print(f'{len(ngrams_list_total)=} ngrams')\n",
    "joblib.dump(({'ngrams_list_total': ngrams_list_total, 'wordseq_idxs': wordseq_idxs}), os.path.join(\n",
    "    neuro.config.root_dir, 'qa/cache_gpt/ngrams_metadata.joblib'))\n",
    "\n",
    "\n",
    "questions = [\n",
    "    'Does the sentence describe a personal reflection or thought?',\n",
    "    'Does the sentence contain a proper noun?',\n",
    "    'Does the sentence describe a physical action?',\n",
    "    'Does the sentence describe a personal or social interaction that leads to a change or revelation?',\n",
    "    'Does the sentence involve the mention of a specific object or item?',  # completed\n",
    "    'Does the sentence involve a description of physical environment or setting?',\n",
    "    'Does the sentence describe a relationship between people?',\n",
    "    'Does the sentence mention a specific location?',\n",
    "    'Is time mentioned in the input?',  # completed\n",
    "    'Is the sentence abstract rather than concrete?',\n",
    "    \"Does the sentence express the narrator's opinion or judgment about an event or character?\",\n",
    "    'Is the input related to a specific industry or profession?',\n",
    "    'Does the sentence include dialogue?',\n",
    "    'Does the sentence describe a visual experience or scene?',\n",
    "    'Does the input involve planning or organizing?',\n",
    "    'Does the sentence involve spatial reasoning?',\n",
    "    'Does the sentence involve an expression of personal values or beliefs?',\n",
    "    'Does the sentence contain a negation?',\n",
    "    'Does the sentence describe a sensory experience?',\n",
    "    'Does the sentence include technical or specialized terminology?',\n",
    "    'Does the input contain a number?',\n",
    "    'Does the sentence contain a cultural reference?',\n",
    "    'Does the text describe a mode of communication?',\n",
    "    'Does the input include a comparison or metaphor?',\n",
    "    'Does the sentence express a sense of belonging or connection to a place or community?',\n",
    "    'Does the sentence describe a specific sensation or feeling?',\n",
    "    'Does the text include a planning or decision-making process?',\n",
    "    'Does the sentence include a personal anecdote or story?',\n",
    "    'Does the sentence involve a discussion about personal or social values?',\n",
    "    'Does the text describe a journey?',\n",
    "    'Does the input contain a measurement?',\n",
    "    'Does the sentence describe a physical sensation?',\n",
    "    'Does the sentence include a direct speech quotation?',\n",
    "    'Is the sentence reflective, involving self-analysis or introspection?',\n",
    "    'Does the input describe a specific texture or sensation?',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_name = 'wheretheressmoke'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt4_qa_embs(questions, story_name):\n",
    "    answers_dict = {}\n",
    "    for question in os.listdir(os.path.join(neuro.config.root_dir, 'qa/cache_gpt')):\n",
    "        out_file = os.path.join(neuro.config.root_dir,\n",
    "                                f'qa/cache_gpt/{question}')\n",
    "        answers_dict[question] = joblib.load(out_file)\n",
    "    out = pd.DataFrame(answers_dict, index=ngrams_list_total)\n",
    "\n",
    "    embs = np.zeros((len(wordseqs[story_name].data), len(questions)))\n",
    "    out_story = out.iloc[wordseq_idxs[story_name]\n",
    "                         [0]: wordseq_idxs[story_name][1]]\n",
    "    for q in out_story.columns:\n",
    "        assert q in questions\n",
    "        idx = questions.index(q)\n",
    "        embs[:, idx] = out_story[q].values\n",
    "\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_dict = {}\n",
    "for question in tqdm(questions[:17]):\n",
    "    out_file = f'/home/chansingh/mntv1/deep-fMRI/qa/cache_gpt/{question}.pkl'\n",
    "    answers_dict[question] = joblib.load(out_file)\n",
    "out = pd.DataFrame(answers_dict, index=ngrams_list_total)\n",
    "\n",
    "\n",
    "def abbrev_question(q):\n",
    "    for prefix in ['Does the sentence', 'Is the sentence', 'Does the input', 'Is the input']:\n",
    "        q = q.replace(prefix, '...')\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = deepcopy(out)\n",
    "o.columns = [abbrev_question(q) for q in o.columns]\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "corrs = o.corr()\n",
    "# set diag to nan\n",
    "vabs = np.nanmax(corrs)\n",
    "# plot clustermap with cbar bottom right and mask diagonal\n",
    "sns.clustermap(corrs, center=0, cmap='RdBu_r', vmin=-vabs,\n",
    "               vmax=vabs, cbar_pos=(0.5, 0.3, 0.03, 0.2))\n",
    "\n",
    "# add barplot on top of the clustermap\n",
    "# plt.figure(figsize=(10, 10))\n",
    "plt.xlabel('Mean correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
