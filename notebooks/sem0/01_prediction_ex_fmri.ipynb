{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import dvu\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import neuro.features.feature_utils\n",
    "import joblib\n",
    "import neuro.data.story_names\n",
    "import neuro.data.response_utils\n",
    "from tqdm import tqdm\n",
    "import neuro.features.feature_spaces\n",
    "from himalaya.ridge import RidgeCV\n",
    "from utils import generate_leave_one_run_out\n",
    "from sklearn.model_selection import check_cv\n",
    "from himalaya.backend import set_backend\n",
    "import neuro.config\n",
    "from tabpfn import TabPFNRegressor\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up basic regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'UTS03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resps = joblib.load(join(neuro.config.root_dir, 'data',\n",
    "                         'huge_data', f'{subject}_responses.jbl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_stories = 5\n",
    "n_voxels = 100\n",
    "n_feats = 400\n",
    "backend = set_backend(\"torch_cuda\")  # for himalaya\n",
    "n_delays_ridge = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_names_train = neuro.data.story_names.get_story_names(\n",
    "    subject=subject, train_or_test='train')[:n_train_stories]\n",
    "story_names_test = neuro.data.story_names.get_story_names(\n",
    "    # could set use_huge=True here and below....\n",
    "    subject=subject, train_or_test='test')\n",
    "# resps_train = neuro.data.response_utils.load_response(\n",
    "#     story_names_train, subject=subject)\n",
    "# resps_test = neuro.data.response_utils.load_response(\n",
    "#     story_names_test, subject=subject)\n",
    "resps_train = np.vstack([resps[story] for story in story_names_train])\n",
    "resps_test = np.vstack([resps[story] for story in story_names_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    feature_space = 'eng1000'\n",
    "\n",
    "\n",
    "# load feats, already trimmed and normalized\n",
    "args = A()\n",
    "feats_train = neuro.features.feature_utils.get_features_full(\n",
    "    args=args,\n",
    "    feature_space=args.feature_space,\n",
    "    qa_embedding_model=None,\n",
    "    story_names=story_names_train,\n",
    "    use_added_delays=False,\n",
    ")\n",
    "feats_test = neuro.features.feature_utils.get_features_full(\n",
    "    args=args,\n",
    "    feature_space=args.feature_space,\n",
    "    qa_embedding_model=None,\n",
    "    story_names=story_names_test,\n",
    "    use_added_delays=False,\n",
    ")\n",
    "\n",
    "print('feat shapes', feats_train.shape, feats_test.shape)\n",
    "print('resp shapes', resps_train.shape, resps_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample output voxels and feature inputs\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "corrs_test = joblib.load(join(neuro.config.PROCESSED_DIR, subject.replace(\n",
    "    'UT', ''), 'corrs_test_35.pkl')).values[0]\n",
    "# find indices of voxels in top-2000 voxels and randomly sample n_voxels\n",
    "inds_top = np.argsort(corrs_test)[-1000:]\n",
    "random_voxels = rng.choice(\n",
    "    inds_top, size=n_voxels, replace=False\n",
    ")\n",
    "resps_train_subsampled_voxels = resps_train[:, random_voxels].astype(\n",
    "    np.float32)\n",
    "resps_test_subsampled_voxels = resps_test[:, random_voxels].astype(np.float32)\n",
    "\n",
    "feats_train_subsampled = feats_train[:, :n_feats].astype(np.float32)\n",
    "feats_test_subsampled = feats_test[:, :n_feats].astype(np.float32)\n",
    "\n",
    "print('feat shapes', feats_train_subsampled.shape, feats_test_subsampled.shape)\n",
    "print('resp shapes', resps_train_subsampled_voxels.shape,\n",
    "      resps_test_subsampled_voxels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up cv splitting\n",
    "n_samples_train = feats_train_subsampled.shape[0]\n",
    "chunk_len = 40\n",
    "chunk_starts = np.arange(0, n_samples_train, chunk_len)\n",
    "cv = generate_leave_one_run_out(n_samples_train, chunk_starts)\n",
    "cv = check_cv(cv)  # copy the cross-validation splitter into a reusable list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RidgeCV(alphas=[1, 10, 100], cv=cv)\n",
    "# add delays for ridge\n",
    "feats_train_subsampled_delayed = neuro.features.feature_utils.make_delayed(\n",
    "    feats_train_subsampled, range(1, n_delays_ridge + 1))\n",
    "model.fit(feats_train_subsampled, resps_train_subsampled_voxels)\n",
    "preds_train = model.predict(feats_train_subsampled)\n",
    "preds_test = model.predict(feats_test_subsampled)\n",
    "\n",
    "\n",
    "def get_corrs(preds, resps):\n",
    "    return [np.corrcoef(preds[:, i], resps[:, i])[0, 1] for i in range(preds.shape[1])]\n",
    "\n",
    "\n",
    "r = defaultdict(list)\n",
    "r['corrs_train_ridge'] = get_corrs(preds_train, resps_train_subsampled_voxels)\n",
    "r['corrs_test_ridge'] = get_corrs(preds_test, resps_test_subsampled_voxels)\n",
    "print('train', np.mean(r['corrs_train_ridge']))\n",
    "print('test', np.mean(r['corrs_test_ridge']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_cols(n):\n",
    "\n",
    "    t = np.arange(n) / n\n",
    "    vals = [t]\n",
    "    for period in np.logspace(0, 3, 5):\n",
    "        vals.append(np.sin(t * period * 2 * np.pi))\n",
    "        vals.append(np.cos(t * period * 2 * np.pi))\n",
    "    return np.stack(vals, axis=1)\n",
    "\n",
    "\n",
    "time_cols = get_time_cols(\n",
    "    feats_train_subsampled.shape[0] + feats_test_subsampled.shape[0])\n",
    "feats_train_subsampled_with_time = np.concatenate(\n",
    "    [feats_train_subsampled, time_cols[:feats_train_subsampled.shape[0]]], axis=1)\n",
    "feats_test_subsampled_with_time = np.concatenate(\n",
    "    [feats_test_subsampled, time_cols[feats_train_subsampled.shape[0]:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(preds_train.shape[1])):\n",
    "    model = TabPFNRegressor(device='cuda:1')\n",
    "    model.fit(feats_train_subsampled, preds_train[:, i])\n",
    "    preds_test = model.predict(feats_test_subsampled)\n",
    "    r['corrs_test_tabpfn'].append(np.corrcoef(\n",
    "        preds_test, resps_test_subsampled_voxels[:, i])[0, 1])\n",
    "\n",
    "    # redo with time feats\n",
    "    model = TabPFNRegressor(device='cuda:1')\n",
    "    model.fit(feats_train_subsampled_with_time, preds_train[:, i])\n",
    "    preds_test = model.predict(feats_test_subsampled_with_time)\n",
    "    r['corrs_test_tabpfn_time'].append(np.corrcoef(\n",
    "        preds_test, resps_test_subsampled_voxels[:, i])[0, 1])\n",
    "\n",
    "    print(\n",
    "        f'voxel {i} test {r[\"corrs_test_ridge\"][i]:.3f} -> {r[\"corrs_test_tabpfn\"][-1]:.3f} -> {r[\"corrs_test_tabpfn_time\"][-1]:.3f}')\n",
    "    print(\n",
    "        '\\tavg cum. improvement',\n",
    "        np.mean(r['corrs_test_tabpfn'] -\n",
    "                np.mean(r['corrs_test_ridge'][:len(r['corrs_test_tabpfn'])])),\n",
    "        np.mean(r['corrs_test_tabpfn_time'] -\n",
    "                np.mean(r['corrs_test_ridge'][:len(r['corrs_test_tabpfn_time'])]))\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
