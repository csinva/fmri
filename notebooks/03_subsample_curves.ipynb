{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from os.path import join\n",
    "# import config\n",
    "import numpy as np\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from neuro import analyze_helper, viz\n",
    "from neuro.features.feat_select import get_alphas\n",
    "import matplotlib.patches as mpatches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = analyze_helper.best_results_dir\n",
    "r, cols_varied, mets = analyze_helper.load_clean_results(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[r['qa_questions_version'] ==\n",
    "    'v3_boostexamples_merged']['weight_enet_mask_num_nonzero'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = rr\n",
    "r = r[r.qa_questions_version.isin(['', 'v3_boostexamples_merged'])]\n",
    "# r = r[r.feature_selection_alpha == -1]\n",
    "r = r[~r.feature_space.isin(\n",
    "    ['meta-llama/Llama-2-7b-hf', 'meta-llama/Meta-Llama-3-8B'])]\n",
    "cols_varied = [c for c in cols_varied if not c in [\n",
    "    'feature_selection_stability_seeds']]\n",
    "\n",
    "r = r[r.qa_embedding_model.isin(['', 'ensemble1', 'ensemble2'])]\n",
    "\n",
    "# only keep feature selection with stability\n",
    "r = r[(r.feature_selection_alpha < 0) | (\n",
    "    r.feature_selection_stability_seeds > 0)]\n",
    "\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check runs (full grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = r\n",
    "# d = d[d.subject.isin(['S01', 'S02', 'S03'])]\n",
    "d = d[~(d.num_stories == 15)]\n",
    "# d = d[d.feature_selection_alpha < 0]\n",
    "d = d[\n",
    "    (d.feature_selection_alpha < 0) |\n",
    "    ((d.feature_space_simplified == 'qa_embedder')\n",
    "     & (d.feature_selection_alpha == get_alphas('qa_embedder')[3]))\n",
    "]\n",
    "d = d.groupby(cols_varied)[['corrs_test_mean']].mean()\n",
    "cols_top = ['feature_space', 'embedding_layer',\n",
    "            'qa_embedding_model', 'qa_questions_version', 'feature_selection_alpha']\n",
    "d = (\n",
    "    d.pivot_table(index=[c for c in cols_varied if not c in cols_top],\n",
    "                  columns=cols_top, values='corrs_test_mean', aggfunc='mean')\n",
    "    .sort_index(axis=1)\n",
    ")\n",
    "display(\n",
    "    d.style\n",
    "    .background_gradient(cmap='viridis', axis=1)\n",
    "    .format(precision=3)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check simplified table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.feature_space.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.feature_space_simplified.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = r\n",
    "d.num_stories = d.num_stories.replace(-1, 100)\n",
    "num_stories_list = [5, 10, 20, 100]\n",
    "d = d[d.num_stories.isin(num_stories_list)]\n",
    "# d = d[d.num_stories == 10]\n",
    "# d = d[d.subject.isin(['S01', 'S02', 'S03'])]\n",
    "# d = d[~d.subject.isin(['S01', 'S02', 'S03'])]\n",
    "d = d[\n",
    "    (d.feature_selection_alpha < 0) |\n",
    "    ((d.feature_space_simplified == 'qa_embedder')\n",
    "     & (d.feature_selection_alpha == get_alphas('qa_embedder')[3]))\n",
    "]\n",
    "group_cols = ['subject', 'num_stories',\n",
    "              'feature_space_simplified', 'feature_selection_alpha']\n",
    "metric_sort = 'corrs_tune_pc_weighted_mean'\n",
    "d = d.sort_values(\n",
    "    by=metric_sort, ascending=False)\n",
    "\n",
    "d = d.groupby(group_cols)[mets]\n",
    "d = d.first().reset_index()\n",
    "cols_top = ['feature_space_simplified', 'feature_selection_alpha']\n",
    "d_tab = (\n",
    "    d.pivot_table(index=[c for c in group_cols if not c in cols_top],\n",
    "                  columns=cols_top, values='corrs_test_mean', aggfunc='mean')\n",
    "    .sort_index(axis=1)\n",
    ")\n",
    "display(\n",
    "    d_tab.style\n",
    "    .background_gradient(cmap='magma', axis=1)\n",
    "    .format(precision=3)\n",
    ")\n",
    "\n",
    "\n",
    "# plot\n",
    "d['legend'] = list(\n",
    "    zip(d.feature_space_simplified.map(viz.feature_space_rename), d.feature_selection_alpha))\n",
    "# ('BERT', -1.0), ('Eng1000', -1.0), ('LLaMA', -1.0),\n",
    "#    ('QA-Emb', -1.0), ('QA-Emb', 0.28)\n",
    "d['legend'] = d['legend'].map(lambda x: {\n",
    "    ('BERT', -1.0): 'BERT',\n",
    "    ('Eng1000', -1.0): 'Eng1000',\n",
    "    ('LLaMA', -1.0): 'LLaMA',\n",
    "    ('QA-Emb', -1.0): 'QA-Emb',\n",
    "    ('QA-Emb', 0.28): 'QA-Emb (35 questions)'\n",
    "}.get(x, x))\n",
    "kwargs = dict(\n",
    "    x='num_stories',\n",
    "    y='corrs_test_mean',\n",
    "    hue='legend',\n",
    "    hue_order=['Eng1000', 'BERT', 'LLaMA', 'QA-Emb', 'QA-Emb (35 questions)'],\n",
    "    palette=['tomato', '#aaa', '#000', 'C0', 'cadetblue'],\n",
    "    dodge=True,\n",
    ")\n",
    "# sns.boxplot(**kwargs, fill=False)\n",
    "# fig = plt.figure(figsize=(12, 6))\n",
    "plt.figure(dpi=300)\n",
    "ax = sns.barplot(**kwargs, data=d, alpha=0.2, errorbar='se',\n",
    "                 err_kws={'alpha': 0.4}, legend=False)\n",
    "sns.stripplot(\n",
    "    **kwargs, data=d[d.subject.isin(['S01', 'S02', 'S03'])], jitter=True, size=4, marker='^', legend=False)\n",
    "# sns.stripplot(**kwargs, jitter=True, size=4)\n",
    "sns.stripplot(\n",
    "    **kwargs, data=d[~d.subject.isin(['S01', 'S02', 'S03'])], jitter=True, size=4)\n",
    "\n",
    "# ylim bottom to 0\n",
    "plt.ylim(bottom=0)\n",
    "\n",
    "# replace \"100\" with \"All\" on xticklabels\n",
    "xtick_labels = ax.get_xticklabels()\n",
    "ax.set_xticklabels(['All' if label.get_text() ==\n",
    "                   '100' else label.get_text() for label in xtick_labels])\n",
    "\n",
    "plt.xlabel(\"Number of stories used for training\")\n",
    "plt.ylabel(\"Test correlation\")\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.savefig('../qa_results/figs/subsample_barplot.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_stories_list = [5, 10, 20, 100]\n",
    "dt = d_tab.reset_index()\n",
    "for i, num_stories in enumerate(num_stories_list):\n",
    "    dn = dt[dt.num_stories == num_stories]\n",
    "    # display(dn)\n",
    "    print(f'num_stories = {num_stories}')\n",
    "    display(dn.drop(columns=['num_stories']).style.background_gradient(\n",
    "        cmap='magma', axis=1).format(precision=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
