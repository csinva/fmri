{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import dvu\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import imodelsx.process_results\n",
    "import qa_questions\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "fit_encoding = __import__('01_fit_encoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f927e0bcdd2f40999680dcb7c6f3f5ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, pipeline\n",
    "\n",
    "checkpoint = 'meta-llama/Llama-2-7b-hf'\n",
    "tokenizer = imodelsx.llm.load_tokenizer(checkpoint)\n",
    "model = AutoModel.from_pretrained(\n",
    "    checkpoint, output_hidden_states=True)\n",
    "\n",
    "# Input text\n",
    "texts = ['this is a sample text that is longer than the other one',\n",
    "         'the cat chased the dog']\n",
    "\n",
    "# Get embeddings\n",
    "inputs = tokenizer(texts, return_tensors='pt', padding=True)\n",
    "hidden_states = model(**inputs).hidden_states\n",
    "\n",
    "# layers x batch x tokens x features\n",
    "layer_idx = 18\n",
    "embs = hidden_states[layer_idx].detach().numpy()\n",
    "embs = embs[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'bert-base-uncased'\n",
    "llm = imodelsx.llm.LLMEmbs(checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embs \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_embs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m18\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/imodelsx/imodelsx/llm.py:492\u001b[0m, in \u001b[0;36mLLMEmbs.get_embs\u001b[0;34m(self, texts, layer_idx, batch_size)\u001b[0m\n\u001b[1;32m    489\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\u001b[38;5;241m.\u001b[39mhidden_states\n\u001b[1;32m    491\u001b[0m \u001b[38;5;66;03m# layers x batch x tokens x features\u001b[39;00m\n\u001b[0;32m--> 492\u001b[0m emb \u001b[38;5;241m=\u001b[39m \u001b[43mhidden_states\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    494\u001b[0m \u001b[38;5;66;03m# get emb from last token\u001b[39;00m\n\u001b[1;32m    495\u001b[0m emb \u001b[38;5;241m=\u001b[39m emb[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "embs = llm.get_embs(texts, layer_idx=18, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4096)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
