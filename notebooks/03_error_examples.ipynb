{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import imodelsx.process_results\n",
    "import qa_questions\n",
    "import random\n",
    "import json\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import feature_spaces\n",
    "fit_encoding = __import__('01_fit_encoding')\n",
    "import encoding_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    use_test_setup = False\n",
    "    subject = 'UTS03'\n",
    "    num_stories = -1\n",
    "\n",
    "\n",
    "args = A()\n",
    "story_names_train, story_names_test = fit_encoding.get_story_names(args)\n",
    "wordseqs = feature_spaces.get_story_wordseqs(story_names_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random exapmles for prompting new questions (v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 43  # 42, 43\n",
    "ngrams_examples = []\n",
    "ngram_size = 10\n",
    "num_examples_per_story = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "for story_name in story_names_train:\n",
    "    words_list = wordseqs[story_name].data\n",
    "    ngrams_list = feature_spaces._get_ngrams_list_from_words_list(\n",
    "        words_list, ngram_size=ngram_size)[ngram_size + 2:]\n",
    "    ngrams_examples += np.random.choice(ngrams_list,\n",
    "                                        num_examples_per_story).tolist()\n",
    "print('\\n'.join(['- ' + ngram for ngram in ngrams_examples]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate examples for boosted questions based model errors (v4, v5)\n",
    "- note: v4 wasn't actually boosted because the model we used was basically random\n",
    "- v5 settings were:\n",
    "  - args_top.feature_space='qa_embedder-10' args_top.ndelays=4\n",
    "  - args_top.corrs_test_mean=0.126 args_top.corrs_tune_pc_mean=0.134110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load top model to boost\n",
    "# results_dir = '/home/chansingh/mntv1/deep-fMRI/encoding/results_apr1'\n",
    "results_dir = '/home/chansingh/mntv1/deep-fMRI/encoding/results_apr7'\n",
    "r = imodelsx.process_results.get_results_df(results_dir)\n",
    "for k in ['save_dir', 'save_dir_unique']:\n",
    "    r[k] = r[k].map(lambda x: x if x.startswith('/home')\n",
    "                    else x.replace('/mntv1', '/home/chansingh/mntv1'))\n",
    "\n",
    "args_top = r[\n",
    "    (r.feature_space.str.contains('qa_embedder')) *\n",
    "    (r.pc_components == 100) *\n",
    "    (r.ndelays == 4) *\n",
    "    (r.qa_questions_version == 'v4')\n",
    "].sort_values(\n",
    "    by='corrs_tune_pc_mean',\n",
    "    ascending=False).iloc[0]\n",
    "print(f'{args_top.feature_space=} {args_top.ndelays=}')\n",
    "print(f'{args_top.corrs_test_mean=:.3f} {args_top.corrs_tune_pc_mean=:3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params_to_save = joblib.load(\n",
    "    join(args_top.save_dir_unique, 'model_params.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = defaultdict(list)\n",
    "for story_name in tqdm(story_names_train):\n",
    "    # ngram for 3 trs preceding the current TR\n",
    "    chunks = wordseqs[story_name].chunks()\n",
    "    ngrams_list = feature_spaces._get_ngrams_list_from_chunks(\n",
    "        chunks, num_trs=3)\n",
    "    ngrams_list = np.array(ngrams_list[10:-5])\n",
    "\n",
    "    stim_train_delayed, resp_train = fit_encoding.get_data(\n",
    "        args_top, [story_name])\n",
    "\n",
    "    preds_test = stim_train_delayed @ model_params_to_save['weights'] + \\\n",
    "        model_params_to_save['bias']\n",
    "\n",
    "    # calculate correlation at each timepoint\n",
    "    corrs_time = np.array([np.corrcoef(resp_train[i, :], preds_test[i, :])[0, 1]\n",
    "                           for i in range(resp_train.shape[0])])\n",
    "    corrs_time[:10] = 100  # don't pick first 10 TRs\n",
    "    # get worst 3 idxs\n",
    "    corrs_worst_idxs = np.argsort(corrs_time)[:3]\n",
    "\n",
    "    for i in range(3):\n",
    "        r['story_name'].append(story_name)\n",
    "        r['corrs'].append(corrs_time[corrs_worst_idxs[i]])\n",
    "        r['ngram'].append(ngrams_list[corrs_worst_idxs[i]])\n",
    "        r['tr'].append(corrs_worst_idxs[i])\n",
    "\n",
    "    joblib.dump(r, '04_ngrams_boost_v5.pkl')  # saved as 04_ngrams_boost.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_boost = pd.DataFrame(joblib.load('04_ngrams_boost_v5.pkl'))\n",
    "print('\\n'.join(['- ' + x for x in ngrams_boost.iloc[::2]\n",
    "      ['ngram'].values if len(x.strip()) > 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_prev = json.load(open('../all_questions_v1-v4.json'))\n",
    "print('\\n'.join(['- ' + x for x in questions_prev[1::2]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
