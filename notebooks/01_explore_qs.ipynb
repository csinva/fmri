{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../experiments')\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "from neuro.features import qa_questions, feature_spaces\n",
    "import dvu\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "dvu.set_style()\n",
    "fit_encoding = __import__('02_fit_encoding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at activations for questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read and export some questions\n",
    "# qs = pd.read_csv('../qa_results/v3_boostexamples_num=29/questions.csv')\n",
    "# qs = (\n",
    "#     qs.rename(columns={'question': 'Question',\n",
    "#               'avg_abs_coef_normalized': 'Importance'})\n",
    "#     .to_latex(escape=False, column_format='lrrrr', float_format='%.3f', index=False)\n",
    "# )\n",
    "# for s in ['Does the sentence', 'Is the sentence', 'Does the input', 'in the input?', '?']:\n",
    "#     qs = qs.replace(s, r'\\textcolor{gray}{' + s + '}')\n",
    "# print(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    use_test_setup = False\n",
    "    subject = 'UTS03'\n",
    "    feature_space = 'qa_embedder'\n",
    "    # qa_embedding_model = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "    # qa_embedding_model = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "    qa_embedding_model = 'ensemble1'\n",
    "    trim = 5\n",
    "    num_stories = -1\n",
    "    # num_stories = 2\n",
    "    seed_stories = 1\n",
    "    use_huge = 1\n",
    "    input_chunking_type = 'ngram'\n",
    "    input_chunking_size = 10\n",
    "    embedding_layer = -1\n",
    "\n",
    "\n",
    "args = A()\n",
    "story_names_train, story_names_test = fit_encoding.get_story_names(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:getting wordseqs..\n",
      "INFO:root:extracting qa_embedder v1 ensemble1 embs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading embedding_model...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'QuestionEmbedder' object has no attribute 'checkpoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m ngrams_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m qa_questions_version \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv3_boostexamples\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Features (this doesn't support ensemble1!)\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     allstories, vectors, wordseqs, ngrams_list_dict \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_spaces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# allstories=story_names_train,\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# allstories=story_names_test,\u001b[39;49;00m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstory_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstory_names_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqa_embedding_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqa_embedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqa_questions_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqa_questions_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownsample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_huge\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_huge\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# n_time_points x n_features\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# features_downsampled = encoding_utils.trim_and_normalize_features(\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# features_downsampled_dict, args.trim, normalize=True\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([vectors[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m vectors\u001b[38;5;241m.\u001b[39mkeys()])\n",
      "File \u001b[0;32m~/fmri/neuro/features/feature_spaces.py:326\u001b[0m, in \u001b[0;36mget_features\u001b[0;34m(args, feature_space, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_wordrate_vectors(wordseqs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_llm_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwordseqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_extra\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/fmri/neuro/features/feature_spaces.py:254\u001b[0m, in \u001b[0;36mget_llm_vectors\u001b[0;34m(wordseqs, story_names, checkpoint, num_ngrams_context, num_trs_context, num_secs_context_per_word, layer_idx, qa_embedding_model, qa_questions_version, downsample, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# embed the ngrams\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m embedding_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 254\u001b[0m     embedding_model \u001b[38;5;241m=\u001b[39m \u001b[43m_get_embedding_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqa_questions_version\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqa_embedding_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqa_embedder\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstory_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(story_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/fmri/neuro/features/feature_spaces.py:199\u001b[0m, in \u001b[0;36mget_llm_vectors.<locals>._get_embedding_model\u001b[0;34m(checkpoint, qa_questions_version, qa_embedding_model)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqa_embedder\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    197\u001b[0m     questions \u001b[38;5;241m=\u001b[39m qa_questions\u001b[38;5;241m.\u001b[39mget_questions(\n\u001b[1;32m    198\u001b[0m         version\u001b[38;5;241m=\u001b[39mqa_questions_version)\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mQuestionEmbedder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqa_embedding_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# dont cache calls locally\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m checkpoint\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinetune_\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m FinetunedQAEmbedder(\n\u001b[1;32m    203\u001b[0m         checkpoint\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinetune_\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_binary\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m), qa_questions_version\u001b[38;5;241m=\u001b[39mqa_questions_version)\n",
      "File \u001b[0;32m~/fmri/neuro/features/qa_embedder.py:123\u001b[0m, in \u001b[0;36mQuestionEmbedder.__init__\u001b[0;34m(self, questions, checkpoint, use_cache)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m  \u001b[38;5;66;03m# requires 8 GPUs\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# self.llm = guidance.models.Transformers(\"meta-llama/Llama-2-13b-hf\")\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# print('PROMPT', self.prompt)\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm \u001b[38;5;241m=\u001b[39m imodelsx\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mget_llm(\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m, CACHE_DIR\u001b[38;5;241m=\u001b[39mexpanduser(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m~/cache_qa_embedder\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# self.llm = LLM(model=checkpoint,\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m#    tensor_parallel_size=torch.cuda.device_count())\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# self.sampling_params = SamplingParams(temperature=0, max_tokens=1)\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m use_cache\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'QuestionEmbedder' object has no attribute 'checkpoint'"
     ]
    }
   ],
   "source": [
    "# # get downsampled features\n",
    "# features_downsampled_list = []\n",
    "# for qa_questions_version in ['v1']:\n",
    "#     # Features\n",
    "#     features_downsampled_dict = feature_spaces.get_features(\n",
    "#         args.feature_space,\n",
    "#         allstories=story_names_train,\n",
    "#         qa_embedding_model=args.qa_embedding_model,\n",
    "#         qa_questions_version=qa_questions_version,\n",
    "#     )\n",
    "#     # n_time_points x n_features\n",
    "#     features_downsampled = encoding_utils.trim_and_normalize_features(\n",
    "#         features_downsampled_dict, args.trim, normalize=True\n",
    "#     )\n",
    "#     features_downsampled_list.append(deepcopy(features_downsampled))\n",
    "# features_downsampled_list = np.hstack(features_downsampled_list)\n",
    "\n",
    "# # transform so feats is (features x n_time_points)\n",
    "# feats = features_downsampled_list.T\n",
    "\n",
    "# get non-downsampled features\n",
    "features_downsampled_list = []\n",
    "ngrams_list = []\n",
    "for qa_questions_version in ['v1', 'v2', 'v3_boostexamples']:\n",
    "    # Features (this doesn't support ensemble1!)\n",
    "    allstories, vectors, wordseqs, ngrams_list_dict = feature_spaces.get_features(\n",
    "        args=args,\n",
    "        feature_space=args.feature_space,\n",
    "        story_names=story_names_train,\n",
    "        qa_embedding_model=args.qa_embedding_model,\n",
    "        qa_questions_version=qa_questions_version,\n",
    "        downsample=False,\n",
    "        use_huge=args.use_huge,\n",
    "    )\n",
    "    # n_time_points x n_features\n",
    "    # features_downsampled = encoding_utils.trim_and_normalize_features(\n",
    "    # features_downsampled_dict, args.trim, normalize=True\n",
    "    # )\n",
    "    features = np.vstack([vectors[k] for k in vectors.keys()])\n",
    "    ngrams_list = sum([ngrams_list_dict[k]\n",
    "                      for k in ngrams_list_dict.keys()], [])\n",
    "    features_downsampled_list.append(deepcopy(features))\n",
    "    # ngrams_list.append(ngrams)\n",
    "    # assert len(ngrams) == features.shape[0]\n",
    "features_downsampled_list = np.hstack(features_downsampled_list)\n",
    "\n",
    "# transform so feats is (features x n_time_points)\n",
    "feats = features_downsampled_list.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export to csv\n",
    "# qa_questions_version = 'v3_boostexamples'\n",
    "# qs = qa_questions.get_questions(qa_questions_version, full=True)\n",
    "\n",
    "# # save compressed\n",
    "# np.savez_compressed(f'../data/{qa_questions_version}_answers_test_numpy',\n",
    "#                     feats.astype(bool).T)\n",
    "# joblib.dump({'columns': qs, 'index': ngrams_list},\n",
    "#             f'../data/{qa_questions_version}_test_metadata.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(300):\n",
    "    plt.plot(feats[i][:1000], '.')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Feature value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = np.corrcoef(feats)\n",
    "# set diagonal to nan\n",
    "# np.fill_diagonal(corrs, np.nan)\n",
    "qs_1 = qa_questions.get_questions('v1')\n",
    "# qs_2 = qa_questions.get_questions('v2')\n",
    "# qs = qs_1 + qs_2\n",
    "qs = qs_1\n",
    "corrs = pd.DataFrame(corrs, columns=qs, index=qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustermap = sns.clustermap(corrs)\n",
    "plt.close()\n",
    "corrs = corrs.iloc[:, clustermap.dendrogram_col.reordered_ind]\n",
    "corrs = corrs.iloc[clustermap.dendrogram_row.reordered_ind, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cbar in bottom right\n",
    "# sns.clustermap(\n",
    "sns.heatmap(\n",
    "    corrs,\n",
    "    # cbar_pos=(0.85, 0.03, 0.03, 0.2),\n",
    "    # figsize=(20, 20),\n",
    "    cbar_kws={'label': 'Correlation Coefficient'},\n",
    "    vmin=-1, vmax=1, cmap='RdBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_triu = corrs.where(np.triu(np.ones(corrs.shape), k=1).astype(bool))\n",
    "plt.hist(corrs_triu.values.flatten(), bins=100)\n",
    "plt.xlabel('Pairwise correlation')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indexes/columns of high correlations\n",
    "high_corr = corrs_triu[corrs_triu > 0.6].stack().index\n",
    "high_corr_idx = [(high_corr[i][0], high_corr[i][1])\n",
    "                 for i in range(len(high_corr))]\n",
    "high_corr_vals = [corrs_triu.loc[high_corr[i][0], high_corr[i][1]]\n",
    "                  for i in range(len(high_corr))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(high_corr_idx)):\n",
    "    print(high_corr_vals[i])\n",
    "    print('\\t', high_corr_idx[i][0])\n",
    "    print('\\t', high_corr_idx[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_fracs = pd.DataFrame({\n",
    "    'yes_frac': feats.mean(axis=1),\n",
    "    'question': qs_1,\n",
    "}).sort_values(by='yes_frac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display full width and non-truncated strings\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', None, 'display.max_colwidth', None):\n",
    "    display(yes_fracs.head(30).round(3))\n",
    "    display(yes_fracs.tail(30).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exact sparsity doesnt work that well bc of lanczos sampling\n",
    "# feat_mins = np.zeros(feats.shape[0])\n",
    "# for i in range(feats.shape[0]):\n",
    "# feat_mins[i] = (feats[i] == np.min(feats[i])).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
