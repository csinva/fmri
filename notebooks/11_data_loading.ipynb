{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import imodelsx.process_results\n",
    "import sys\n",
    "import numpy as np\n",
    "import src.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = joblib.load(join('../data/', \"story_data\", \"grids_huge.jbl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grids_huge.jbl\ttrfiles_huge.jbl     UTS02_responses.jbl\n",
      "readme.txt\tUTS01_responses.jbl\n"
     ]
    }
   ],
   "source": [
    "!ls ~/mntv1/deep-fMRI/data/huge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trfiles = joblib.load(join(\n",
    "#     '../data/', \"story_data\", \"trfiles_huge.jbl\"))\n",
    "trfiles = joblib.load(join(src.config.root_dir, 'data',\n",
    "                           'huge_data', 'trfiles_huge.jbl'))\n",
    "grids = joblib.load(join(src.config.root_dir, 'data',\n",
    "                         'huge_data', 'grids_huge.jbl'))\n",
    "wordseqs = make_word_ds(grids, trfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes ~2mins while, loads 20+ GBs...\n",
    "resps = joblib.load(join(src.config.root_dir, 'data',\n",
    "                    'huge_data', 'UTS01_responses.jbl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_story_candidates = [\"wheretheressmoke\",\n",
    "                         \"fromboyhoodtofatherhood\", \"onapproachtopluto\"]\n",
    "train_stories = [s for s in resps.keys() if s not in test_story_candidates]\n",
    "test_stories = [s for s in resps.keys() if s in test_story_candidates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['itsabox', 'odetostepfather', 'inamoment', 'hangtime', 'ifthishaircouldtalk', 'goingthelibertyway', 'golfclubbing', 'thetriangleshirtwaistconnection', 'igrewupinthewestborobaptistchurch', 'tetris', 'becomingindian', 'canplanetearthfeedtenbillionpeoplepart1', 'thetiniestbouquet', 'swimmingwithastronauts', 'lifereimagined', 'forgettingfear', 'stumblinginthedark', 'backsideofthestorm', 'food', 'theclosetthatateeverything', 'notontheusualtour', 'exorcism', 'adventuresinsayingyes', 'thefreedomridersandme', 'cocoonoflove', 'waitingtogo', 'thepostmanalwayscalls', 'googlingstrangersandkentuckybluegrass', 'mayorofthefreaks', 'learninghumanityfromdogs', 'shoppinginchina', 'souls', 'cautioneating', 'comingofageondeathrow', 'breakingupintheageofgoogle', 'gpsformylostidentity', 'eyespy', 'treasureisland', 'thesurprisingthingilearnedsailingsoloaroundtheworld', 'theadvancedbeginner', 'goldiethegoldfish', 'life', 'thumbsup', 'seedpotatoesofleningrad', 'theshower', 'adollshouse', 'canplanetearthfeedtenbillionpeoplepart2', 'sloth', 'howtodraw', 'quietfire', 'metsmagic', 'penpal', 'thecurse', 'canadageeseandddp', 'thatthingonmyarm', 'buck', 'wildwomenanddancingqueens', 'againstthewind', 'indianapolis', 'alternateithicatom', 'bluehope', 'kiksuya', 'afatherscover', 'haveyoumethimyet', 'firetestforlove', 'catfishingstrangerstofindmyself', 'christmas1940', 'tildeath', 'lifeanddeathontheoregontrail', 'vixenandtheussr', 'undertheinfluence', 'beneaththemushroomcloud', 'jugglingandjesus', 'superheroesjustforeachother', 'sweetaspie', 'naked', 'singlewomanseekingmanwich', 'avatar', 'whenmothersbullyback', 'myfathershands', 'reachingoutbetweenthebars', 'theinterview', 'stagefright', 'legacy', 'canplanetearthfeedtenbillionpeoplepart3', 'listo', 'gangstersandcookies', 'birthofanation', 'mybackseatviewofagreatromance', 'lawsthatchokecreativity', 'threemonths', 'whyimustspeakoutaboutclimatechange', 'leavingbaghdad']\n"
     ]
    }
   ],
   "source": [
    "print(train_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resps['itsabox'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import h5py\n",
    "from ridge_utils.dsutils import make_word_ds, make_phoneme_ds\n",
    "\n",
    "\n",
    "class HuthLabDataset(Dataset):\n",
    "    def __init__(self, data_dir: str, subject: str, num_trs: int, trim_start: int = 5, trim_end: int = 10):\n",
    "        self.subject = subject\n",
    "        self.stories = joblib.load(os.path.join(\n",
    "            data_dir, subject, \"storylist.jbl\"))\n",
    "        self.grids = joblib.load(os.path.join(\n",
    "            data_dir, \"story_data\", \"grids.jbl\"))\n",
    "        self.trfiles = joblib.load(os.path.join(\n",
    "            data_dir, \"story_data\", \"trfiles.jbl\"))\n",
    "        self.wordseqs = make_word_ds(self.grids, self.trfiles)\n",
    "        self.trim_start = trim_start\n",
    "        self.trim_end = trim_end\n",
    "        self.lookback = num_trs  # num_trs = num_seconds / 2\n",
    "        self.resp_dict = {}\n",
    "        self.chunk_dict = {}\n",
    "        for story in self.stories:\n",
    "            hf5_path = os.path.join(data_dir, subject, story + \".hf5\")\n",
    "            self.resp_dict[story] = h5py.File(hf5_path, 'r')\n",
    "            self.chunk_dict[story] = self.wordseqs[story].chunks()[\n",
    "                self.trim_start:-self.trim_end]\n",
    "            # Confirm trimming dimensions match\n",
    "            num_trs_stim = len(\n",
    "                self.wordseqs[story].tr_times[self.trim_start:-self.trim_end])\n",
    "            num_trs_resp = self.resp_dict[story]['data'].shape[0]\n",
    "            assert num_trs_stim == num_trs_resp\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stories)\n",
    "\n",
    "    def __getitem__(self, story: str, idx: int, delays: int):\n",
    "        assert delays >= 0\n",
    "        if delays == 0:\n",
    "            return (self.chunk_dict[story][idx], self.resp_dict[story]['data'][idx])\n",
    "        else:\n",
    "            acc_out = []\n",
    "            for i in range(delays+1):\n",
    "                if idx-delays+i < 0:\n",
    "                    acc_out.append(np.array([], dtype='<U13'))\n",
    "                else:\n",
    "                    acc_out.append(self.chunk_dict[story][idx-delays+i])\n",
    "            return (acc_out, self.resp_dict[story]['data'][idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
