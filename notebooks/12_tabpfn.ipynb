{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../experiments')\n",
    "import dvu\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import imodelsx.process_results\n",
    "import neuro.features.qa_questions as qa_questions\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from neuro import analyze_helper, viz\n",
    "fit_encoding = __import__('02_fit_encoding')\n",
    "dvu.set_style()\n",
    "\n",
    "# results_dir = analyze_helper.best_results_dir\n",
    "results_dir = '/home/chansingh/mntv1/deep-fMRI/encoding/feb13_2025_test_tabpfn'\n",
    "rr, cols_varied, mets = analyze_helper.load_clean_results(results_dir)\n",
    "# joblib.dump({'r': rr, 'cols_varied': cols_varied, 'mets': mets}, 'results.pkl')\n",
    "# data = joblib.load('results.pkl')\n",
    "# rr, cols_varied, mets = data['r'], data['cols_varied'], data['mets']\n",
    "metric_sort = 'corrs_tune_pc_weighted_mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.loc[\n",
    "    (r.num_stories == num_stories) & (r.encoding_model == encoding_model), 'corrs_test_mean'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ndel in rr.ndelays.unique():\n",
    "    r = rr[rr.ndelays == ndel]\n",
    "    r = r[r.subject.isin(['S01', 'S02', 'S03'])]\n",
    "\n",
    "    # add AVG over subjects\n",
    "    for num_stories in r.num_stories.unique():\n",
    "        for encoding_model in r.encoding_model.unique():\n",
    "            new_row = deepcopy(r.iloc[0])\n",
    "            new_row['subject'] = 'AVG'\n",
    "            new_row['num_stories'] = num_stories\n",
    "            new_row['encoding_model'] = encoding_model\n",
    "            new_row['corrs_test_mean'] = r.loc[(r.num_stories == num_stories) & (\n",
    "                r.encoding_model == encoding_model), 'corrs_test_mean'].mean()\n",
    "            r = pd.concat([r, new_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "    r['grouping'] = r['num_stories'].astype(\n",
    "        str).str.zfill(2) + ' ' + r['subject'].astype(str)\n",
    "    # r = r[r.grouping.str.contains('AVG')]\n",
    "    sns.barplot(data=r, x='grouping', y='corrs_test_mean',\n",
    "                hue='encoding_model', order=sorted(r['grouping'].unique()),\n",
    "                hue_order=['ridge', 'tabpfn', 'mlp'])\n",
    "\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel('Num training stories & subject')\n",
    "    plt.title('ndelay = ' + str(ndel))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
