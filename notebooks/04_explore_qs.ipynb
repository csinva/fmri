{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import imodelsx.process_results\n",
    "import qa_questions\n",
    "import random\n",
    "import feature_spaces\n",
    "import encoding_utils\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import feature_spaces\n",
    "import dvu\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "dvu.set_style()\n",
    "fit_encoding = __import__('01_fit_encoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    use_test_setup = False\n",
    "    subject = 'UTS03'\n",
    "    feature_space = 'qa_embedder-10'\n",
    "    # qa_embedding_model = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "    qa_embedding_model = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "    trim = 5\n",
    "    num_stories = -1\n",
    "    # num_stories = 2\n",
    "    seed_stories = 1\n",
    "\n",
    "\n",
    "args = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_names_train, story_names_test = fit_encoding.get_story_names(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:getting wordseqs..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:extracting qa_embedder v1 meta-llama/Meta-Llama-3-8B-Instruct embs...\n",
      "INFO:root:Loading cached 0/2: wheretheressmoke\n",
      "INFO:root:Loading cached 1/2: fromboyhoodtofatherhood\n",
      "INFO:root:getting wordseqs..\n",
      "INFO:root:extracting qa_embedder v2 meta-llama/Meta-Llama-3-8B-Instruct embs...\n",
      "INFO:root:Loading cached 0/2: wheretheressmoke\n",
      "INFO:root:Loading cached 1/2: fromboyhoodtofatherhood\n",
      "INFO:root:getting wordseqs..\n",
      "INFO:root:extracting qa_embedder v3_boostexamples meta-llama/Meta-Llama-3-8B-Instruct embs...\n",
      "INFO:root:Loading cached 0/2: wheretheressmoke\n",
      "INFO:root:Loading cached 1/2: fromboyhoodtofatherhood\n"
     ]
    }
   ],
   "source": [
    "# # get downsampled features\n",
    "# features_downsampled_list = []\n",
    "# for qa_questions_version in ['v1']:\n",
    "#     # Features\n",
    "#     features_downsampled_dict = feature_spaces.get_features(\n",
    "#         args.feature_space,\n",
    "#         allstories=story_names_train,\n",
    "#         qa_embedding_model=args.qa_embedding_model,\n",
    "#         qa_questions_version=qa_questions_version,\n",
    "#     )\n",
    "#     # n_time_points x n_features\n",
    "#     features_downsampled = encoding_utils.trim_and_normalize_features(\n",
    "#         features_downsampled_dict, args.trim, normalize=True\n",
    "#     )\n",
    "#     features_downsampled_list.append(deepcopy(features_downsampled))\n",
    "# features_downsampled_list = np.hstack(features_downsampled_list)\n",
    "\n",
    "# # transform so feats is (features x n_time_points)\n",
    "# feats = features_downsampled_list.T\n",
    "\n",
    "# get non-downsampled features\n",
    "features_downsampled_list = []\n",
    "ngrams_list = []\n",
    "for qa_questions_version in ['v1', 'v2', 'v3_boostexamples']:\n",
    "    # Features\n",
    "    allstories, vectors, wordseqs, ngrams_list_dict = feature_spaces.get_features(\n",
    "        args.feature_space,\n",
    "        allstories=story_names_train,\n",
    "        # allstories=story_names_test,\n",
    "        qa_embedding_model=args.qa_embedding_model,\n",
    "        qa_questions_version=qa_questions_version,\n",
    "        downsample=False,\n",
    "    )\n",
    "    # n_time_points x n_features\n",
    "    # features_downsampled = encoding_utils.trim_and_normalize_features(\n",
    "    # features_downsampled_dict, args.trim, normalize=True\n",
    "    # )\n",
    "    features = np.vstack([vectors[k] for k in vectors.keys()])\n",
    "    ngrams_list = sum([ngrams_list_dict[k]\n",
    "                      for k in ngrams_list_dict.keys()], [])\n",
    "    features_downsampled_list.append(deepcopy(features))\n",
    "    # ngrams_list.append(ngrams)\n",
    "    # assert len(ngrams) == features.shape[0]\n",
    "features_downsampled_list = np.hstack(features_downsampled_list)\n",
    "\n",
    "# transform so feats is (features x n_time_points)\n",
    "feats = features_downsampled_list.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/v3_boostexamples_test_metadata.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # export to csv\n",
    "# qa_questions_version = 'v3_boostexamples'\n",
    "# qs = qa_questions.get_questions(qa_questions_version, full=True)\n",
    "\n",
    "# # save compressed\n",
    "# np.savez_compressed(f'../data/{qa_questions_version}_answers_test_numpy',\n",
    "#                     feats.astype(bool).T)\n",
    "# joblib.dump({'columns': qs, 'index': ngrams_list},\n",
    "#             f'../data/{qa_questions_version}_test_metadata.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(300):\n",
    "    plt.plot(feats[i][:1000], '.')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Feature value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = np.corrcoef(feats)\n",
    "# set diagonal to nan\n",
    "# np.fill_diagonal(corrs, np.nan)\n",
    "qs_1 = qa_questions.get_questions('v1')\n",
    "# qs_2 = qa_questions.get_questions('v2')\n",
    "# qs = qs_1 + qs_2\n",
    "qs = qs_1\n",
    "corrs = pd.DataFrame(corrs, columns=qs, index=qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustermap = sns.clustermap(corrs)\n",
    "plt.close()\n",
    "corrs = corrs.iloc[:, clustermap.dendrogram_col.reordered_ind]\n",
    "corrs = corrs.iloc[clustermap.dendrogram_row.reordered_ind, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cbar in bottom right\n",
    "# sns.clustermap(\n",
    "sns.heatmap(\n",
    "    corrs,\n",
    "    # cbar_pos=(0.85, 0.03, 0.03, 0.2),\n",
    "    # figsize=(20, 20),\n",
    "    cbar_kws={'label': 'Correlation Coefficient'},\n",
    "    vmin=-1, vmax=1, cmap='RdBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_triu = corrs.where(np.triu(np.ones(corrs.shape), k=1).astype(bool))\n",
    "plt.hist(corrs_triu.values.flatten(), bins=100)\n",
    "plt.xlabel('Pairwise correlation')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indexes/columns of high correlations\n",
    "high_corr = corrs_triu[corrs_triu > 0.6].stack().index\n",
    "high_corr_idx = [(high_corr[i][0], high_corr[i][1])\n",
    "                 for i in range(len(high_corr))]\n",
    "high_corr_vals = [corrs_triu.loc[high_corr[i][0], high_corr[i][1]]\n",
    "                  for i in range(len(high_corr))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(high_corr_idx)):\n",
    "    print(high_corr_vals[i])\n",
    "    print('\\t', high_corr_idx[i][0])\n",
    "    print('\\t', high_corr_idx[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_fracs = pd.DataFrame({\n",
    "    'yes_frac': feats.mean(axis=1),\n",
    "    'question': qs_1,\n",
    "}).sort_values(by='yes_frac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display full width and non-truncated strings\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', None, 'display.max_colwidth', None):\n",
    "    display(yes_fracs.head(30).round(3))\n",
    "    display(yes_fracs.tail(30).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exact sparsity doesnt work that well bc of lanczos sampling\n",
    "# feat_mins = np.zeros(feats.shape[0])\n",
    "# for i in range(feats.shape[0]):\n",
    "# feat_mins[i] = (feats[i] == np.min(feats[i])).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
