{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import imodelsx.process_results\n",
    "import qa_questions\n",
    "import random\n",
    "import json\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import feature_spaces\n",
    "fit_encoding = __import__('01_fit_encoding')\n",
    "import encoding_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    use_test_setup = False\n",
    "    subject = 'UTS03'\n",
    "    num_stories = -1\n",
    "\n",
    "\n",
    "args = A()\n",
    "story_names_train, story_names_test = fit_encoding.get_story_names(args)\n",
    "wordseqs = feature_spaces.get_story_wordseqs(story_names_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model to boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = analyze_helper.best_results_dir\n",
    "r = imodelsx.process_results.get_results_df(results_dir)\n",
    "for k in ['save_dir', 'save_dir_unique']:\n",
    "    r[k] = r[k].map(lambda x: x if x.startswith('/home')\n",
    "                    else x.replace('/mntv1', '/home/chansingh/mntv1'))\n",
    "\n",
    "args_top = r[\n",
    "    (r.feature_space.str.contains('qa_embedder')) *\n",
    "    (r.pc_components == 100) *\n",
    "    # first boost\n",
    "    # (r.ndelays == 4) *\n",
    "    # (r.qa_questions_version == 'v2')\n",
    "    # second boost\n",
    "    (r.ndelays == 8) *\n",
    "    (r.qa_questions_version == 'v3_boostexamples')\n",
    "\n",
    "    # (r.qa_questions_version == 'v4')\n",
    "    # (r.qa_questions_version == 'v5')\n",
    "].sort_values(\n",
    "    by='corrs_tune_pc_mean',\n",
    "    ascending=False).iloc[0]\n",
    "print(f'{args_top.feature_space=} {args_top.ndelays=}')\n",
    "print(f'{args_top.corrs_test_mean=:.3f} {args_top.corrs_tune_pc_mean=:3f}')\n",
    "\n",
    "model_params_to_save = joblib.load(\n",
    "    join(args_top.save_dir_unique, 'model_params.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boost based on errors or boost based on deviation from llama model\n",
    "- If use_distill=True, Boost based on LLaMA model preds\n",
    "- If use_distill=False, Boost based on voxel errors\n",
    "  - Generate examples for boosted questions based model errors (v4, v5, v6)\n",
    "  - note: v4 wasn't actually boosted because the model we used was basically random\n",
    "  - v5 settings were:\n",
    "    - args_top.feature_space='qa_embedder-10' args_top.ndelays=4\n",
    "    - args_top.corrs_test_mean=0.126 args_top.corrs_tune_pc_mean=0.134110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_distill = True\n",
    "if use_distill:\n",
    "    folder_id_distill = '68936a10a548e2b4ce895d14047ac49e7a56c3217e50365134f78f990036c5f7'\n",
    "    results_dir = '/home/chansingh/mntv1/deep-fMRI/encoding/results_apr7'\n",
    "    args_distill = pd.Series(joblib.load(\n",
    "        join(results_dir, folder_id_distill, 'results.pkl')))\n",
    "    print(args_distill[['feature_space', 'ndelays',\n",
    "                        'corrs_test_mean', 'num_stories', 'subject']])\n",
    "    model_params = joblib.load(\n",
    "        join(results_dir, folder_id_distill, 'model_params.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = defaultdict(list)\n",
    "for story_name in tqdm(story_names_train):\n",
    "    # ngram for 3 trs preceding the current TR\n",
    "    chunks = wordseqs[story_name].chunks()\n",
    "    ngrams_list = feature_spaces._get_ngrams_list_from_chunks(\n",
    "        chunks, num_trs=3)\n",
    "    ngrams_list = np.array(ngrams_list[10:-5])\n",
    "\n",
    "    stim_train_delayed, resp_target = fit_encoding.get_data(\n",
    "        args_top, [story_name])\n",
    "\n",
    "    preds_test = stim_train_delayed @ model_params_to_save['weights'] + \\\n",
    "        model_params_to_save['bias']\n",
    "\n",
    "    # compare to distilled predictions instead of actual response\n",
    "    if use_distill:\n",
    "        stim_train_delayed_distill, _ = fit_encoding.get_data(\n",
    "            args_distill, [story_name])\n",
    "        resp_target = stim_train_delayed_distill @ model_params['weights'] + \\\n",
    "            model_params['bias']\n",
    "\n",
    "    # calculate correlation at each timepoint\n",
    "    corrs_time = np.array([np.corrcoef(resp_target[i, :], preds_test[i, :])[0, 1]\n",
    "                           for i in range(resp_target.shape[0])])\n",
    "    corrs_time[:10] = 100  # don't pick first 10 TRs\n",
    "    # get worst 3 idxs\n",
    "    corrs_worst_idxs = np.argsort(corrs_time)[:3]\n",
    "\n",
    "    for i in range(3):\n",
    "        r['story_name'].append(story_name)\n",
    "        r['corrs'].append(corrs_time[corrs_worst_idxs[i]])\n",
    "        r['ngram'].append(ngrams_list[corrs_worst_idxs[i]])\n",
    "        r['tr'].append(corrs_worst_idxs[i])\n",
    "\n",
    "joblib.dump(r, '../questions/ngrams_boost_v4_llama.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_boost_list = pd.DataFrame(joblib.load(\n",
    "    '../questions/ngrams_boost_v4_llama.pkl'))\n",
    "# remove any string that is a subset of another string\n",
    "ngrams_boost_list_clean = []\n",
    "for ngram in ngrams_boost_list['ngram']:\n",
    "    if not any([ngram in x for x in ngrams_boost_list_clean]) and len(ngram.strip()) > 1:\n",
    "        ngrams_boost_list_clean.append(ngram)\n",
    "print('lens', len(ngrams_boost_list), len(ngrams_boost_list_clean))\n",
    "\n",
    "print('\\n'.join(\n",
    "    ['- ' + x for x in ngrams_boost_list_clean[1::2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_prev = json.load(open('../questions/v3_boostexamples.json'))\n",
    "print('\\n'.join(['- ' + x for x in questions_prev[1::2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random examples for prompting new questions (v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 43  # 42, 43\n",
    "ngrams_examples = []\n",
    "ngram_size = 10\n",
    "num_examples_per_story = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "for story_name in story_names_train:\n",
    "    words_list = wordseqs[story_name].data\n",
    "    ngrams_list = feature_spaces._get_ngrams_list_from_words_list(\n",
    "        words_list, ngram_size=ngram_size)[ngram_size + 2:]\n",
    "    ngrams_examples += np.random.choice(ngrams_list,\n",
    "                                        num_examples_per_story).tolist()\n",
    "print('\\n'.join(['- ' + ngram for ngram in ngrams_examples]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
