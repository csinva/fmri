{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chansingh/fmri/neuro/data/story_names.py:84: UserWarning: Loading all stories, ignoring subject / train_or_test\n",
      "  warnings.warn('Loading all stories, ignoring subject / train_or_test')\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ridge_utils.DataSequence import DataSequence\n",
    "import pandas as pd\n",
    "from os.path import dirname\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from neuro.features import qa_questions, feature_spaces\n",
    "from neuro.data import story_names, response_utils\n",
    "from neuro.features.stim_utils import load_story_wordseqs, load_story_wordseqs_huge\n",
    "import neuro.config\n",
    "import joblib\n",
    "from os.path import join\n",
    "\n",
    "story_names_list = sorted(story_names.get_story_names(all=True))\n",
    "wordseqs = load_story_wordseqs_huge(story_names_list)\n",
    "\n",
    "\n",
    "class A:\n",
    "    subject = 'UTS03'\n",
    "    use_huge = True\n",
    "\n",
    "\n",
    "args = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_largest_absolute_coefs(_pca, n_pcs=50, n_coefs_per_pc=50):\n",
    "#     idxs_large = set()\n",
    "#     for i in range(n_pcs):\n",
    "#         coefs = np.abs(_pca.components_[i])\n",
    "#         idxs = np.argsort(coefs)[::-1][:n_coefs_per_pc]\n",
    "#         idxs_large.update(idxs)\n",
    "#     idxs_large = np.array(list(idxs_large))\n",
    "#     return idxs_large\n",
    "\n",
    "for train_or_test in ['test', 'train']:\n",
    "    for subject in ['UTS03', 'UTS02', 'UTS01']:\n",
    "        story_names_list = story_names.get_story_names(\n",
    "            subject=subject, train_or_test=train_or_test, use_huge=True)\n",
    "        args.subject = subject\n",
    "        for story_name in tqdm(story_names_list):\n",
    "            out_file = f'{subject.lower()}/{train_or_test}/{story_name}.pkl'\n",
    "            if os.path.exists(out_file):\n",
    "                print('skipping', out_file)\n",
    "                continue\n",
    "\n",
    "            ngrams_list = feature_spaces.get_ngrams_list_main(\n",
    "                wordseqs[story_name], num_trs_context=1)\n",
    "            ngrams_list = ngrams_list[10:-5]  # apply trim\n",
    "            args.pc_components = 10000\n",
    "            _, resp_test, _pca, _scaler_train, _scaler_test = response_utils.get_resps_full(\n",
    "                args, args.subject, [story_name], [story_name])\n",
    "\n",
    "            # args.pc_components = -1\n",
    "            # _, resp_test_full = response_utils.get_resps_full(\n",
    "            # args, args.subject, [story_name], [story_name])\n",
    "\n",
    "            # idxs_large = _get_largest_absolute_coefs(_pca)\n",
    "            # resp_selected = np.hstack((resp_test, resp_test_full[:, idxs_large]))\n",
    "            resp_selected = resp_test\n",
    "\n",
    "            # print(story_name, 'shapes', resp_test.shape,\n",
    "            #   resp_test_full.shape, resp_selected.shape)\n",
    "\n",
    "            # temporal alignment\n",
    "            # offset = 2\n",
    "            # resp_selected = resp_selected[offset:, :]\n",
    "            # ngrams_list = ngrams_list[:-offset]\n",
    "\n",
    "            # apply convolution smoothing filter over axis 0 of resp\n",
    "            # plt.plot(resp_selected[:, 0])\n",
    "            # conv_filter = np.array([1/3, 1, 1/3])/(5/3)\n",
    "            # resp_selected = np.apply_along_axis(\n",
    "            # lambda m: np.convolve(m, conv_filter, mode='same'), axis=0, arr=resp_selected)\n",
    "            # plt.plot(resp_selected[:, 0])\n",
    "\n",
    "            # trim by 1\n",
    "            # resp_selected = resp_selected[1:-1, :]\n",
    "            # ngrams_list = ngrams_list[1:-1]\n",
    "\n",
    "            assert resp_selected.shape[0] == len(\n",
    "                ngrams_list), f'{resp_selected.shape[0]} != {len(ngrams_list)}'\n",
    "\n",
    "            column_names = ['PC' + str(i) for i in range(resp_test.shape[1])]\n",
    "            # + ['Vox' + str(i) for i in idxs_large]\n",
    "            df = pd.DataFrame(\n",
    "                resp_selected, columns=column_names, index=ngrams_list)\n",
    "\n",
    "            # print('saving shape', df.shape)\n",
    "            os.makedirs(dirname(out_file), exist_ok=True)\n",
    "            df.to_pickle(out_file)\n",
    "            # joblib.dump(resp_selected, f'{subject.lower()}/{story_name}_resp.pkl')\n",
    "            # joblib.dump(\n",
    "            # ngrams_list, f'{subject.lower()}/{story_name}_row_names_ngrams.pkl')\n",
    "            # joblib.dump(\n",
    "            # column_names, f'{subject.lower()}/{story_name}_column_names_fmri.pkl')\n",
    "\n",
    "            # add answer labels\n",
    "            out_file_labels = f'labels/{train_or_test}/{story_name}_labels.pkl'\n",
    "            print('\\tsaving', out_file_labels)\n",
    "            questions = [\n",
    "                'Does the input contain a number?',\n",
    "                'Is time mentioned in the input?',\n",
    "                'Does the sentence include dialogue?',\n",
    "                'Does the input mention or describe high emotional intensity?',\n",
    "                'Does the sentence mention a specific location?',\n",
    "                'Is the sentence emotionally positive?',\n",
    "                'Does the sentence describe a relationship between people?',\n",
    "            ]\n",
    "            question_answers = neuro.features.feature_spaces.get_gpt4_qa_embs_cached(\n",
    "                story_name=story_name, questions=questions,\n",
    "                return_ngrams=False)\n",
    "            question_answers = neuro.features.feature_spaces.downsample_word_vectors(\n",
    "                [story_name], {story_name: question_answers}, wordseqs)[story_name][10:-5]\n",
    "            df_answers = pd.DataFrame(question_answers, columns=questions)\n",
    "            os.makedirs(dirname(out_file_labels), exist_ok=True)\n",
    "            df_answers = df_answers.astype(bool).to_pickle(out_file_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example load with offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes (267, 800) (267, 7)\n"
     ]
    }
   ],
   "source": [
    "story_name = 'onapproachtopluto'\n",
    "df = joblib.load(f'uts03/test/{story_name}.pkl')\n",
    "dfs = []\n",
    "for offset in [1, 2, 3, 4]:\n",
    "    df_offset = df.shift(-offset)\n",
    "    df_offset.columns = [col + f'_{offset}' for col in df.columns]\n",
    "    dfs.append(df_offset)\n",
    "df = pd.concat(dfs, axis=1)  # .dropna()  # would want to dropna here\n",
    "\n",
    "# load labels\n",
    "labs = joblib.load(f'labels/test/{story_name}_labels.pkl')\n",
    "\n",
    "# drop rows with nans\n",
    "idxs_na = df.isna().sum(axis=1).values > 0\n",
    "df = df[~idxs_na]\n",
    "labs = labs[~idxs_na]\n",
    "\n",
    "print('shapes', df.shape, labs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC0_1</th>\n",
       "      <th>PC1_1</th>\n",
       "      <th>PC2_1</th>\n",
       "      <th>PC3_1</th>\n",
       "      <th>PC4_1</th>\n",
       "      <th>PC5_1</th>\n",
       "      <th>PC6_1</th>\n",
       "      <th>PC7_1</th>\n",
       "      <th>PC8_1</th>\n",
       "      <th>PC9_1</th>\n",
       "      <th>...</th>\n",
       "      <th>PC190_4</th>\n",
       "      <th>PC191_4</th>\n",
       "      <th>PC192_4</th>\n",
       "      <th>PC193_4</th>\n",
       "      <th>PC194_4</th>\n",
       "      <th>PC195_4</th>\n",
       "      <th>PC196_4</th>\n",
       "      <th>PC197_4</th>\n",
       "      <th>PC198_4</th>\n",
       "      <th>PC199_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>off i had been working super</th>\n",
       "      <td>4.420157</td>\n",
       "      <td>-1.524455</td>\n",
       "      <td>1.468934</td>\n",
       "      <td>-0.765363</td>\n",
       "      <td>-0.406178</td>\n",
       "      <td>-0.432300</td>\n",
       "      <td>0.957856</td>\n",
       "      <td>-2.163097</td>\n",
       "      <td>2.114482</td>\n",
       "      <td>1.079989</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.696190</td>\n",
       "      <td>-1.434016</td>\n",
       "      <td>1.072742</td>\n",
       "      <td>-0.515596</td>\n",
       "      <td>0.424500</td>\n",
       "      <td>1.220508</td>\n",
       "      <td>-1.056415</td>\n",
       "      <td>-0.183963</td>\n",
       "      <td>-1.264088</td>\n",
       "      <td>0.105623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard for a long time</th>\n",
       "      <td>3.817557</td>\n",
       "      <td>-1.606965</td>\n",
       "      <td>0.050622</td>\n",
       "      <td>0.111497</td>\n",
       "      <td>-1.102836</td>\n",
       "      <td>-0.705528</td>\n",
       "      <td>0.780802</td>\n",
       "      <td>-1.671833</td>\n",
       "      <td>1.405054</td>\n",
       "      <td>1.486964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.738747</td>\n",
       "      <td>-2.651979</td>\n",
       "      <td>-0.564281</td>\n",
       "      <td>-0.483533</td>\n",
       "      <td>0.305728</td>\n",
       "      <td>0.059886</td>\n",
       "      <td>-0.048379</td>\n",
       "      <td>-0.604623</td>\n",
       "      <td>0.192919</td>\n",
       "      <td>-0.272143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i was working on nasa's new horizons</th>\n",
       "      <td>3.351413</td>\n",
       "      <td>-1.143191</td>\n",
       "      <td>-0.858022</td>\n",
       "      <td>-0.184832</td>\n",
       "      <td>-0.846820</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>0.173373</td>\n",
       "      <td>-1.380383</td>\n",
       "      <td>1.473713</td>\n",
       "      <td>2.004168</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.296728</td>\n",
       "      <td>-2.437131</td>\n",
       "      <td>0.008056</td>\n",
       "      <td>-0.508091</td>\n",
       "      <td>0.628004</td>\n",
       "      <td>1.052285</td>\n",
       "      <td>0.014094</td>\n",
       "      <td>-0.289104</td>\n",
       "      <td>0.099962</td>\n",
       "      <td>-0.313488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mission to pluto and</th>\n",
       "      <td>2.709506</td>\n",
       "      <td>-1.047402</td>\n",
       "      <td>-0.338457</td>\n",
       "      <td>0.106503</td>\n",
       "      <td>-0.631205</td>\n",
       "      <td>-1.043409</td>\n",
       "      <td>0.043512</td>\n",
       "      <td>-1.900928</td>\n",
       "      <td>0.611665</td>\n",
       "      <td>2.571490</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.680306</td>\n",
       "      <td>-0.401569</td>\n",
       "      <td>0.658709</td>\n",
       "      <td>-0.976654</td>\n",
       "      <td>-0.109976</td>\n",
       "      <td>-1.147805</td>\n",
       "      <td>-0.246245</td>\n",
       "      <td>0.253397</td>\n",
       "      <td>0.269854</td>\n",
       "      <td>0.381762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>there were always something to do</th>\n",
       "      <td>2.025983</td>\n",
       "      <td>-1.439025</td>\n",
       "      <td>0.155621</td>\n",
       "      <td>-0.476584</td>\n",
       "      <td>0.552912</td>\n",
       "      <td>0.067754</td>\n",
       "      <td>0.906028</td>\n",
       "      <td>-2.012768</td>\n",
       "      <td>0.361617</td>\n",
       "      <td>2.202108</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.317264</td>\n",
       "      <td>-0.937748</td>\n",
       "      <td>-0.428753</td>\n",
       "      <td>-0.941643</td>\n",
       "      <td>0.562629</td>\n",
       "      <td>0.704891</td>\n",
       "      <td>-0.583612</td>\n",
       "      <td>-1.038979</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>-0.571436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         PC0_1     PC1_1     PC2_1     PC3_1  \\\n",
       "off i had been working super          4.420157 -1.524455  1.468934 -0.765363   \n",
       "hard for a long time                  3.817557 -1.606965  0.050622  0.111497   \n",
       "i was working on nasa's new horizons  3.351413 -1.143191 -0.858022 -0.184832   \n",
       "mission to pluto and                  2.709506 -1.047402 -0.338457  0.106503   \n",
       "there were always something to do     2.025983 -1.439025  0.155621 -0.476584   \n",
       "\n",
       "                                         PC4_1     PC5_1     PC6_1     PC7_1  \\\n",
       "off i had been working super         -0.406178 -0.432300  0.957856 -2.163097   \n",
       "hard for a long time                 -1.102836 -0.705528  0.780802 -1.671833   \n",
       "i was working on nasa's new horizons -0.846820 -1.270403  0.173373 -1.380383   \n",
       "mission to pluto and                 -0.631205 -1.043409  0.043512 -1.900928   \n",
       "there were always something to do     0.552912  0.067754  0.906028 -2.012768   \n",
       "\n",
       "                                         PC8_1     PC9_1  ...   PC190_4  \\\n",
       "off i had been working super          2.114482  1.079989  ... -0.696190   \n",
       "hard for a long time                  1.405054  1.486964  ... -0.738747   \n",
       "i was working on nasa's new horizons  1.473713  2.004168  ... -0.296728   \n",
       "mission to pluto and                  0.611665  2.571490  ... -0.680306   \n",
       "there were always something to do     0.361617  2.202108  ... -0.317264   \n",
       "\n",
       "                                       PC191_4   PC192_4   PC193_4   PC194_4  \\\n",
       "off i had been working super         -1.434016  1.072742 -0.515596  0.424500   \n",
       "hard for a long time                 -2.651979 -0.564281 -0.483533  0.305728   \n",
       "i was working on nasa's new horizons -2.437131  0.008056 -0.508091  0.628004   \n",
       "mission to pluto and                 -0.401569  0.658709 -0.976654 -0.109976   \n",
       "there were always something to do    -0.937748 -0.428753 -0.941643  0.562629   \n",
       "\n",
       "                                       PC195_4   PC196_4   PC197_4   PC198_4  \\\n",
       "off i had been working super          1.220508 -1.056415 -0.183963 -1.264088   \n",
       "hard for a long time                  0.059886 -0.048379 -0.604623  0.192919   \n",
       "i was working on nasa's new horizons  1.052285  0.014094 -0.289104  0.099962   \n",
       "mission to pluto and                 -1.147805 -0.246245  0.253397  0.269854   \n",
       "there were always something to do     0.704891 -0.583612 -1.038979  0.000755   \n",
       "\n",
       "                                       PC199_4  \n",
       "off i had been working super          0.105623  \n",
       "hard for a long time                 -0.272143  \n",
       "i was working on nasa's new horizons -0.313488  \n",
       "mission to pluto and                  0.381762  \n",
       "there were always something to do    -0.571436  \n",
       "\n",
       "[5 rows x 800 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Does the input contain a number?</th>\n",
       "      <th>Is time mentioned in the input?</th>\n",
       "      <th>Does the sentence include dialogue?</th>\n",
       "      <th>Does the input mention or describe high emotional intensity?</th>\n",
       "      <th>Does the sentence mention a specific location?</th>\n",
       "      <th>Is the sentence emotionally positive?</th>\n",
       "      <th>Does the sentence describe a relationship between people?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Does the input contain a number?  Is time mentioned in the input?  \\\n",
       "0                              True                             True   \n",
       "1                              True                             True   \n",
       "2                              True                             True   \n",
       "3                              True                             True   \n",
       "4                              True                             True   \n",
       "\n",
       "   Does the sentence include dialogue?  \\\n",
       "0                                False   \n",
       "1                                False   \n",
       "2                                False   \n",
       "3                                False   \n",
       "4                                False   \n",
       "\n",
       "   Does the input mention or describe high emotional intensity?  \\\n",
       "0                                              False              \n",
       "1                                              False              \n",
       "2                                              False              \n",
       "3                                              False              \n",
       "4                                              False              \n",
       "\n",
       "   Does the sentence mention a specific location?  \\\n",
       "0                                            True   \n",
       "1                                            True   \n",
       "2                                            True   \n",
       "3                                            True   \n",
       "4                                            True   \n",
       "\n",
       "   Is the sentence emotionally positive?  \\\n",
       "0                                   True   \n",
       "1                                   True   \n",
       "2                                   True   \n",
       "3                                   True   \n",
       "4                                   True   \n",
       "\n",
       "   Does the sentence describe a relationship between people?  \n",
       "0                                              False          \n",
       "1                                              False          \n",
       "2                                              False          \n",
       "3                                              False          \n",
       "4                                              False          "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
