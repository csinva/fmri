{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from ridge_utils.DataSequence import DataSequence\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cortex\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from sasc.config import FMRI_DIR, STORIES_DIR\n",
    "from neuro.features import qa_questions, feature_spaces\n",
    "from neuro.config import brain_drive_resps_dir\n",
    "import neuro.config\n",
    "from neuro.features.qa_questions import get_questions, get_merged_questions_v3_boostexamples\n",
    "from neuro.data import story_names, response_utils\n",
    "from neuro.features.stim_utils import load_story_wordseqs, load_story_wordseqs_huge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_names_list = sorted(story_names.get_story_names(\n",
    "    use_huge=True, train_or_test='test'))\n",
    "wordseqs = load_story_wordseqs_huge(story_names_list)\n",
    "\n",
    "\n",
    "class A:\n",
    "    subject = 'UTS03'\n",
    "    use_huge = True\n",
    "    pc_components = 10000\n",
    "\n",
    "\n",
    "args = A()\n",
    "\n",
    "\n",
    "def _get_largest_absolute_coefs(_pca, n_pcs=100, n_coefs_per_pc=100):\n",
    "    idxs_large = set()\n",
    "    for i in range(n_pcs):\n",
    "        coefs = np.abs(_pca.components_[i])\n",
    "        idxs = np.argsort(coefs)[::-1][:]\n",
    "        idxs_large.update(idxs)\n",
    "    idxs_large = np.array(list(idxs_large))\n",
    "    return idxs_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_names_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in ['UTS03', 'UTS02', 'UTS01']:\n",
    "    args.subject = subject\n",
    "    for story_name in ['fromboyhoodtofatherhood', 'onapproachtopluto', 'wheretheressmoke']:\n",
    "        ngrams_list = feature_spaces.get_ngrams_list_main(\n",
    "            wordseqs[story_name], num_trs_context=1)\n",
    "        ngrams_list = ngrams_list[10:-5]  # apply trim\n",
    "        args.pc_components = 10000\n",
    "        _, resp_test, _pca, _scaler_train, _scaler_test = response_utils.get_resps_full(\n",
    "            args, args.subject, [story_name], [story_name])\n",
    "\n",
    "        args.pc_components = -1\n",
    "        _, resp_test_full = response_utils.get_resps_full(\n",
    "            args, args.subject, [story_name], [story_name])\n",
    "\n",
    "        idxs_large = _get_largest_absolute_coefs(_pca)\n",
    "\n",
    "        resp_test_full[:, idxs_large].shape\n",
    "        resp_selected = np.hstack((resp_test, resp_test_full[:, idxs_large]))\n",
    "\n",
    "        # temporal alignment\n",
    "        offset = 2\n",
    "        resp_selected = resp_selected[offset:, :]\n",
    "        ngrams_list = ngrams_list[:-offset]\n",
    "\n",
    "        # apply convolution smoothing filter over axis 0 of resp\n",
    "        # plt.plot(resp_selected[:, 0])\n",
    "        conv_filter = np.array([1/3, 1, 1/3])/(5/3)\n",
    "        resp_selected = np.apply_along_axis(\n",
    "            lambda m: np.convolve(m, conv_filter, mode='same'), axis=0, arr=resp_selected)\n",
    "        # plt.plot(resp_selected[:, 0])\n",
    "\n",
    "        # trim by 1\n",
    "        resp_selected = resp_selected[1:-1, :]\n",
    "        ngrams_list = ngrams_list[1:-1]\n",
    "\n",
    "        assert resp_selected.shape[0] == len(\n",
    "            ngrams_list), f'{resp_selected.shape[0]} != {len(ngrams_list)}'\n",
    "\n",
    "        column_names = ['PC' + str(i) for i in range(resp_test.shape[1])] + \\\n",
    "            ['Vox' + str(i) for i in idxs_large]\n",
    "        df = pd.DataFrame(\n",
    "            resp_selected, columns=column_names, index=ngrams_list)\n",
    "        df.to_pickle(f'{subject.lower()}/{story_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
