{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chansingh/fmri/neuro/data/story_names.py:84: UserWarning: Loading all stories, ignoring subject / train_or_test\n",
      "  warnings.warn('Loading all stories, ignoring subject / train_or_test')\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ridge_utils.DataSequence import DataSequence\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import dirname\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from neuro.features import qa_questions, feature_spaces\n",
    "from neuro.data import story_names, response_utils\n",
    "from neuro.features.stim_utils import load_story_wordseqs, load_story_wordseqs_huge\n",
    "import neuro.config\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "from os.path import join\n",
    "\n",
    "story_names_list = sorted(story_names.get_story_names(all=True))\n",
    "wordseqs = load_story_wordseqs_huge(story_names_list)\n",
    "\n",
    "\n",
    "class A:\n",
    "    subject = 'UTS03'\n",
    "    use_huge = True\n",
    "\n",
    "\n",
    "args = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_labels(story_name, train_or_test):\n",
    "    out_file_labels = f'labels/{train_or_test}/{story_name}_labels.pkl'\n",
    "    print('\\tsaving', out_file_labels)\n",
    "    questions = [x.replace('.pkl', '') for x in os.listdir(\n",
    "        '/home/chansingh/mntv1/deep-fMRI/qa/cache_gpt') if '?' in x]\n",
    "    question_answers = neuro.features.feature_spaces.get_gpt4_qa_embs_cached(\n",
    "        story_name=story_name, questions=questions,\n",
    "        return_ngrams=False)\n",
    "    question_answers = neuro.features.feature_spaces.downsample_word_vectors(\n",
    "        [story_name], {story_name: question_answers}, wordseqs)[story_name][10:-5]\n",
    "    df_answers = pd.DataFrame(question_answers, columns=questions)\n",
    "    os.makedirs(dirname(out_file_labels), exist_ok=True)\n",
    "\n",
    "    # binarize each column by checking if z-score greater than 1\n",
    "    df_answers_binary = df_answers.copy()\n",
    "    for col in df_answers.columns:\n",
    "        df_answers_binary[col] = (\n",
    "            df_answers[col] - df_answers[col].mean()) > df_answers[col].std()\n",
    "\n",
    "    df_answers_binary.astype(bool).to_pickle(out_file_labels)\n",
    "\n",
    "\n",
    "def _save_fmri_features(story_name, out_file):\n",
    "    ngrams_list = feature_spaces.get_ngrams_list_main(\n",
    "        wordseqs[story_name], num_trs_context=1)\n",
    "    ngrams_list = ngrams_list[10:-5]  # apply trim\n",
    "    args.pc_components = 10000\n",
    "    _, resp_test, _pca, _scaler_train, _scaler_test = response_utils.get_resps_full(\n",
    "        args, args.subject, [story_name], [story_name])\n",
    "\n",
    "    # args.pc_components = -1\n",
    "    # _, resp_test_full = response_utils.get_resps_full(\n",
    "    # args, args.subject, [story_name], [story_name])\n",
    "\n",
    "    # idxs_large = _get_largest_absolute_coefs(_pca)\n",
    "    # resp_selected = np.hstack((resp_test, resp_test_full[:, idxs_large]))\n",
    "    resp_selected = resp_test\n",
    "\n",
    "    # print(story_name, 'shapes', resp_test.shape,\n",
    "    #   resp_test_full.shape, resp_selected.shape)\n",
    "\n",
    "    # temporal alignment\n",
    "    # offset = 2\n",
    "    # resp_selected = resp_selected[offset:, :]\n",
    "    # ngrams_list = ngrams_list[:-offset]\n",
    "\n",
    "    # apply convolution smoothing filter over axis 0 of resp\n",
    "    # plt.plot(resp_selected[:, 0])\n",
    "    # conv_filter = np.array([1/3, 1, 1/3])/(5/3)\n",
    "    # resp_selected = np.apply_along_axis(\n",
    "    # lambda m: np.convolve(m, conv_filter, mode='same'), axis=0, arr=resp_selected)\n",
    "    # plt.plot(resp_selected[:, 0])\n",
    "\n",
    "    # trim by 1\n",
    "    # resp_selected = resp_selected[1:-1, :]\n",
    "    # ngrams_list = ngrams_list[1:-1]\n",
    "\n",
    "    assert resp_selected.shape[0] == len(\n",
    "        ngrams_list), f'{resp_selected.shape[0]} != {len(ngrams_list)}'\n",
    "\n",
    "    column_names = ['PC' + str(i) for i in range(resp_test.shape[1])]\n",
    "    # + ['Vox' + str(i) for i in idxs_large]\n",
    "    df = pd.DataFrame(\n",
    "        resp_selected, columns=column_names, index=ngrams_list)\n",
    "\n",
    "    # print('saving shape', df.shape)\n",
    "    os.makedirs(dirname(out_file), exist_ok=True)\n",
    "    df.to_pickle(out_file)\n",
    "    # joblib.dump(resp_selected, f'{subject.lower()}/{story_name}_resp.pkl')\n",
    "    # joblib.dump(\n",
    "    # ngrams_list, f'{subject.lower()}/{story_name}_row_names_ngrams.pkl')\n",
    "    # joblib.dump(\n",
    "    # column_names, f'{subject.lower()}/{story_name}_column_names_fmri.pkl')\n",
    "\n",
    "\n",
    "# def _get_largest_absolute_coefs(_pca, n_pcs=50, n_coefs_per_pc=50):\n",
    "#     idxs_large = set()\n",
    "#     for i in range(n_pcs):\n",
    "#         coefs = np.abs(_pca.components_[i])\n",
    "#         idxs = np.argsort(coefs)[::-1][:n_coefs_per_pc]\n",
    "#         idxs_large.update(idxs)\n",
    "#     idxs_large = np.array(list(idxs_large))\n",
    "#     return idxs_large\n",
    "\n",
    "for train_or_test in ['test', 'train']:\n",
    "    for subject in ['UTS03', 'UTS02', 'UTS01']:\n",
    "        story_names_list = story_names.get_story_names(\n",
    "            subject=subject, train_or_test=train_or_test, use_huge=True)\n",
    "        args.subject = subject\n",
    "        for story_name in tqdm(story_names_list):\n",
    "\n",
    "            # out_file = f'{subject.lower()}/{train_or_test}/{story_name}.pkl'\n",
    "            # if os.path.exists(out_file):\n",
    "            #     print('skipping', out_file)\n",
    "            #     continue\n",
    "            # _save_fmri_features(story_name, out_file)\n",
    "\n",
    "            # add answer labels\n",
    "            _save_labels(story_name, train_or_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chansingh/.env/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator PCA from version 1.4.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for subject in ['UTS03', 'UTS02', 'UTS01']:\n",
    "    pca = response_utils.load_pca(subject, 10000)\n",
    "    joblib.dump(pca.components_, f'{subject.lower()}/pca_components.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
