{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ridge_utils.DataSequence import DataSequence\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import dirname\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from neuro.features import qa_questions, feature_spaces\n",
    "from neuro.data import story_names, response_utils\n",
    "from neuro.features.stim_utils import load_story_wordseqs, load_story_wordseqs_huge\n",
    "import neuro.config\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fmri_and_labs(story_name='onapproachtopluto', train_or_test='test', subject='uts03'):\n",
    "    '''\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        The fMRI features, with columns corresponding to the principal components\n",
    "        of the fMRI data.\n",
    "    labs : pd.DataFrame\n",
    "        Binary labeled annotations for each of the texts\n",
    "    texts: \n",
    "        The texts corresponding to the rows of df\n",
    "    '''\n",
    "    df = joblib.load(f'{subject}/{train_or_test}/{story_name}.pkl')\n",
    "    dfs = []\n",
    "    for offset in [1, 2, 3, 4]:\n",
    "        df_offset = df.shift(-offset)\n",
    "        df_offset.columns = [col + f'_{offset}' for col in df.columns]\n",
    "        dfs.append(df_offset)\n",
    "    df = pd.concat(dfs, axis=1)  # .dropna()  # would want to dropna here\n",
    "\n",
    "    # load labels\n",
    "    labs = joblib.load(f'labels/{train_or_test}/{story_name}_labels.pkl')\n",
    "\n",
    "    # drop rows with nans\n",
    "    idxs_na = df.isna().sum(axis=1).values > 0\n",
    "    df = df[~idxs_na]\n",
    "    labs = labs[~idxs_na]\n",
    "    texts = pd.Series(df.index)\n",
    "    return df, labs, texts\n",
    "\n",
    "\n",
    "def concatenate_running_texts(texts, frac=1/2):\n",
    "    '''When decoding, you might want to concatenate \n",
    "    the text of the current and surrounding texts\n",
    "    to deal with the temporal imprecision of the fMRI signal.\n",
    "    '''\n",
    "    texts_before = (\n",
    "        texts.shift(1)\n",
    "        .str.split().apply(  # only keep second half of words\n",
    "            lambda l: ' '.join(l[int(-len(l) * frac):]) if l else '')\n",
    "    )\n",
    "\n",
    "    texts_after = (\n",
    "        texts.shift(-1)\n",
    "        .str.split().apply(  # only keep first half of words\n",
    "            lambda l: ' '.join(l[:int(len(l) * frac)]) if l else '')\n",
    "    )\n",
    "\n",
    "    return texts_before + ' ' + texts + ' ' + texts_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]),\n",
       " array([ 2,  1,  6,  7, 14, 23, 53, 40, 50, 27, 22, 15,  6,  1]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig, labs, texts = get_fmri_and_labs()\n",
    "texts = concatenate_running_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single story\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "df, labs, texts = get_fmri_and_labs()\n",
    "\n",
    "# load all the data for a single subject\n",
    "for subject in ['uts01', 'uts02', 'uts03']:\n",
    "    data = defaultdict(list)\n",
    "    for train_or_test in ['test', 'train']:\n",
    "        story_names_list = os.listdir(f'{subject}/{train_or_test}')\n",
    "        for story_name in story_names_list:\n",
    "            df, labs, texts = get_fmri_and_labs(\n",
    "                story_name.replace('.pkl', ''), train_or_test, subject)\n",
    "            data['df_' + train_or_test].append(df)\n",
    "            data['labs_' + train_or_test].append(labs)\n",
    "            data['texts_' + train_or_test].append(texts)\n",
    "    for k in data:\n",
    "        data[k] = pd.concat(data[k], axis=0)\n",
    "\n",
    "    # example fit linear decoder\n",
    "    r = defaultdict(list)\n",
    "    for label_num in tqdm(range(data['labs_train'].shape[1])):\n",
    "        X_train, y_train = data['df_train'].values, data['labs_train'].values[:, label_num]\n",
    "        X_test, y_test = data['df_test'].values, data['labs_test'].values[:, label_num]\n",
    "\n",
    "        # balance the binary class imbalance\n",
    "        try:\n",
    "            rus = RandomUnderSampler(random_state=42)\n",
    "            X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "            X_test, y_test = rus.fit_resample(X_test, y_test)\n",
    "\n",
    "            if len(y_test) < 30:\n",
    "                print('too few positive labels', label_num)\n",
    "                continue\n",
    "\n",
    "            print('label', label_num,\n",
    "                  data['labs_train'].columns[label_num], X_train.shape, X_test.shape)\n",
    "            m = LogisticRegressionCV(random_state=42)\n",
    "            m.fit(X_train, y_train)\n",
    "            print(\n",
    "                f\"\"\"\\ttest acc {m.score(X_test, y_test):.3f}\\n\\tnaive acc {1 -y_test.mean():.3f}\"\"\")\n",
    "            r['label'].append(data['labs_train'].columns[label_num])\n",
    "            r['test_acc'].append(m.score(X_test, y_test))\n",
    "            r['num_test'].append(len(y_test))\n",
    "            r['coef'].append(m.coef_.copy())\n",
    "        except:\n",
    "            print('error for', label_num)\n",
    "            continue\n",
    "    r_df = pd.DataFrame(r)\n",
    "    # .sort_values(\n",
    "    # 'test_acc', ascending=False).reset_index()\n",
    "    r_df.to_pickle(f'r_df_{subject}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 13))\n",
    "colors = {\n",
    "    'uts01': 'C0',\n",
    "    'uts02': 'C1',\n",
    "    'uts03': 'C2',\n",
    "    'mean': 'black'\n",
    "}\n",
    "for subject in ['mean', 'uts01', 'uts02', 'uts03']:\n",
    "    if subject == 'mean':\n",
    "        dfs = [pd.read_pickle(f'r_df_{subject}.pkl')\n",
    "               for subject in ['uts01', 'uts02', 'uts03']]\n",
    "        r_df = pd.concat(dfs, axis=0).groupby('label').mean().reset_index()\n",
    "        idx_sort = r_df['test_acc'].sort_values(ascending=False).index\n",
    "    else:\n",
    "        r_df = pd.read_pickle(f'r_df_{subject}.pkl')\n",
    "\n",
    "    r_df = r_df.loc[idx_sort]\n",
    "\n",
    "    # plot accuracy with binomial error bars\n",
    "    if subject == 'mean':\n",
    "        plt.errorbar(\n",
    "            r_df['test_acc'],\n",
    "            range(len(r_df)),\n",
    "            color='black',\n",
    "            fmt='o',\n",
    "            zorder=1000,\n",
    "            label=subject.capitalize(),\n",
    "        )\n",
    "        plt.axvline(r_df['test_acc'].mean(), color=colors[subject])\n",
    "    else:\n",
    "        plt.errorbar(\n",
    "            r_df['test_acc'],\n",
    "            range(len(r_df)),\n",
    "            xerr=(r_df['test_acc']*(1-r_df['test_acc']) /\n",
    "                  np.sqrt(r_df['num_test'])),\n",
    "            alpha=0.5,\n",
    "            label=subject.upper(),\n",
    "            fmt='o')\n",
    "        plt.axvline(r_df['test_acc'].mean(),\n",
    "                    linestyle='--', color=colors[subject])\n",
    "\n",
    "    print('mean acc', r_df['test_acc'].mean())\n",
    "\n",
    "# add horizontal bars\n",
    "plt.yticks(range(len(r_df)), r_df['label'])\n",
    "plt.xlabel(\n",
    "    'Test accuracy when decoding with linear model\\n(after balancing labels with undersampling)', fontsize='large')\n",
    "plt.grid()\n",
    "\n",
    "# annotate with baseline and text label\n",
    "plt.axvline(0.5, color='darkgray', linestyle='--')\n",
    "plt.text(0.5, 0, 'Chance', color='darkgray', fontsize=12, ha='right')\n",
    "plt.legend(fontsize='large')\n",
    "plt.tight_layout()\n",
    "plt.savefig('linear_decoding.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize learned coefs on cortex map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'uts03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_comps = joblib.load(f'{subject}/pca_components.pkl')\n",
    "# vertically stack pca_comps 4 times\n",
    "pca_comps = np.vstack([pca_comps]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quickshow(X: np.ndarray, subject=\"UTS03\", fname_save=None, title=None):\n",
    "    import cortex\n",
    "\n",
    "    \"\"\"\n",
    "    Actual visualizations\n",
    "    Note: for this to work, need to point the cortex config filestore to the `ds003020/derivative/pycortex-db` directory.\n",
    "    This might look something like `/home/chansingh/mntv1/deep-fMRI/data/ds003020/derivative/pycortex-db/UTS03/anatomicals/`\n",
    "    \"\"\"\n",
    "    vol = cortex.Volume(X, subject, xfmname=f\"{subject}_auto\")\n",
    "    # , with_curvature=True, with_sulci=True)\n",
    "    vabs = max(abs(vol.data.min()), abs(vol.data.max()))\n",
    "    vol.vmin = -vabs\n",
    "    vol.vmax = vabs\n",
    "    # fig = plt.figure()\n",
    "    # , vmin=-vabs, vmax=vabs)\n",
    "    cortex.quickshow(vol, with_rois=True, cmap=\"PuBu\")\n",
    "    # fig = plt.gcf()\n",
    "    # add title\n",
    "    # fig.axes[0].set_title(title, fontsize='xx-small')\n",
    "    if fname_save is not None:\n",
    "        plt.savefig(fname_save)\n",
    "        # plt.savefig(fname_save.replace(\".pdf\", \".png\"))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(r_df)):\n",
    "    pc_coef = r_df.iloc[i]['coef']\n",
    "    voxel_coefs = (pc_coef @ pca_comps).squeeze()\n",
    "    quickshow(voxel_coefs, fname_save=join(\n",
    "        'flatmaps_decoding', f'{r_df.iloc[i][\"label\"]}.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
