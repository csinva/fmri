{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from os.path import expanduser\n",
    "import sys\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pprint import pprint\n",
    "import imodelsx.util\n",
    "from os.path import dirname\n",
    "import pickle as pkl\n",
    "import json\n",
    "from copy import deepcopy\n",
    "from numpy.linalg import norm\n",
    "from math import ceil\n",
    "from imodelsx.qaemb.qaemb import QAEmb, get_sample_questions_and_examples\n",
    "from neuro.treebank.config import STORIES_POPULAR, STORIES_UNPOPULAR, ECOG_DIR\n",
    "import mne\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "extract = __import__('00_extract')\n",
    "from nilearn.plotting import plot_markers\n",
    "from mne_bids import BIDSPath\n",
    "\n",
    "from himalaya.backend import set_backend, get_backend\n",
    "from himalaya.ridge import RidgeCV\n",
    "from himalaya.scoring import correlation_score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from neuro.ecog.config import ECOG_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_root = join(ECOG_DIR, 'podcasts_data', 'ds005574/')\n",
    "\n",
    "# Download the transcript, if required\n",
    "# transcript_path = f\"{bids_root}stimuli/gpt2-xl/transcript.tsv\"\n",
    "transcript_path = join(bids_root, \"stimuli/syntactic/transcript.tsv\")\n",
    "\n",
    "# Load transcript\n",
    "df_contextual = pd.read_csv(transcript_path, sep=\"\\t\", index_col=0)\n",
    "df_contextual.head()\n",
    "\n",
    "df_word = df_contextual.groupby(\"word_idx\").agg(\n",
    "    dict(word=\"first\", start=\"first\", end=\"last\"))\n",
    "df_word = df_word.rename(columns={'word': 'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = join(ECOG_DIR, 'data', 'transcripts')\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "df_word.to_csv(join(out_dir, '___podcasts-story___', 'features.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
