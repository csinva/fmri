{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../experiments')\n",
    "import dvu\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import imodelsx.process_results\n",
    "import neuro.features.qa_questions as qa_questions\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from neuro import analyze_helper, viz\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "import torch\n",
    "import spacy\n",
    "fit_encoding = __import__('02_fit_encoding')\n",
    "dvu.set_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "path = f\"KomeijiForce/Cuckoo-C4-Super-Rainbow\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "tagger = AutoModelForTokenClassification.from_pretrained(path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_tokens_extraction(text):\n",
    "\n",
    "    def find_sequences(lst):\n",
    "        sequences = []\n",
    "        i = 0\n",
    "        while i < len(lst):\n",
    "            if lst[i] == 0:\n",
    "                start = i\n",
    "                end = i\n",
    "                i += 1\n",
    "                while i < len(lst) and lst[i] == 1:\n",
    "                    end = i\n",
    "                    i += 1\n",
    "                sequences.append((start, end+1))\n",
    "            else:\n",
    "                i += 1\n",
    "        return sequences\n",
    "\n",
    "    text = \" \".join([token.text for token in nlp(text)])\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    # print(tokens)\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    tag_predictions = tagger(**inputs).logits[0].argmax(-1).cpu().numpy()\n",
    "\n",
    "    # only keep relevant tokens\n",
    "    start_idx = tokens.index('ĊĊ')\n",
    "    end_idx = tokens.index('ĠQuestion')\n",
    "    # print(start_idx)\n",
    "    input_ids = inputs.input_ids[0, start_idx:end_idx - 1]\n",
    "    tag_predictions = tag_predictions[start_idx:end_idx - 1]\n",
    "    tokens = tokens[start_idx: end_idx - 1]\n",
    "\n",
    "    predictions = [tokenizer.decode(input_ids[seq[0]:seq[1]]).strip(\n",
    "    ) for seq in find_sequences(tag_predictions)]\n",
    "\n",
    "    return tokens, tag_predictions, predictions\n",
    "\n",
    "\n",
    "def clean_token(s):\n",
    "    return s.replace('Ċ', '_').replace('Ġ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Tom and Jack went to their trip in Paris and London.\"\n",
    "\n",
    "tag_predictions_list = []\n",
    "questions = [\n",
    "    \"What is the person mentioned here?\",\n",
    "    \"What is the city mentioned here?\",\n",
    "    \"Who goes with Tom together?\",\n",
    "    \"What do Tom and Jack go to Paris for?\",\n",
    "    \"Where does George live in?\",\n",
    "]\n",
    "for question in questions:\n",
    "    prompt = f\"User:\\n\\n{text}\\n\\nQuestion: {question}\\n\\nAssistant:\"\n",
    "    tokens, tag_predictions, predictions = next_tokens_extraction(prompt)\n",
    "    tokens = [clean_token(token) for token in tokens]\n",
    "    # print(question, predictions)\n",
    "    # print(len(tokens), len(tag_predictions), len(predictions))\n",
    "    tag_predictions_list.append(tag_predictions)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(tag_predictions_list, columns=tokens, index=questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df, cmap=\"Blues\", cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tag_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
